{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"ff3c9fb9-0c86-4acf-9162-c741c46e53a4","_kg_hide-output":false,"_uuid":"91db1348-a896-4607-8686-f6c6df6419ed","collapsed":false,"execution":{"iopub.execute_input":"2023-03-19T07:30:35.202851Z","iopub.status.busy":"2023-03-19T07:30:35.202431Z","iopub.status.idle":"2023-03-19T07:30:53.178442Z","shell.execute_reply":"2023-03-19T07:30:53.177132Z","shell.execute_reply.started":"2023-03-19T07:30:35.202813Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import shutil\n","import time\n","import zarr\n","import glob\n","import PIL.Image as Image\n","import random\n","import torch.utils.data as data\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from tqdm import tqdm\n","from ipywidgets import interact, fixed\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision.utils import make_grid\n","import os\n","os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n","\n","# INPUT_FOLDER = \"/kaggle/input/vesuvius-challenge-ink-detection\"\n","# WORKING_FOLDER = \"/kaggle/working/\"\n","# TEMP_FOLDER = \"kaggle/temp/\"\n","INPUT_FOLDER = \"data/\"\n","WORKING_FOLDER = \"working/\"\n","TEMP_FOLDER = \"temp/\"\n","TEST_PREFIX = ['data/test/a/', 'data/test/b/']\n","BUFFER = 32  # Buffer size in x and y direction\n","Z_START = 29 # First slice in the z direction to use\n","Z_DIM = 6  # Number of slices in the z direction\n","TRAINING_STEPS = 30000\n","LEARNING_RATE = 1e-3\n","BATCH_SIZE = 32\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","IS_TRAIN = True\n","IF_ZARR = True\n","CHEPOINT = 'result/dataset-1-ResNet3D-DIM-16-[train_loss]-0.0540-[dice_score]-0.94-[iou_score]-0.89-5-epoch.pkl'\n","FT = True # 是否加载预训练权重\n","THRESHOLD = 0.55 # mask阈值"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["class TimerError(Exception):\n","    pass\n","\n","class Timer():\n","    def __init__(self, text=None):\n","        if text is not None:\n","            self.text = text + \": {:0.4f} seconds\"\n","        else:\n","            self.text = \"Elapsed time: {:0.4f} seconds\"\n","        def logfunc(x):\n","            print(x)\n","        self.logger = logfunc\n","        self._start_time = None\n","\n","    def start(self):\n","        if self._start_time is not None:\n","            raise TimerError(\"Timer is already running.  Use .stop() to stop it.\")\n","        self._start_time = time.time()\n","\n","    def stop(self):\n","        if self._start_time is None:\n","            raise TimerError(\"Timer is not running.  Use .start() to start it.\")\n","        elapsed_time = time.time() - self._start_time\n","        self._start_time = None\n","\n","        if self.logger is not None:\n","            self.logger(self.text.format(elapsed_time))\n","\n","        return elapsed_time\n","\n","    def __enter__(self):\n","        self.start()\n","        return self\n","\n","    def __exit__(self, exc_type, exc_value, exc_traceback):\n","        self.stop()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The FragmentImageData class is used to store the compressed data on disk. It takes three parameters: the sample type (\"test\" or \"train\"), the sample index in the folder, and a boolean that determines whether the data is stored in the (persistent) working directory or the temporary directory. If stored persistently, then once generated, the zarr data format can be quickly loaded in other notebooks.\n","\n","If the zarr file does not already exist, it will be generated by parsing the individual image files in the corresponding input directory. Otherwise, it will quickly load from the zarr file.\n","\n","The image data can be accessed as attributes of the object, largely (with the exception of fancy indexing) treated as numpy arrays:\n","\n","surface_volume: the 3D X-ray tomography data\n","mask: the 2D boolean mask describing where data exists\n","truth: (Training data only) the 2D boolean mask with the ink truth set\n","infrared: (Training data only) the 2D infrared image of the parchment"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"25930dc1-1883-4fcd-9d40-f4aaa2ca152b","_kg_hide-output":true,"_uuid":"9cf6abaa-b06b-4d05-a6d8-b7f012cf2e2c","collapsed":false,"execution":{"iopub.execute_input":"2023-03-19T07:21:27.189440Z","iopub.status.busy":"2023-03-19T07:21:27.188760Z","iopub.status.idle":"2023-03-19T07:21:27.197989Z","shell.execute_reply":"2023-03-19T07:21:27.196895Z","shell.execute_reply.started":"2023-03-19T07:21:27.189397Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class FragmentImageException(Exception):\n","    pass\n","\n","class FragmentImageData:\n","    \"\"\"A general class that uses persistent zarr objects to store the surface volume data,\n","    binary data mask, and for training sets, the truth data and infrared image of a papyrus\n","    fragment, in a compressed and efficient way.\n","    \"\"\"\n","    def __init__(self, sample_type: str, sample_index: str, working: bool = True):\n","        if sample_type not in (\"test, train\"):\n","            raise FragmentImageException(\n","                f\"Invalid sample type f{sample_type}, must be one of 'test' or 'train'\"\n","            )\n","        zarrpath = self._zarr_path(sample_type, sample_index, working)\n","        if os.path.exists(zarrpath):\n","            self.zarr = self.load_from_zarr(zarrpath)\n","        else:\n","            dirpath = os.path.join(INPUT_FOLDER, sample_type, sample_index)\n","            if not os.path.exists(dirpath):\n","                raise FragmentImageException(\n","                    f\"No input data found at f{zarrpath} or f{dirpath}\"\n","                )\n","            self.zarr = self.load_from_directory(dirpath, zarrpath)\n","    \n","    @property\n","    def surface_volume(self):\n","        return self.zarr.surface_volume\n","    \n","    @property\n","    def mask(self):\n","        return self.zarr.mask\n","    \n","    @property\n","    def truth(self):\n","        return self.zarr.truth\n","    \n","    @property\n","    def infrared(self):\n","        return self.zarr.infrared\n","    \n","    @staticmethod\n","    def _zarr_path(sample_type: str, sample_index: str, working: bool = True):\n","        filename = f\"{sample_type}-{sample_index}.zarr\"\n","        if working:\n","            return os.path.join(WORKING_FOLDER, filename)\n","        else:\n","            return os.path.join(TEMP_FOLDER, filename)\n","    \n","    @staticmethod\n","    def clean_zarr(sample_type: str, sample_index: str, working: bool = True):\n","        zarrpath = FragmentImageData._zarr_path(sample_type, sample_index, working)\n","        if os.path.exists(zarrpath):\n","            shutil.rmtree(zarrpath)\n","    \n","    @staticmethod\n","    def load_from_zarr(filepath):\n","        with Timer(\"Loading from existing zarr\"):\n","            return zarr.open(filepath, mode=\"r\")\n","    \n","    @staticmethod\n","    def load_from_directory(dirpath, zarrpath):\n","        if os.path.exists(zarrpath):\n","            raise FragmentImageException(\n","                f\"Trying to overwrite existing zarr at f{zarrpath}\"\n","            )\n","        # Initialize the root zarr group and write the file\n","        root = zarr.open_group(zarrpath, mode=\"w\")\n","        # Load in the surface volume tif files\n","        with Timer(\"Surface volume loading\"):\n","            init = True\n","            imgfiles = sorted([\n","                imgfile for imgfile in\n","                os.listdir(os.path.join(dirpath, \"surface_volume\"))\n","            ])\n","            imgfiles = imgfiles[Z_START:Z_START+Z_DIM]\n","            for imgfile in imgfiles:\n","                print(f\"Loading file {imgfile}\", end=\"\\r\")\n","                img_data = np.array(\n","                    Image.open(os.path.join(dirpath, \"surface_volume\", imgfile))\n","                )\n","                if init:\n","                    surface_volume = root.zeros(\n","                        name=\"surface_volume\",\n","                        shape=(img_data.shape[0], img_data.shape[1], len(imgfiles)),\n","                        chunks=(1000, 1000, 4),\n","                        dtype=img_data.dtype,\n","                        write_empty_chunks=False,\n","                    )\n","                    init = False\n","                z_index = int(imgfile.split(\".\")[0]) - Z_START\n","                surface_volume[:,:,z_index] = img_data\n","        # Load in the mask\n","        with Timer(\"Mask loading\"):\n","            img_data = np.array(Image.open(os.path.join(dirpath, \"mask.png\")), dtype=bool)\n","            mask = root.array(\n","                name=\"mask\",\n","                data=img_data,\n","                shape=img_data.shape,\n","                chunks=(1000, 1000),\n","                dtype=img_data.dtype,\n","                write_empty_chunks=False,\n","            )\n","        # Load in the truth set (if it exists)\n","        with Timer(\"Truth set loading\"):\n","            truthfile = os.path.join(dirpath, \"inklabels.png\")\n","            if os.path.exists(truthfile):\n","                img_data = np.array(Image.open(truthfile), dtype=bool)\n","                truth = root.array(\n","                    name=\"truth\",\n","                    data=img_data,\n","                    shape=img_data.shape,\n","                    chunks=(1000, 1000),\n","                    dtype=img_data.dtype,\n","                    write_empty_chunks=False,\n","                )\n","        # Load in the infrared image (if it exists)\n","        with Timer(\"Infrared image loading\"):\n","            irfile = os.path.join(dirpath, \"ir.png\")\n","            if os.path.exists(irfile):\n","                img_data = np.array(Image.open(irfile))\n","                infrared = root.array(\n","                    name = \"infrared\",\n","                    data = img_data,\n","                    shape = img_data.shape,\n","                    chunks = (1000, 1000),\n","                    dtype=img_data.dtype,\n","                    write_empty_chunks=False,\n","                )\n","        return root "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let's see how long it takes to generate a new zarr file from scratch on the first training set data. Note we need to clean up any pre-existing zarr data first, otherwise it will load directly from there instead of reading the input images."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Surface volume loading: 36.1081 seconds\n","Mask loading: 0.0927 seconds\n","Truth set loading: 0.0912 seconds\n","Infrared image loading: 0.3774 seconds\n","Loading file 27.tif\r"]},{"name":"stderr","output_type":"stream","text":["/home/stu/anaconda3/envs/dtt/lib/python3.9/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (140973980 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Surface volume loading: 80.4000 seconds\n","Mask loading: 0.2657 seconds\n","Truth set loading: 0.2687 seconds\n","Infrared image loading: 1.1186 seconds\n","Surface volume loading: 33.4963 seconds\n","Mask loading: 0.9128 seconds\n","Truth set loading: 0.4121 seconds\n","Infrared image loading: 3.4408 seconds\n","Surface volume loading: 55.8678 seconds\n","Mask loading: 0.0365 seconds\n","Truth set loading: 0.0000 seconds\n","Infrared image loading: 0.0000 seconds\n","Surface volume loading: 7.1472 seconds\n","Mask loading: 0.1005 seconds\n","Truth set loading: 0.0000 seconds\n","Infrared image loading: 0.0000 seconds\n"]}],"source":["# 第一次运行需要这段代码生成缓存\n","if IF_ZARR:\n","    FragmentImageData.clean_zarr(\"train\", \"1\")\n","    data = FragmentImageData(\"train\", \"1\")\n","    FragmentImageData.clean_zarr(\"train\", \"2\")\n","    data = FragmentImageData(\"train\", \"2\")\n","    FragmentImageData.clean_zarr(\"train\", \"3\")\n","    data = FragmentImageData(\"train\", \"3\")\n","    FragmentImageData.clean_zarr(\"test\", \"a\")\n","    data = FragmentImageData(\"test\", \"a\")\n","    FragmentImageData.clean_zarr(\"test\", \"b\")\n","    data = FragmentImageData(\"test\", \"b\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_data_1 = FragmentImageData(\"train\", \"1\")\n","train_data_2 = FragmentImageData(\"train\", \"2\")\n","train_data_3 = FragmentImageData(\"train\", \"3\")\n","test_data_a = FragmentImageData(\"test\", \"a\")\n","test_data_b = FragmentImageData(\"test\", \"b\")\n","train_data_list = [train_data_1, train_data_2, train_data_3]\n","test_data_list = [test_data_a, test_data_b]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_val_split(mask, val_percent=0.3):\n","    # Convert the mask to a Numpy array\n","    mask_array = np.array(mask)\n","    # Generate random points within the mask\n","    num_points = TRAINING_STEPS * BATCH_SIZE  # Number of points to generate\n","    height, width = mask_array.shape\n","    points = []\n","    while len(points) < num_points:\n","        x = np.random.randint(0, width)\n","        y = np.random.randint(0, height)\n","        if mask_array[y, x] and not (x < BUFFER or x >= width-BUFFER or y < BUFFER or y >= height-BUFFER):\n","            points.append((y, x))\n","    n = int(num_points * val_percent)\n","    return points[:-n], points[-n:]\n","    \n","\n","class SubvolumeDataset(data.Dataset):\n","    def __init__(self, image_stack, label, pixels, is_train):\n","        self.image_stack = image_stack\n","        self.label = label\n","        self.pixels = pixels\n","        self.is_train = is_train\n","    def __len__(self):\n","        return len(self.pixels)\n","    def __getitem__(self, index):\n","        if self.is_train:\n","            y, x = self.pixels[index]\n","            subvolume = self.image_stack[y-BUFFER:y+BUFFER+1, x-BUFFER:x+BUFFER+1, :]\n","            subvolume = subvolume.unsqueeze(0).permute(0, 3, 1, 2)\n","            inklabel = self.label[y, x].view(1)\n","            return subvolume, inklabel\n","        else:\n","            subvolume = self.image_stack[y-BUFFER:y+BUFFER+1, x-BUFFER:x+BUFFER+1, :]\n","            subvolume = subvolume.squeeze(0).permute(0, 3, 1, 2)\n","            return subvolume\n","# IOU and Dice Score\n","def dice_coef(y_true, y_pred, thr=0.5, dim=(0, 1), epsilon=0.001):\n","    y_true = y_true.to(torch.float32)\n","    y_pred = (y_pred > thr).to(torch.float32)\n","    inter = (y_true * y_pred).sum(dim=dim)\n","    den = y_true.sum(dim=dim) + y_pred.sum(dim=dim)\n","    dice = ((2 * inter + epsilon) / (den + epsilon)).mean()\n","    return dice\n","\n","\n","def iou_coef(y_true, y_pred, thr=0.5, dim=(0, 1), epsilon=0.001):\n","    y_true = y_true.to(torch.float32)\n","    y_pred = (y_pred > thr).to(torch.float32)\n","    inter = (y_true * y_pred).sum(dim=dim)\n","    union = (y_true + y_pred - y_true * y_pred).sum(dim=dim)\n","    iou = ((inter + epsilon) / (union + epsilon)).mean()\n","    return iou"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We can see it took on the order of a minute to load all the images for this training dataset. However, now that we have the data on disk in our working directory, we can reload the data from that zarr much faster:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with Timer():\n","    for i in range(len(train_data_list)):\n","        fig, ax = plt.subplots(1, 1)\n","        ax.set_title(str(i) + \"_ir.png\")\n","        ax.imshow(train_data_list[i].infrared)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-19T07:21:27.201325Z","iopub.status.busy":"2023-03-19T07:21:27.200972Z","iopub.status.idle":"2023-03-19T07:21:27.221232Z","shell.execute_reply":"2023-03-19T07:21:27.220146Z","shell.execute_reply.started":"2023-03-19T07:21:27.201284Z"},"trusted":true},"outputs":[],"source":["class ResNetBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super(ResNetBlock, self).__init__()\n","        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm3d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.stride = stride\n","\n","        if in_channels != out_channels or stride != 1:\n","            self.shortcut = nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n","            self.bn_shortcut = nn.BatchNorm3d(out_channels)\n","        else:\n","            self.shortcut = nn.Identity()\n","            self.bn_shortcut = None\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","\n","        identity = self.shortcut(identity)\n","        if self.bn_shortcut is not None:\n","            identity = self.bn_shortcut(identity)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","class ResNet3D(nn.Module):\n","    def __init__(self, block, layers, num_classes=10):\n","        super(ResNet3D, self).__init__()\n","        self.in_channels = 8\n","\n","        self.conv1 = nn.Conv3d(1, 8, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm3d(8)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.layer1 = self.make_layer(block, 8, layers[0])\n","        self.layer2 = self.make_layer(block, 16, layers[1], stride=2)\n","        self.layer3 = self.make_layer(block, 32, layers[2], stride=2)\n","        self.layer4 = self.make_layer(block, 64, layers[3], stride=2)\n","\n","        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n","        self.flatten = nn.Flatten(start_dim=1)\n","        self.linear1 = nn.LazyLinear(256)\n","        self.relu1 = nn.ReLU()\n","        self.linear2 = nn.LazyLinear(128)\n","        self.relu2 = nn.ReLU()\n","        self.linear3 = nn.LazyLinear(num_classes)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def make_layer(self, block, out_channels, blocks, stride=1):\n","        layers = []\n","        layers.append(block(self.in_channels, out_channels, stride))\n","        self.in_channels = out_channels\n","\n","        for i in range(1, blocks):\n","            layers.append(block(out_channels, out_channels))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        # x = x.view(x.size(0), -1)\n","        x = self.flatten(x)\n","        x = self.linear1(x)\n","        x = self.relu1(x)\n","        x = self.linear2(x)\n","        x = self.relu2(x)\n","        x = self.linear3(x)\n","        x = self.sigmoid(x)\n","\n","        return x\n","class ResNet3DLess(nn.Module):\n","    def __init__(self, block, layers, num_classes=10):\n","        super(ResNet3DLess, self).__init__()\n","        self.in_channels = 64\n","\n","        self.conv1 = nn.Conv3d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm3d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.layer1 = self.make_layer(block, 64, layers[0])\n","        self.layer2 = self.make_layer(block, 128, layers[1], stride=2)\n","\n","        self.avgpool = nn.AdaptiveAvgPool3d((2, 2, 2))\n","        self.flatten = nn.Flatten(start_dim=1)\n","        # self.linear1 = nn.LazyLinear(1024)\n","        # self.drop1 = nn.Dropout(0.1)\n","        # self.linear2 = nn.LazyLinear(512)\n","        # self.drop2 = nn.Dropout(0.1)\n","        self.linear3 = nn.LazyLinear(128)\n","        self.relu = nn.ReLU()\n","        self.linear4 = nn.LazyLinear(num_classes)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def make_layer(self, block, out_channels, blocks, stride=1):\n","        layers = []\n","        layers.append(block(self.in_channels, out_channels, stride))\n","        self.in_channels = out_channels\n","\n","        for i in range(1, blocks):\n","            layers.append(block(out_channels, out_channels))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","\n","        x = self.avgpool(x)\n","        x = self.flatten(x)\n","        # x = self.linear1(x)\n","        # x = self.drop1(x)\n","        # x = self.linear2(x)\n","        # x = self.drop2(x)\n","        x = self.linear3(x)\n","        x = self.relu(x)\n","        x = self.linear4(x)\n","        x = self.sigmoid(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"_cell_guid":"e7b84e1e-7903-4290-9e09-3bf2cb62b222","_uuid":"cfbc9413-b6ff-4a69-ae60-22dddef18f11","trusted":true},"source":["Now we'll train the model. Conceptually it looks like this:\n","\n","<a href=\"https://user-images.githubusercontent.com/22727759/224853655-3fad9edb-c798-452e-94d0-f74efe71c08e.mp4\"><img src=\"https://user-images.githubusercontent.com/22727759/224853385-ed190d89-f466-469c-82a9-499881759d57.gif\"/></a>\n","\n","This typically takes about 10 minutes."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-19T07:22:04.779128Z","iopub.status.busy":"2023-03-19T07:22:04.778480Z","iopub.status.idle":"2023-03-19T07:22:06.646772Z","shell.execute_reply":"2023-03-19T07:22:06.645661Z","shell.execute_reply.started":"2023-03-19T07:22:04.779088Z"},"trusted":true},"outputs":[],"source":["model = ResNet3D(block=ResNetBlock, layers=[1, 1, 1, 1], num_classes=1).to(DEVICE)\n","model_name = 'ResNet3D'\n","if FT:\n","    try:\n","        checkpoint = torch.load(CHEPOINT, map_location=DEVICE)\n","        models_dict = model.state_dict()\n","        for model_part in models_dict:\n","            if model_part in checkpoint:\n","                models_dict[model_part] = checkpoint[model_part]\n","        model.load_state_dict(models_dict)\n","        print('Checkpoint loaded')\n","    except:\n","        print('Checkpoint not loaded')\n","        pass"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"790108d2-5260-4276-9105-9da5a27c28f5","_uuid":"29fb8028-1ec5-42fb-b61a-658e1181c951","execution":{"iopub.execute_input":"2023-03-19T07:22:06.650589Z","iopub.status.busy":"2023-03-19T07:22:06.649965Z","iopub.status.idle":"2023-03-19T07:22:06.662667Z","shell.execute_reply":"2023-03-19T07:22:06.661396Z","shell.execute_reply.started":"2023-03-19T07:22:06.650559Z"},"trusted":true},"outputs":[],"source":["if IS_TRAIN:\n","    # 实例化SummaryWriter对象\n","    torch.cuda.empty_cache()\n","    writer = SummaryWriter('result/logs')\n","    EPOCH = 5\n","    T_max = int(30000 / BATCH_SIZE * EPOCH) + 50\n","    min_lr = 0.000001\n","    print('''\n","    Starting training:\n","        Model: {}\n","        Epochs: {}\n","        Batch size: {}\n","        Learning rate: {}\n","        CUDA: {}\n","    '''.format(model_name,\n","               EPOCH,\n","               BATCH_SIZE,\n","               LEARNING_RATE,\n","               torch.cuda.is_available()))\n","    criterion = nn.BCELoss()\n","    optimizer = optim.AdamW(model.parameters(),\n","                            lr=LEARNING_RATE,\n","                            betas=(0.9, 0.999),\n","                            weight_decay=0.01\n","                            )\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max, eta_min=min_lr)\n","    max_memory = torch.cuda.max_memory_allocated(device=DEVICE) / 1E9 if torch.cuda.is_available() else 0\n","    # 循环训练 1~3中的数据，每轮数据只抽取了TRAINING_STEPS的长度，也可以全部加入\n","    iter = 6\n","    for index in range(1, len(train_data_list)):\n","        import gc\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # 加载数据\n","        pixels_train_rect , pixels_val_rect= train_val_split(train_data_list[index].mask)\n","        image_stack = torch.from_numpy(np.array(train_data_list[index].surface_volume[:, :, Z_START:Z_START+Z_DIM], dtype=np.float32) / 65535.0)\n","        label = torch.from_numpy(np.array(train_data_list[index].truth)).float()\n","        train_dataset = SubvolumeDataset(image_stack, label, pixels_train_rect, IS_TRAIN)\n","        eval_dataset = SubvolumeDataset(image_stack, label, pixels_val_rect, IS_TRAIN)\n","\n","        for epoch in range(1, EPOCH + 1):\n","            train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","            eval_loader = data.DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","            epoch_loss = 0\n","            model.train()\n","            # TRAINING_STEPS = len(train_loader)\n","            bar = tqdm(enumerate(train_loader), total=len(train_loader)) \n","            for i, (subvolumes, inklabels) in bar:\n","                optimizer.zero_grad()\n","                outputs = model(subvolumes.to(DEVICE))\n","                loss = criterion(outputs, inklabels.to(DEVICE))\n","                loss.backward()\n","                optimizer.step()\n","                scheduler.step()\n","                mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","                bar.set_postfix(loss=f'{loss.item():0.4f}', epoch=iter, dataset=str(index + 1) ,gpu_mem=f'{mem:0.2f} GB')\n","                epoch_loss += loss.item()\n","            #     for j, pred_value in enumerate(outputs):\n","            #         output[pixels_outside_rect[i*BATCH_SIZE+j]] = pred_value\n","            # # 使用make_grid将图片转换成网格形式，这里是每训练SUMMERY_SIZE步就会把结果打印在tensorboard中\n","            # pred_mask = make_grid(output.to(DEVICE), normalize=True)\n","            # true_mask = make_grid(lable_list[index].to(DEVICE), normalize=True)\n","            # 使用add_image方法将图片添加到TensorBoard中\n","            # writer.add_image('Train/True_mask', true_mask, global_step=epoch, dataformats=\"CHW\")\n","            # writer.add_image('Train/Pred_mask', pred_mask, global_step=epoch, dataformats=\"CHW\")\n","            writer.add_scalar('Train/Loss', epoch_loss / len(train_loader), iter)\n","            output = torch.zeros(train_data_list[index].truth.shape).float()\n","            true = torch.zeros(train_data_list[index].truth.shape).float()\n","            model.eval()\n","            with torch.no_grad():\n","                for i, (subvolumes, inklabels) in enumerate(tqdm(eval_loader)):\n","                    outputs = model(subvolumes.to(DEVICE))\n","                    for j, (value, true_value) in enumerate(zip(outputs, inklabels)):\n","                        output[pixels_val_rect[i*BATCH_SIZE+j]] = value\n","                        true[pixels_val_rect[i*BATCH_SIZE+j]] = true_value\n","\n","                # 计算准确率\n","                dice_score = dice_coef(true.to(DEVICE), output.to(DEVICE), thr=THRESHOLD).item()\n","                iou_socre = iou_coef(true.to(DEVICE), output.to(DEVICE), thr=THRESHOLD).item()\n","                        \n","                # 使用make_grid将图片转换成网格形式\n","                pred_mask = make_grid(output.to(DEVICE), normalize=True)\n","                true_mask = make_grid(true.to(DEVICE), normalize=True)\n","                # 使用add_image方法将图片添加到TensorBoard中\n","                writer.add_image('Valid/True_mask', true_mask, global_step=iter, dataformats=\"CHW\")\n","                writer.add_image('Valid/Pred_mask', pred_mask, global_step=iter, dataformats=\"CHW\")\n","                iter += 1\n","\n","                # fig, (ax1, ax2) = plt.subplots(1, 2)\n","                # ax1.imshow(output.cpu(), cmap='gray')\n","                # ax2.imshow(label.cpu(), cmap='gray')\n","                # plt.show()\n","                writer.add_scalar('Val/IOU', iou_socre, epoch)\n","                writer.add_scalar('Val/Dice', dice_score, epoch)\n","            torch.save(model.state_dict(), 'result/dataset-' + str(index + 1) +  '-{}-DIM-{}-[train_loss]-{:.4f}-[dice_score]-{:.2f}-[iou_score]-{:.2f}-'.format(model_name, Z_DIM ,epoch_loss / TRAINING_STEPS, dice_score, iou_socre) + str(epoch) + '-epoch.pkl')\n","        del image_stack\n","        del label\n","    writer.close()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"3c6ad763-f47c-4aaa-8c12-cb95c2d28d74","_uuid":"8edfa121-b2ef-419e-acbe-6d430fb50133","trusted":true},"source":["Finally, we'll generate a prediction image. We'll use the model to predict the presence of ink for each pixel in our rectangle (the val set). Conceptually it looks like this:\n","\n","<a href=\"https://user-images.githubusercontent.com/22727759/224853653-7cffd0a4-c6fa-49a2-93c1-e3c820863a51.mp4\"><img src=\"https://user-images.githubusercontent.com/22727759/224853379-09ae991e-02be-4ecc-a652-313165b3005c.gif\"/></a>\n","\n","\n","This should take about a minute.\n","\n","Remember that the model has never seen the label data within the rectangle before!\n","\n","We'll plot it side-by-side with the label image. Are you able to recognize the letter \"P\" in it?"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"56812c41-904d-4645-bddf-49b19fe2685d","_uuid":"68013338-2e52-4f0b-b15b-b18e071aa5da","collapsed":false,"execution":{"iopub.execute_input":"2023-03-19T07:25:33.475121Z","iopub.status.busy":"2023-03-19T07:25:33.474728Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["if not IS_TRAIN:\n","    output_list = []\n","    for index in range(len(test_image_stack_list)):\n","        test_dataset = SubvolumeDataset(test_image_stack_list[index], None, pixels_test_rect_list[index], IS_TRAIN)\n","        test_eval_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","        output = torch.zeros_like(shape_list[index]).float()\n","        model.eval()\n","        with torch.no_grad():\n","            for i, (subvolumes) in enumerate(tqdm(test_eval_loader)):\n","                for j, value in enumerate(model(subvolumes.to(DEVICE))):\n","                    output[pixels_test_rect_list[index][i*BATCH_SIZE+j]] = value\n","            output_list.append(output)\n","            out = output_list[index].gt(THRESHOLD).cpu().float().numpy()\n","            import cv2\n","            cv2.imwrite(str(index + 1) + '.png', out * 255)\n","    fig, (ax1, ax2) = plt.subplots(1, 2)\n","    ax1.imshow(output_list[0].gt(THRESHOLD).cpu(), cmap='gray')\n","    ax1.imshow(output_list[1].gt(THRESHOLD).cpu(), cmap='gray')\n","    plt.show()\n","    "]},{"cell_type":"markdown","metadata":{"_cell_guid":"49b12c62-7143-4d27-be79-e20e8cd9f5fe","_uuid":"15c0a510-b4d1-4e14-974e-cbe5a7ac6b8e","trusted":true},"source":["Since our output has to be binary, we have to choose a threshold, say 40% confidence."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4f1a3ed4-43c8-4a9c-9f49-dab4d3047048","_uuid":"3eb989fa-2823-49f7-a55f-1e178884e344","collapsed":false,"execution":{"iopub.status.busy":"2023-03-19T07:22:28.186015Z","iopub.status.idle":"2023-03-19T07:22:28.186806Z","shell.execute_reply":"2023-03-19T07:22:28.186565Z","shell.execute_reply.started":"2023-03-19T07:22:28.186538Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["if IS_TRAIN:\n","    fig, (ax1, ax2) = plt.subplots(1, 2)\n","    ax1.imshow(output.gt(THRESHOLD).cpu(), cmap='gray')\n","    ax2.imshow(label.cpu(), cmap='gray')\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"df73edb8-b09d-4e84-b33a-b384dbe486fe","_uuid":"04dc6e9a-5178-4ffa-95b3-a64783d4cf1a","trusted":true},"source":["Finally, Kaggle expects a runlength-encoded submission.csv file, so let's output that."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79b4b495-2e93-49ba-b9d8-434dccf49907","_uuid":"512cd6ab-2794-4ad3-87cc-fc240561f286","collapsed":false,"execution":{"iopub.status.busy":"2023-03-19T07:22:28.188296Z","iopub.status.idle":"2023-03-19T07:22:28.189057Z","shell.execute_reply":"2023-03-19T07:22:28.188810Z","shell.execute_reply.started":"2023-03-19T07:22:28.188784Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def rle(output):\n","    flat_img = np.where(output.flatten().cpu() > THRESHOLD, 1, 0).astype(np.uint8)\n","    starts = np.array((flat_img[:-1] == 0) & (flat_img[1:] == 1))\n","    ends = np.array((flat_img[:-1] == 1) & (flat_img[1:] == 0))\n","    starts_ix = np.where(starts)[0] + 2\n","    ends_ix = np.where(ends)[0] + 2\n","    lengths = ends_ix - starts_ix\n","    return \" \".join(map(str, sum(zip(starts_ix, lengths), ())))\n","# rle_output = rle(output)\n","# This doesn't make too much sense, but let's just output in the required format\n","# so notebook works as a submission. :-)\n","# print(\"Id,Predicted\\na,\" + rle_output + \"\\nb,\" + rle_output, file=open('submission.csv', 'w'))"]},{"cell_type":"markdown","metadata":{"_cell_guid":"799ddbd9-6862-4a43-9ae4-3c2d2f01da85","_uuid":"e84d0aa9-a297-4a90-b4f2-a8afb7c389c5","trusted":true},"source":["Hurray! We've detected ink! Now, can you do better? :-) For example, you could start with this [example submission](https://www.kaggle.com/code/danielhavir/vesuvius-challenge-example-submission)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-03-19T07:22:28.190428Z","iopub.status.idle":"2023-03-19T07:22:28.191183Z","shell.execute_reply":"2023-03-19T07:22:28.190951Z","shell.execute_reply.started":"2023-03-19T07:22:28.190926Z"},"trusted":true},"outputs":[],"source":["rle_list = []\n","for output in outputs:\n","    rle_sample = rle(output)\n","    rle_list.append(rle_sample)\n","print(\"Id,Predicted\\na,\" + rle_list[0] + \"\\nb,\" + rle_list[1], file=open('submission.csv', 'w'))"]}],"metadata":{"kernelspec":{"display_name":"dtt","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"61166640a95ac08c4dfcc44984648f9045f44ea39ff0c31cc75bc4fde1586daf"}}},"nbformat":4,"nbformat_minor":4}
