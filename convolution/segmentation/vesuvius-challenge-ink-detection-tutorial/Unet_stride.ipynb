{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"ff3c9fb9-0c86-4acf-9162-c741c46e53a4","_kg_hide-output":false,"_uuid":"91db1348-a896-4607-8686-f6c6df6419ed","collapsed":false,"execution":{"iopub.execute_input":"2023-03-19T07:30:35.202851Z","iopub.status.busy":"2023-03-19T07:30:35.202431Z","iopub.status.idle":"2023-03-19T07:30:53.178442Z","shell.execute_reply":"2023-03-19T07:30:53.177132Z","shell.execute_reply.started":"2023-03-19T07:30:35.202813Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import random\n","import torch.utils.data as data\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision.utils import make_grid\n","from torch.utils.data import ConcatDataset\n","from torch.cuda.amp import autocast, GradScaler\n","import os\n","import segmentation_models_pytorch as smp\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import warnings\n","import gc\n","import cv2\n","# 忽略所有警告\n","warnings.filterwarnings('ignore')\n","os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n","seed_value = 42   # 设定随机数种子\n","\n","np.random.seed(seed_value)\n","random.seed(seed_value)\n","os.environ['PYTHONHASHSEED'] = str(seed_value)  # 为了禁止hash随机化，使得实验可复现。\n","\n","torch.manual_seed(seed_value)     # 为CPU设置随机种子\n","torch.cuda.manual_seed(seed_value)      # 为当前GPU设置随机种子（只用一块GPU）\n","torch.cuda.manual_seed_all(seed_value)   # 为所有GPU设置随机种子（多块GPU）\n","\n","torch.backends.cudnn.deterministic = True\n","\n","class CFG:\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","    checpoint = 'result/UnetPlusPlus-DIM-6-[eval_loss]-0.3889-[dice_score]-0.49-10-epoch.pkl'\n","    # ============== comp exp name =============\n","    comp_name = 'vesuvius'\n","\n","    # # comp_dir_path = './'\n","    # comp_dir_path = '/kaggle/input/'\n","    # comp_folder_name = 'vesuvius-challenge-ink-detection'\n","    # # comp_dataset_path = f'{comp_dir_path}datasets/{comp_folder_name}/'\n","    # comp_dataset_path = f'{comp_dir_path}{comp_folder_name}/'\n","        # comp_dir_path = './'\n","    comp_dir_path = ''\n","    comp_folder_name = 'data'\n","    # comp_dataset_path = f'{comp_dir_path}datasets/{comp_folder_name}/'\n","    comp_dataset_path = f'{comp_dir_path}{comp_folder_name}/'\n","    \n","    exp_name = 'Unet_stride'\n","\n","    # ============== pred target =============\n","    target_size = 1\n","\n","    # ============== model cfg =============\n","    model_name = 'Unet'\n","\n","    in_chans = 24# 65\n","    # ============== training cfg =============\n","    size = 224\n","    tile_size = 224\n","    stride = tile_size // 2\n","\n","    train_batch_size = 8 # 32\n","    valid_batch_size = 8\n","    use_amp = True\n","\n","    epochs = 50 # 30\n","\n","    # lr = 1e-4 / warmup_factor\n","    lr = 1e-5\n","\n","    # ============== fixed =============\n","    pretrained = True\n","\n","    backbone = 'se_resnext50_32x4d'\n","\n","    min_lr = 1e-6\n","    weight_decay = 1e-6\n","    max_grad_norm = 1000\n","\n","    num_workers = 4\n","\n","    seed = 42\n","\n","    threshhold = 0.5\n","\n","    all_best_dice = 0\n","    all_best_loss = np.float('inf')\n","\n","    shape_list = []\n","    test_shape_list = []\n","\n","    val_mask = None\n","    val_label = None\n","\n","    # ============== set dataset path =============\n","\n","    # outputs_path = f'/kaggle/working/outputs/{comp_name}/{exp_name}/'\n","    outputs_path = 'result/'\n","\n","    submission_dir = outputs_path + 'submissions/'\n","    submission_path = submission_dir + f'submission_{exp_name}.csv'\n","\n","    model_dir = outputs_path\n","    log_dir = outputs_path + 'logs/'\n","\n","    # ============== augmentation =============\n","    train_aug_list = [\n","        # A.RandomResizedCrop(\n","        #     size, size, scale=(0.85, 1.0)),\n","        A.Resize(size, size),\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.5),\n","        A.RandomBrightnessContrast(p=0.75),\n","        A.ShiftScaleRotate(p=0.75),\n","        A.OneOf([\n","                A.GaussNoise(var_limit=[10, 50]),\n","                A.GaussianBlur(),\n","                A.MotionBlur(),\n","                ], p=0.4),\n","        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n","        A.CoarseDropout(max_holes=1, max_width=int(size * 0.3), max_height=int(size * 0.3), \n","                        mask_fill_value=0, p=0.5),\n","        # A.Cutout(max_h_size=int(size * 0.6),\n","        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n","        A.Normalize(\n","            mean= [0] * in_chans,\n","            std= [1] * in_chans\n","        ),\n","        ToTensorV2(transpose_mask=True),\n","    ]\n","\n","    valid_aug_list = [\n","        A.Resize(size, size),\n","        A.Normalize(\n","            mean= [0] * in_chans,\n","            std= [1] * in_chans\n","        ),\n","        ToTensorV2(transpose_mask=True),\n","    ]\n","seed = CFG.seed\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def read_image_mask(fragment_id):\n","\n","    images = []\n","\n","    # idxs = range(65)\n","    mid = 65 // 2\n","    start = mid - CFG.in_chans // 2\n","    end = mid + CFG.in_chans // 2\n","    idxs = range(start, end)\n","\n","    for i in tqdm(idxs):\n","        \n","        image = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/surface_volume/{i:02}.tif\", 0)\n","\n","        pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size + 1)\n","        pad1 = (CFG.tile_size - image.shape[1] % CFG.tile_size + 1)\n","\n","        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n","\n","        images.append(image)\n","    images = np.stack(images, axis=2)\n","\n","    label = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/inklabels.png\", 0)\n","    label = np.pad(label, [(0, pad0), (0, pad1)], constant_values=0)\n","\n","    label = label.astype('float32')\n","    label /= 255.0\n","\n","    mask = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/mask.png\", 0)\n","    mask = np.pad(mask, [(0, pad0), (0, pad1)], constant_values=0)\n","\n","    mask = (mask / 255.).astype('float32')\n","\n","    CFG.shape_list.append(mask.shape)\n","    if fragment_id == 1:\n","        CFG.val_mask = mask\n","        CFG.val_label = label\n","    \n","    return images, label, mask\n","\n","def get_train_valid_dataset(val_persent=0.05):\n","    train_id = [2, 3]\n","    train_images = []\n","    train_labels = []\n","\n","    valid_images = []\n","    valid_labels = []\n","    valid_positons = []\n","\n","    for fragment_id in range(1, 4):\n","\n","        image, label, mask = read_image_mask(fragment_id)\n","\n","        x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n","        y1_list = list(range(0, image.shape[0]-CFG.tile_size+1, CFG.stride))\n","\n","        for y1 in y1_list:\n","            for x1 in x1_list:\n","                y2 = y1 + CFG.tile_size\n","                x2 = x1 + CFG.tile_size\n","                if sum(list(mask[y1:y2, x1:x2].flatten())) != 0:\n","                    if fragment_id in train_id:\n","                        train_images.append(image[y1:y2, x1:x2])\n","                        train_labels.append(label[y1:y2, x1:x2, None])\n","                    else:\n","                        valid_images.append(image[y1:y2, x1:x2])\n","                        valid_labels.append(label[y1:y2, x1:x2, None])\n","                        valid_positons.append([x1, y1, x2, y2, fragment_id - 1])\n","    return train_images, train_labels, valid_images, valid_labels, valid_positons\n","\n","def get_transforms(data, cfg):\n","    if data == 'train':\n","        aug = A.Compose(cfg.train_aug_list)\n","    elif data == 'valid':\n","        aug = A.Compose(cfg.valid_aug_list)\n","    return aug\n","\n","class SubvolumeDataset(data.Dataset):\n","    def __init__(self, images, labels, positions, transform, is_train):\n","        self.transform = transform\n","        self.images = images\n","        self.labels = labels\n","        self.is_train = is_train\n","        self.positions = positions\n","    def __len__(self):\n","        return len(self.images)\n","    def __getitem__(self, index):\n","        if self.is_train:\n","            image = self.images[index]\n","            label = self.labels[index]\n","            if self.positions:\n","                position = np.array(self.positions[index])\n","            else:\n","                position = np.zeros(1)\n","            if self.transform:\n","                data = self.transform(image=image, mask=label)\n","                image = data['image']\n","                label = data['mask']\n","            return image, label, position\n","        else:\n","            image = self.images[index]\n","            position = np.array(self.positions[index])\n","            if self.transform:\n","                data = self.transform(image=image, mask=label)\n","                image = data['image']\n","            return image, position\n","        \n","# IOU and Dice Score\n","def dice_coef(targets, preds, thr=0.5, beta=0.5, smooth=1e-5):\n","\n","    #comment out if your model contains a sigmoid or equivalent activation layer\n","    # flatten label and prediction tensors\n","    preds = (preds > thr).view(-1).float()\n","    targets = targets.view(-1).float()\n","\n","    y_true_count = targets.sum()\n","    ctp = preds[targets==1].sum()\n","    cfp = preds[targets==0].sum()\n","    beta_squared = beta * beta\n","\n","    c_precision = ctp / (ctp + cfp + smooth)\n","    c_recall = ctp / (y_true_count + smooth)\n","    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n","\n","    return dice"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 24/24 [00:08<00:00,  2.73it/s]\n","100%|██████████| 24/24 [01:04<00:00,  2.67s/it]\n","100%|██████████| 24/24 [00:08<00:00,  2.67it/s]\n"]}],"source":["train_images, train_labels, valid_images, valid_labels, valid_positons = get_train_valid_dataset()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["train_dataset = SubvolumeDataset(train_images, train_labels, None,get_transforms(data='train', cfg=CFG), True)\n","valid_dataset = SubvolumeDataset(valid_images, valid_labels, valid_positons, get_transforms(data='valid', cfg=CFG), True)\n","train_loader = data.DataLoader(train_dataset,\n","                          batch_size=CFG.train_batch_size,\n","                          shuffle=True,\n","                          num_workers=CFG.num_workers, pin_memory=True, drop_last=True,\n","                          )\n","valid_loader = data.DataLoader(valid_dataset,\n","                          batch_size=CFG.valid_batch_size,\n","                          shuffle=False,\n","                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-03-19T07:22:04.779128Z","iopub.status.busy":"2023-03-19T07:22:04.778480Z","iopub.status.idle":"2023-03-19T07:22:06.646772Z","shell.execute_reply":"2023-03-19T07:22:06.645661Z","shell.execute_reply.started":"2023-03-19T07:22:04.779088Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]          75,264\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5          [-1, 128, 56, 56]           8,192\n","       BatchNorm2d-6          [-1, 128, 56, 56]             256\n","              ReLU-7          [-1, 128, 56, 56]               0\n","            Conv2d-8          [-1, 128, 56, 56]           4,608\n","       BatchNorm2d-9          [-1, 128, 56, 56]             256\n","             ReLU-10          [-1, 128, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          32,768\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","AdaptiveAvgPool2d-15            [-1, 256, 1, 1]               0\n","           Conv2d-16             [-1, 16, 1, 1]           4,112\n","             ReLU-17             [-1, 16, 1, 1]               0\n","           Conv2d-18            [-1, 256, 1, 1]           4,352\n","          Sigmoid-19            [-1, 256, 1, 1]               0\n","         SEModule-20          [-1, 256, 56, 56]               0\n","             ReLU-21          [-1, 256, 56, 56]               0\n","SEResNeXtBottleneck-22          [-1, 256, 56, 56]               0\n","           Conv2d-23          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-24          [-1, 128, 56, 56]             256\n","             ReLU-25          [-1, 128, 56, 56]               0\n","           Conv2d-26          [-1, 128, 56, 56]           4,608\n","      BatchNorm2d-27          [-1, 128, 56, 56]             256\n","             ReLU-28          [-1, 128, 56, 56]               0\n","           Conv2d-29          [-1, 256, 56, 56]          32,768\n","      BatchNorm2d-30          [-1, 256, 56, 56]             512\n","AdaptiveAvgPool2d-31            [-1, 256, 1, 1]               0\n","           Conv2d-32             [-1, 16, 1, 1]           4,112\n","             ReLU-33             [-1, 16, 1, 1]               0\n","           Conv2d-34            [-1, 256, 1, 1]           4,352\n","          Sigmoid-35            [-1, 256, 1, 1]               0\n","         SEModule-36          [-1, 256, 56, 56]               0\n","             ReLU-37          [-1, 256, 56, 56]               0\n","SEResNeXtBottleneck-38          [-1, 256, 56, 56]               0\n","           Conv2d-39          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-40          [-1, 128, 56, 56]             256\n","             ReLU-41          [-1, 128, 56, 56]               0\n","           Conv2d-42          [-1, 128, 56, 56]           4,608\n","      BatchNorm2d-43          [-1, 128, 56, 56]             256\n","             ReLU-44          [-1, 128, 56, 56]               0\n","           Conv2d-45          [-1, 256, 56, 56]          32,768\n","      BatchNorm2d-46          [-1, 256, 56, 56]             512\n","AdaptiveAvgPool2d-47            [-1, 256, 1, 1]               0\n","           Conv2d-48             [-1, 16, 1, 1]           4,112\n","             ReLU-49             [-1, 16, 1, 1]               0\n","           Conv2d-50            [-1, 256, 1, 1]           4,352\n","          Sigmoid-51            [-1, 256, 1, 1]               0\n","         SEModule-52          [-1, 256, 56, 56]               0\n","             ReLU-53          [-1, 256, 56, 56]               0\n","SEResNeXtBottleneck-54          [-1, 256, 56, 56]               0\n","           Conv2d-55          [-1, 256, 56, 56]          65,536\n","      BatchNorm2d-56          [-1, 256, 56, 56]             512\n","             ReLU-57          [-1, 256, 56, 56]               0\n","           Conv2d-58          [-1, 256, 28, 28]          18,432\n","      BatchNorm2d-59          [-1, 256, 28, 28]             512\n","             ReLU-60          [-1, 256, 28, 28]               0\n","           Conv2d-61          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-62          [-1, 512, 28, 28]           1,024\n","           Conv2d-63          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-64          [-1, 512, 28, 28]           1,024\n","AdaptiveAvgPool2d-65            [-1, 512, 1, 1]               0\n","           Conv2d-66             [-1, 32, 1, 1]          16,416\n","             ReLU-67             [-1, 32, 1, 1]               0\n","           Conv2d-68            [-1, 512, 1, 1]          16,896\n","          Sigmoid-69            [-1, 512, 1, 1]               0\n","         SEModule-70          [-1, 512, 28, 28]               0\n","             ReLU-71          [-1, 512, 28, 28]               0\n","SEResNeXtBottleneck-72          [-1, 512, 28, 28]               0\n","           Conv2d-73          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-74          [-1, 256, 28, 28]             512\n","             ReLU-75          [-1, 256, 28, 28]               0\n","           Conv2d-76          [-1, 256, 28, 28]          18,432\n","      BatchNorm2d-77          [-1, 256, 28, 28]             512\n","             ReLU-78          [-1, 256, 28, 28]               0\n","           Conv2d-79          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 512, 28, 28]           1,024\n","AdaptiveAvgPool2d-81            [-1, 512, 1, 1]               0\n","           Conv2d-82             [-1, 32, 1, 1]          16,416\n","             ReLU-83             [-1, 32, 1, 1]               0\n","           Conv2d-84            [-1, 512, 1, 1]          16,896\n","          Sigmoid-85            [-1, 512, 1, 1]               0\n","         SEModule-86          [-1, 512, 28, 28]               0\n","             ReLU-87          [-1, 512, 28, 28]               0\n","SEResNeXtBottleneck-88          [-1, 512, 28, 28]               0\n","           Conv2d-89          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-90          [-1, 256, 28, 28]             512\n","             ReLU-91          [-1, 256, 28, 28]               0\n","           Conv2d-92          [-1, 256, 28, 28]          18,432\n","      BatchNorm2d-93          [-1, 256, 28, 28]             512\n","             ReLU-94          [-1, 256, 28, 28]               0\n","           Conv2d-95          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-96          [-1, 512, 28, 28]           1,024\n","AdaptiveAvgPool2d-97            [-1, 512, 1, 1]               0\n","           Conv2d-98             [-1, 32, 1, 1]          16,416\n","             ReLU-99             [-1, 32, 1, 1]               0\n","          Conv2d-100            [-1, 512, 1, 1]          16,896\n","         Sigmoid-101            [-1, 512, 1, 1]               0\n","        SEModule-102          [-1, 512, 28, 28]               0\n","            ReLU-103          [-1, 512, 28, 28]               0\n","SEResNeXtBottleneck-104          [-1, 512, 28, 28]               0\n","          Conv2d-105          [-1, 256, 28, 28]         131,072\n","     BatchNorm2d-106          [-1, 256, 28, 28]             512\n","            ReLU-107          [-1, 256, 28, 28]               0\n","          Conv2d-108          [-1, 256, 28, 28]          18,432\n","     BatchNorm2d-109          [-1, 256, 28, 28]             512\n","            ReLU-110          [-1, 256, 28, 28]               0\n","          Conv2d-111          [-1, 512, 28, 28]         131,072\n","     BatchNorm2d-112          [-1, 512, 28, 28]           1,024\n","AdaptiveAvgPool2d-113            [-1, 512, 1, 1]               0\n","          Conv2d-114             [-1, 32, 1, 1]          16,416\n","            ReLU-115             [-1, 32, 1, 1]               0\n","          Conv2d-116            [-1, 512, 1, 1]          16,896\n","         Sigmoid-117            [-1, 512, 1, 1]               0\n","        SEModule-118          [-1, 512, 28, 28]               0\n","            ReLU-119          [-1, 512, 28, 28]               0\n","SEResNeXtBottleneck-120          [-1, 512, 28, 28]               0\n","          Conv2d-121          [-1, 512, 28, 28]         262,144\n","     BatchNorm2d-122          [-1, 512, 28, 28]           1,024\n","            ReLU-123          [-1, 512, 28, 28]               0\n","          Conv2d-124          [-1, 512, 14, 14]          73,728\n","     BatchNorm2d-125          [-1, 512, 14, 14]           1,024\n","            ReLU-126          [-1, 512, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","          Conv2d-129         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-130         [-1, 1024, 14, 14]           2,048\n","AdaptiveAvgPool2d-131           [-1, 1024, 1, 1]               0\n","          Conv2d-132             [-1, 64, 1, 1]          65,600\n","            ReLU-133             [-1, 64, 1, 1]               0\n","          Conv2d-134           [-1, 1024, 1, 1]          66,560\n","         Sigmoid-135           [-1, 1024, 1, 1]               0\n","        SEModule-136         [-1, 1024, 14, 14]               0\n","            ReLU-137         [-1, 1024, 14, 14]               0\n","SEResNeXtBottleneck-138         [-1, 1024, 14, 14]               0\n","          Conv2d-139          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-140          [-1, 512, 14, 14]           1,024\n","            ReLU-141          [-1, 512, 14, 14]               0\n","          Conv2d-142          [-1, 512, 14, 14]          73,728\n","     BatchNorm2d-143          [-1, 512, 14, 14]           1,024\n","            ReLU-144          [-1, 512, 14, 14]               0\n","          Conv2d-145         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-146         [-1, 1024, 14, 14]           2,048\n","AdaptiveAvgPool2d-147           [-1, 1024, 1, 1]               0\n","          Conv2d-148             [-1, 64, 1, 1]          65,600\n","            ReLU-149             [-1, 64, 1, 1]               0\n","          Conv2d-150           [-1, 1024, 1, 1]          66,560\n","         Sigmoid-151           [-1, 1024, 1, 1]               0\n","        SEModule-152         [-1, 1024, 14, 14]               0\n","            ReLU-153         [-1, 1024, 14, 14]               0\n","SEResNeXtBottleneck-154         [-1, 1024, 14, 14]               0\n","          Conv2d-155          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-156          [-1, 512, 14, 14]           1,024\n","            ReLU-157          [-1, 512, 14, 14]               0\n","          Conv2d-158          [-1, 512, 14, 14]          73,728\n","     BatchNorm2d-159          [-1, 512, 14, 14]           1,024\n","            ReLU-160          [-1, 512, 14, 14]               0\n","          Conv2d-161         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-162         [-1, 1024, 14, 14]           2,048\n","AdaptiveAvgPool2d-163           [-1, 1024, 1, 1]               0\n","          Conv2d-164             [-1, 64, 1, 1]          65,600\n","            ReLU-165             [-1, 64, 1, 1]               0\n","          Conv2d-166           [-1, 1024, 1, 1]          66,560\n","         Sigmoid-167           [-1, 1024, 1, 1]               0\n","        SEModule-168         [-1, 1024, 14, 14]               0\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","SEResNeXtBottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-172          [-1, 512, 14, 14]           1,024\n","            ReLU-173          [-1, 512, 14, 14]               0\n","          Conv2d-174          [-1, 512, 14, 14]          73,728\n","     BatchNorm2d-175          [-1, 512, 14, 14]           1,024\n","            ReLU-176          [-1, 512, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","AdaptiveAvgPool2d-179           [-1, 1024, 1, 1]               0\n","          Conv2d-180             [-1, 64, 1, 1]          65,600\n","            ReLU-181             [-1, 64, 1, 1]               0\n","          Conv2d-182           [-1, 1024, 1, 1]          66,560\n","         Sigmoid-183           [-1, 1024, 1, 1]               0\n","        SEModule-184         [-1, 1024, 14, 14]               0\n","            ReLU-185         [-1, 1024, 14, 14]               0\n","SEResNeXtBottleneck-186         [-1, 1024, 14, 14]               0\n","          Conv2d-187          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-188          [-1, 512, 14, 14]           1,024\n","            ReLU-189          [-1, 512, 14, 14]               0\n","          Conv2d-190          [-1, 512, 14, 14]          73,728\n","     BatchNorm2d-191          [-1, 512, 14, 14]           1,024\n","            ReLU-192          [-1, 512, 14, 14]               0\n","          Conv2d-193         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-194         [-1, 1024, 14, 14]           2,048\n","AdaptiveAvgPool2d-195           [-1, 1024, 1, 1]               0\n","          Conv2d-196             [-1, 64, 1, 1]          65,600\n","            ReLU-197             [-1, 64, 1, 1]               0\n","          Conv2d-198           [-1, 1024, 1, 1]          66,560\n","         Sigmoid-199           [-1, 1024, 1, 1]               0\n","        SEModule-200         [-1, 1024, 14, 14]               0\n","            ReLU-201         [-1, 1024, 14, 14]               0\n","SEResNeXtBottleneck-202         [-1, 1024, 14, 14]               0\n","          Conv2d-203          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-204          [-1, 512, 14, 14]           1,024\n","            ReLU-205          [-1, 512, 14, 14]               0\n","          Conv2d-206          [-1, 512, 14, 14]          73,728\n","     BatchNorm2d-207          [-1, 512, 14, 14]           1,024\n","            ReLU-208          [-1, 512, 14, 14]               0\n","          Conv2d-209         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-210         [-1, 1024, 14, 14]           2,048\n","AdaptiveAvgPool2d-211           [-1, 1024, 1, 1]               0\n","          Conv2d-212             [-1, 64, 1, 1]          65,600\n","            ReLU-213             [-1, 64, 1, 1]               0\n","          Conv2d-214           [-1, 1024, 1, 1]          66,560\n","         Sigmoid-215           [-1, 1024, 1, 1]               0\n","        SEModule-216         [-1, 1024, 14, 14]               0\n","            ReLU-217         [-1, 1024, 14, 14]               0\n","SEResNeXtBottleneck-218         [-1, 1024, 14, 14]               0\n","          Conv2d-219         [-1, 1024, 14, 14]       1,048,576\n","     BatchNorm2d-220         [-1, 1024, 14, 14]           2,048\n","            ReLU-221         [-1, 1024, 14, 14]               0\n","          Conv2d-222           [-1, 1024, 7, 7]         294,912\n","     BatchNorm2d-223           [-1, 1024, 7, 7]           2,048\n","            ReLU-224           [-1, 1024, 7, 7]               0\n","          Conv2d-225           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-226           [-1, 2048, 7, 7]           4,096\n","          Conv2d-227           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-228           [-1, 2048, 7, 7]           4,096\n","AdaptiveAvgPool2d-229           [-1, 2048, 1, 1]               0\n","          Conv2d-230            [-1, 128, 1, 1]         262,272\n","            ReLU-231            [-1, 128, 1, 1]               0\n","          Conv2d-232           [-1, 2048, 1, 1]         264,192\n","         Sigmoid-233           [-1, 2048, 1, 1]               0\n","        SEModule-234           [-1, 2048, 7, 7]               0\n","            ReLU-235           [-1, 2048, 7, 7]               0\n","SEResNeXtBottleneck-236           [-1, 2048, 7, 7]               0\n","          Conv2d-237           [-1, 1024, 7, 7]       2,097,152\n","     BatchNorm2d-238           [-1, 1024, 7, 7]           2,048\n","            ReLU-239           [-1, 1024, 7, 7]               0\n","          Conv2d-240           [-1, 1024, 7, 7]         294,912\n","     BatchNorm2d-241           [-1, 1024, 7, 7]           2,048\n","            ReLU-242           [-1, 1024, 7, 7]               0\n","          Conv2d-243           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-244           [-1, 2048, 7, 7]           4,096\n","AdaptiveAvgPool2d-245           [-1, 2048, 1, 1]               0\n","          Conv2d-246            [-1, 128, 1, 1]         262,272\n","            ReLU-247            [-1, 128, 1, 1]               0\n","          Conv2d-248           [-1, 2048, 1, 1]         264,192\n","         Sigmoid-249           [-1, 2048, 1, 1]               0\n","        SEModule-250           [-1, 2048, 7, 7]               0\n","            ReLU-251           [-1, 2048, 7, 7]               0\n","SEResNeXtBottleneck-252           [-1, 2048, 7, 7]               0\n","          Conv2d-253           [-1, 1024, 7, 7]       2,097,152\n","     BatchNorm2d-254           [-1, 1024, 7, 7]           2,048\n","            ReLU-255           [-1, 1024, 7, 7]               0\n","          Conv2d-256           [-1, 1024, 7, 7]         294,912\n","     BatchNorm2d-257           [-1, 1024, 7, 7]           2,048\n","            ReLU-258           [-1, 1024, 7, 7]               0\n","          Conv2d-259           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-260           [-1, 2048, 7, 7]           4,096\n","AdaptiveAvgPool2d-261           [-1, 2048, 1, 1]               0\n","          Conv2d-262            [-1, 128, 1, 1]         262,272\n","            ReLU-263            [-1, 128, 1, 1]               0\n","          Conv2d-264           [-1, 2048, 1, 1]         264,192\n","         Sigmoid-265           [-1, 2048, 1, 1]               0\n","        SEModule-266           [-1, 2048, 7, 7]               0\n","            ReLU-267           [-1, 2048, 7, 7]               0\n","SEResNeXtBottleneck-268           [-1, 2048, 7, 7]               0\n","    SENetEncoder-269  [[-1, 24, 224, 224], [-1, 64, 112, 112], [-1, 256, 56, 56], [-1, 512, 28, 28], [-1, 1024, 14, 14], [-1, 2048, 7, 7]]               0\n","AdaptiveAvgPool2d-270           [-1, 3072, 1, 1]               0\n","          Conv2d-271            [-1, 192, 1, 1]         590,016\n","            ReLU-272            [-1, 192, 1, 1]               0\n","          Conv2d-273           [-1, 3072, 1, 1]         592,896\n","         Sigmoid-274           [-1, 3072, 1, 1]               0\n","          Conv2d-275            [-1, 1, 14, 14]           3,073\n","         Sigmoid-276            [-1, 1, 14, 14]               0\n","      SCSEModule-277         [-1, 3072, 14, 14]               0\n","       Attention-278         [-1, 3072, 14, 14]               0\n","          Conv2d-279          [-1, 256, 14, 14]       7,077,888\n","     BatchNorm2d-280          [-1, 256, 14, 14]             512\n","            ReLU-281          [-1, 256, 14, 14]               0\n","          Conv2d-282          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-283          [-1, 256, 14, 14]             512\n","            ReLU-284          [-1, 256, 14, 14]               0\n","AdaptiveAvgPool2d-285            [-1, 256, 1, 1]               0\n","          Conv2d-286             [-1, 16, 1, 1]           4,112\n","            ReLU-287             [-1, 16, 1, 1]               0\n","          Conv2d-288            [-1, 256, 1, 1]           4,352\n","         Sigmoid-289            [-1, 256, 1, 1]               0\n","          Conv2d-290            [-1, 1, 14, 14]             257\n","         Sigmoid-291            [-1, 1, 14, 14]               0\n","      SCSEModule-292          [-1, 256, 14, 14]               0\n","       Attention-293          [-1, 256, 14, 14]               0\n","    DecoderBlock-294          [-1, 256, 14, 14]               0\n","AdaptiveAvgPool2d-295           [-1, 1536, 1, 1]               0\n","          Conv2d-296             [-1, 96, 1, 1]         147,552\n","            ReLU-297             [-1, 96, 1, 1]               0\n","          Conv2d-298           [-1, 1536, 1, 1]         148,992\n","         Sigmoid-299           [-1, 1536, 1, 1]               0\n","          Conv2d-300            [-1, 1, 28, 28]           1,537\n","         Sigmoid-301            [-1, 1, 28, 28]               0\n","      SCSEModule-302         [-1, 1536, 28, 28]               0\n","       Attention-303         [-1, 1536, 28, 28]               0\n","          Conv2d-304          [-1, 512, 28, 28]       7,077,888\n","     BatchNorm2d-305          [-1, 512, 28, 28]           1,024\n","            ReLU-306          [-1, 512, 28, 28]               0\n","          Conv2d-307          [-1, 512, 28, 28]       2,359,296\n","     BatchNorm2d-308          [-1, 512, 28, 28]           1,024\n","            ReLU-309          [-1, 512, 28, 28]               0\n","AdaptiveAvgPool2d-310            [-1, 512, 1, 1]               0\n","          Conv2d-311             [-1, 32, 1, 1]          16,416\n","            ReLU-312             [-1, 32, 1, 1]               0\n","          Conv2d-313            [-1, 512, 1, 1]          16,896\n","         Sigmoid-314            [-1, 512, 1, 1]               0\n","          Conv2d-315            [-1, 1, 28, 28]             513\n","         Sigmoid-316            [-1, 1, 28, 28]               0\n","      SCSEModule-317          [-1, 512, 28, 28]               0\n","       Attention-318          [-1, 512, 28, 28]               0\n","    DecoderBlock-319          [-1, 512, 28, 28]               0\n","AdaptiveAvgPool2d-320            [-1, 768, 1, 1]               0\n","          Conv2d-321             [-1, 48, 1, 1]          36,912\n","            ReLU-322             [-1, 48, 1, 1]               0\n","          Conv2d-323            [-1, 768, 1, 1]          37,632\n","         Sigmoid-324            [-1, 768, 1, 1]               0\n","          Conv2d-325            [-1, 1, 56, 56]             769\n","         Sigmoid-326            [-1, 1, 56, 56]               0\n","      SCSEModule-327          [-1, 768, 56, 56]               0\n","       Attention-328          [-1, 768, 56, 56]               0\n","          Conv2d-329          [-1, 256, 56, 56]       1,769,472\n","     BatchNorm2d-330          [-1, 256, 56, 56]             512\n","            ReLU-331          [-1, 256, 56, 56]               0\n","          Conv2d-332          [-1, 256, 56, 56]         589,824\n","     BatchNorm2d-333          [-1, 256, 56, 56]             512\n","            ReLU-334          [-1, 256, 56, 56]               0\n","AdaptiveAvgPool2d-335            [-1, 256, 1, 1]               0\n","          Conv2d-336             [-1, 16, 1, 1]           4,112\n","            ReLU-337             [-1, 16, 1, 1]               0\n","          Conv2d-338            [-1, 256, 1, 1]           4,352\n","         Sigmoid-339            [-1, 256, 1, 1]               0\n","          Conv2d-340            [-1, 1, 56, 56]             257\n","         Sigmoid-341            [-1, 1, 56, 56]               0\n","      SCSEModule-342          [-1, 256, 56, 56]               0\n","       Attention-343          [-1, 256, 56, 56]               0\n","    DecoderBlock-344          [-1, 256, 56, 56]               0\n","AdaptiveAvgPool2d-345            [-1, 320, 1, 1]               0\n","          Conv2d-346             [-1, 20, 1, 1]           6,420\n","            ReLU-347             [-1, 20, 1, 1]               0\n","          Conv2d-348            [-1, 320, 1, 1]           6,720\n","         Sigmoid-349            [-1, 320, 1, 1]               0\n","          Conv2d-350          [-1, 1, 112, 112]             321\n","         Sigmoid-351          [-1, 1, 112, 112]               0\n","      SCSEModule-352        [-1, 320, 112, 112]               0\n","       Attention-353        [-1, 320, 112, 112]               0\n","          Conv2d-354         [-1, 64, 112, 112]         184,320\n","     BatchNorm2d-355         [-1, 64, 112, 112]             128\n","            ReLU-356         [-1, 64, 112, 112]               0\n","          Conv2d-357         [-1, 64, 112, 112]          36,864\n","     BatchNorm2d-358         [-1, 64, 112, 112]             128\n","            ReLU-359         [-1, 64, 112, 112]               0\n","AdaptiveAvgPool2d-360             [-1, 64, 1, 1]               0\n","          Conv2d-361              [-1, 4, 1, 1]             260\n","            ReLU-362              [-1, 4, 1, 1]               0\n","          Conv2d-363             [-1, 64, 1, 1]             320\n","         Sigmoid-364             [-1, 64, 1, 1]               0\n","          Conv2d-365          [-1, 1, 112, 112]              65\n","         Sigmoid-366          [-1, 1, 112, 112]               0\n","      SCSEModule-367         [-1, 64, 112, 112]               0\n","       Attention-368         [-1, 64, 112, 112]               0\n","    DecoderBlock-369         [-1, 64, 112, 112]               0\n","AdaptiveAvgPool2d-370           [-1, 1280, 1, 1]               0\n","          Conv2d-371             [-1, 80, 1, 1]         102,480\n","            ReLU-372             [-1, 80, 1, 1]               0\n","          Conv2d-373           [-1, 1280, 1, 1]         103,680\n","         Sigmoid-374           [-1, 1280, 1, 1]               0\n","          Conv2d-375            [-1, 1, 28, 28]           1,281\n","         Sigmoid-376            [-1, 1, 28, 28]               0\n","      SCSEModule-377         [-1, 1280, 28, 28]               0\n","       Attention-378         [-1, 1280, 28, 28]               0\n","          Conv2d-379          [-1, 128, 28, 28]       1,474,560\n","     BatchNorm2d-380          [-1, 128, 28, 28]             256\n","            ReLU-381          [-1, 128, 28, 28]               0\n","          Conv2d-382          [-1, 128, 28, 28]         147,456\n","     BatchNorm2d-383          [-1, 128, 28, 28]             256\n","            ReLU-384          [-1, 128, 28, 28]               0\n","AdaptiveAvgPool2d-385            [-1, 128, 1, 1]               0\n","          Conv2d-386              [-1, 8, 1, 1]           1,032\n","            ReLU-387              [-1, 8, 1, 1]               0\n","          Conv2d-388            [-1, 128, 1, 1]           1,152\n","         Sigmoid-389            [-1, 128, 1, 1]               0\n","          Conv2d-390            [-1, 1, 28, 28]             129\n","         Sigmoid-391            [-1, 1, 28, 28]               0\n","      SCSEModule-392          [-1, 128, 28, 28]               0\n","       Attention-393          [-1, 128, 28, 28]               0\n","    DecoderBlock-394          [-1, 128, 28, 28]               0\n","AdaptiveAvgPool2d-395           [-1, 1024, 1, 1]               0\n","          Conv2d-396             [-1, 64, 1, 1]          65,600\n","            ReLU-397             [-1, 64, 1, 1]               0\n","          Conv2d-398           [-1, 1024, 1, 1]          66,560\n","         Sigmoid-399           [-1, 1024, 1, 1]               0\n","          Conv2d-400            [-1, 1, 56, 56]           1,025\n","         Sigmoid-401            [-1, 1, 56, 56]               0\n","      SCSEModule-402         [-1, 1024, 56, 56]               0\n","       Attention-403         [-1, 1024, 56, 56]               0\n","          Conv2d-404          [-1, 256, 56, 56]       2,359,296\n","     BatchNorm2d-405          [-1, 256, 56, 56]             512\n","            ReLU-406          [-1, 256, 56, 56]               0\n","          Conv2d-407          [-1, 256, 56, 56]         589,824\n","     BatchNorm2d-408          [-1, 256, 56, 56]             512\n","            ReLU-409          [-1, 256, 56, 56]               0\n","AdaptiveAvgPool2d-410            [-1, 256, 1, 1]               0\n","          Conv2d-411             [-1, 16, 1, 1]           4,112\n","            ReLU-412             [-1, 16, 1, 1]               0\n","          Conv2d-413            [-1, 256, 1, 1]           4,352\n","         Sigmoid-414            [-1, 256, 1, 1]               0\n","          Conv2d-415            [-1, 1, 56, 56]             257\n","         Sigmoid-416            [-1, 1, 56, 56]               0\n","      SCSEModule-417          [-1, 256, 56, 56]               0\n","       Attention-418          [-1, 256, 56, 56]               0\n","    DecoderBlock-419          [-1, 256, 56, 56]               0\n","AdaptiveAvgPool2d-420            [-1, 384, 1, 1]               0\n","          Conv2d-421             [-1, 24, 1, 1]           9,240\n","            ReLU-422             [-1, 24, 1, 1]               0\n","          Conv2d-423            [-1, 384, 1, 1]           9,600\n","         Sigmoid-424            [-1, 384, 1, 1]               0\n","          Conv2d-425          [-1, 1, 112, 112]             385\n","         Sigmoid-426          [-1, 1, 112, 112]               0\n","      SCSEModule-427        [-1, 384, 112, 112]               0\n","       Attention-428        [-1, 384, 112, 112]               0\n","          Conv2d-429         [-1, 64, 112, 112]         221,184\n","     BatchNorm2d-430         [-1, 64, 112, 112]             128\n","            ReLU-431         [-1, 64, 112, 112]               0\n","          Conv2d-432         [-1, 64, 112, 112]          36,864\n","     BatchNorm2d-433         [-1, 64, 112, 112]             128\n","            ReLU-434         [-1, 64, 112, 112]               0\n","AdaptiveAvgPool2d-435             [-1, 64, 1, 1]               0\n","          Conv2d-436              [-1, 4, 1, 1]             260\n","            ReLU-437              [-1, 4, 1, 1]               0\n","          Conv2d-438             [-1, 64, 1, 1]             320\n","         Sigmoid-439             [-1, 64, 1, 1]               0\n","          Conv2d-440          [-1, 1, 112, 112]              65\n","         Sigmoid-441          [-1, 1, 112, 112]               0\n","      SCSEModule-442         [-1, 64, 112, 112]               0\n","       Attention-443         [-1, 64, 112, 112]               0\n","    DecoderBlock-444         [-1, 64, 112, 112]               0\n","AdaptiveAvgPool2d-445            [-1, 896, 1, 1]               0\n","          Conv2d-446             [-1, 56, 1, 1]          50,232\n","            ReLU-447             [-1, 56, 1, 1]               0\n","          Conv2d-448            [-1, 896, 1, 1]          51,072\n","         Sigmoid-449            [-1, 896, 1, 1]               0\n","          Conv2d-450            [-1, 1, 56, 56]             897\n","         Sigmoid-451            [-1, 1, 56, 56]               0\n","      SCSEModule-452          [-1, 896, 56, 56]               0\n","       Attention-453          [-1, 896, 56, 56]               0\n","          Conv2d-454           [-1, 64, 56, 56]         516,096\n","     BatchNorm2d-455           [-1, 64, 56, 56]             128\n","            ReLU-456           [-1, 64, 56, 56]               0\n","          Conv2d-457           [-1, 64, 56, 56]          36,864\n","     BatchNorm2d-458           [-1, 64, 56, 56]             128\n","            ReLU-459           [-1, 64, 56, 56]               0\n","AdaptiveAvgPool2d-460             [-1, 64, 1, 1]               0\n","          Conv2d-461              [-1, 4, 1, 1]             260\n","            ReLU-462              [-1, 4, 1, 1]               0\n","          Conv2d-463             [-1, 64, 1, 1]             320\n","         Sigmoid-464             [-1, 64, 1, 1]               0\n","          Conv2d-465            [-1, 1, 56, 56]              65\n","         Sigmoid-466            [-1, 1, 56, 56]               0\n","      SCSEModule-467           [-1, 64, 56, 56]               0\n","       Attention-468           [-1, 64, 56, 56]               0\n","    DecoderBlock-469           [-1, 64, 56, 56]               0\n","AdaptiveAvgPool2d-470            [-1, 448, 1, 1]               0\n","          Conv2d-471             [-1, 28, 1, 1]          12,572\n","            ReLU-472             [-1, 28, 1, 1]               0\n","          Conv2d-473            [-1, 448, 1, 1]          12,992\n","         Sigmoid-474            [-1, 448, 1, 1]               0\n","          Conv2d-475          [-1, 1, 112, 112]             449\n","         Sigmoid-476          [-1, 1, 112, 112]               0\n","      SCSEModule-477        [-1, 448, 112, 112]               0\n","       Attention-478        [-1, 448, 112, 112]               0\n","          Conv2d-479         [-1, 64, 112, 112]         258,048\n","     BatchNorm2d-480         [-1, 64, 112, 112]             128\n","            ReLU-481         [-1, 64, 112, 112]               0\n","          Conv2d-482         [-1, 64, 112, 112]          36,864\n","     BatchNorm2d-483         [-1, 64, 112, 112]             128\n","            ReLU-484         [-1, 64, 112, 112]               0\n","AdaptiveAvgPool2d-485             [-1, 64, 1, 1]               0\n","          Conv2d-486              [-1, 4, 1, 1]             260\n","            ReLU-487              [-1, 4, 1, 1]               0\n","          Conv2d-488             [-1, 64, 1, 1]             320\n","         Sigmoid-489             [-1, 64, 1, 1]               0\n","          Conv2d-490          [-1, 1, 112, 112]              65\n","         Sigmoid-491          [-1, 1, 112, 112]               0\n","      SCSEModule-492         [-1, 64, 112, 112]               0\n","       Attention-493         [-1, 64, 112, 112]               0\n","    DecoderBlock-494         [-1, 64, 112, 112]               0\n","AdaptiveAvgPool2d-495            [-1, 320, 1, 1]               0\n","          Conv2d-496             [-1, 20, 1, 1]           6,420\n","            ReLU-497             [-1, 20, 1, 1]               0\n","          Conv2d-498            [-1, 320, 1, 1]           6,720\n","         Sigmoid-499            [-1, 320, 1, 1]               0\n","          Conv2d-500          [-1, 1, 112, 112]             321\n","         Sigmoid-501          [-1, 1, 112, 112]               0\n","      SCSEModule-502        [-1, 320, 112, 112]               0\n","       Attention-503        [-1, 320, 112, 112]               0\n","          Conv2d-504         [-1, 32, 112, 112]          92,160\n","     BatchNorm2d-505         [-1, 32, 112, 112]              64\n","            ReLU-506         [-1, 32, 112, 112]               0\n","          Conv2d-507         [-1, 32, 112, 112]           9,216\n","     BatchNorm2d-508         [-1, 32, 112, 112]              64\n","            ReLU-509         [-1, 32, 112, 112]               0\n","AdaptiveAvgPool2d-510             [-1, 32, 1, 1]               0\n","          Conv2d-511              [-1, 2, 1, 1]              66\n","            ReLU-512              [-1, 2, 1, 1]               0\n","          Conv2d-513             [-1, 32, 1, 1]              96\n","         Sigmoid-514             [-1, 32, 1, 1]               0\n","          Conv2d-515          [-1, 1, 112, 112]              33\n","         Sigmoid-516          [-1, 1, 112, 112]               0\n","      SCSEModule-517         [-1, 32, 112, 112]               0\n","       Attention-518         [-1, 32, 112, 112]               0\n","    DecoderBlock-519         [-1, 32, 112, 112]               0\n","          Conv2d-520         [-1, 16, 224, 224]           4,608\n","     BatchNorm2d-521         [-1, 16, 224, 224]              32\n","            ReLU-522         [-1, 16, 224, 224]               0\n","          Conv2d-523         [-1, 16, 224, 224]           2,304\n","     BatchNorm2d-524         [-1, 16, 224, 224]              32\n","            ReLU-525         [-1, 16, 224, 224]               0\n","AdaptiveAvgPool2d-526             [-1, 16, 1, 1]               0\n","          Conv2d-527              [-1, 1, 1, 1]              17\n","            ReLU-528              [-1, 1, 1, 1]               0\n","          Conv2d-529             [-1, 16, 1, 1]              32\n","         Sigmoid-530             [-1, 16, 1, 1]               0\n","          Conv2d-531          [-1, 1, 224, 224]              17\n","         Sigmoid-532          [-1, 1, 224, 224]               0\n","      SCSEModule-533         [-1, 16, 224, 224]               0\n","       Attention-534         [-1, 16, 224, 224]               0\n","    DecoderBlock-535         [-1, 16, 224, 224]               0\n","UnetPlusPlusDecoder-536         [-1, 16, 224, 224]               0\n","          Conv2d-537          [-1, 1, 224, 224]             145\n","        Identity-538          [-1, 1, 224, 224]               0\n","        Identity-539          [-1, 1, 224, 224]               0\n","      Activation-540          [-1, 1, 224, 224]               0\n","================================================================\n","Total params: 53,193,973\n","Trainable params: 53,193,973\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 4.59\n","Forward/backward pass size (MB): 1278.04\n","Params size (MB): 202.92\n","Estimated Total Size (MB): 1485.56\n","----------------------------------------------------------------\n","Checkpoint not loaded\n"]}],"source":["# model = Ringed_Res_Unet(n_channels=CFG.in_chans, n_classes=CFG.target_size).to(CFG.device)\n","model = smp.UnetPlusPlus(in_channels=CFG.in_chans, \n","                         classes=1, \n","                         encoder_name=CFG.backbone, \n","                         encoder_weights='imagenet', \n","                         activation=None, \n","                         decoder_attention_type='scse').to(CFG.device)\n","# x = np.zeros((16, CFG.in_chans, 224, 224))\n","# x = torch.from_numpy(x).to(CFG.device).float()\n","# out = model(x)\n","from torchsummary import summary\n","summary(model, input_size=(CFG.in_chans, 224, 224))\n","model_name = 'UnetPlusPlus'\n","if CFG.pretrained:\n","    try:\n","        checkpoint = torch.load(CFG.checpoint, map_location=CFG.device)\n","        models_dict = model.state_dict()\n","        for model_part in models_dict:\n","            if model_part in checkpoint:\n","                models_dict[model_part] = checkpoint[model_part]\n","        model.load_state_dict(models_dict)\n","        print('Checkpoint loaded')\n","    except:\n","        print('Checkpoint not loaded')\n","        pass"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from warmup_scheduler import GradualWarmupScheduler\n","\n","\n","class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n","    \"\"\"\n","    https://www.kaggle.com/code/underwearfitting/single-fold-training-of-resnet200d-lb0-965\n","    \"\"\"\n","    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n","        super(GradualWarmupSchedulerV2, self).__init__(\n","            optimizer, multiplier, total_epoch, after_scheduler)\n","\n","    def get_lr(self):\n","        if self.last_epoch > self.total_epoch:\n","            if self.after_scheduler:\n","                if not self.finished:\n","                    self.after_scheduler.base_lrs = [\n","                        base_lr * self.multiplier for base_lr in self.base_lrs]\n","                    self.finished = True\n","                return self.after_scheduler.get_lr()\n","            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n","        if self.multiplier == 1.0:\n","            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n","        else:\n","            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n","\n","def get_scheduler(cfg, optimizer):\n","    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(\n","        optimizer, cfg.epochs, eta_min=1e-7)\n","    scheduler = GradualWarmupSchedulerV2(\n","        optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n","\n","    return scheduler\n","\n","def scheduler_step(scheduler, avg_val_loss, epoch):\n","    scheduler.step(epoch)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def train_step(train_loader, model, criterion, optimizer, writer, device, epoch):\n","    model.train()\n","    epoch_loss = 0\n","    scaler = GradScaler(enabled=CFG.use_amp)\n","    bar = tqdm(enumerate(train_loader), total=len(train_loader)) \n","    for step, (image, label, _) in bar:\n","        optimizer.zero_grad()\n","        outputs = model(image.to(device))\n","        loss = criterion(outputs, label.to(device))\n","        scaler.scale(loss).backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        scaler.step(optimizer)\n","        scaler.update()\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        bar.set_postfix(loss=f'{loss.item():0.4f}', epoch=epoch ,gpu_mem=f'{mem:0.2f} GB', lr=f'{optimizer.state_dict()[\"param_groups\"][0][\"lr\"]:0.2e}')\n","        epoch_loss += loss.item()\n","    writer.add_scalar('Train/Loss', epoch_loss / len(train_loader), epoch)\n","    return epoch_loss / len(train_loader)\n","\n","def valid_step(valid_loader, model, criterion, device, writer, epoch):\n","    pred_label = np.zeros(CFG.shape_list[0])\n","    true_label = CFG.val_label\n","    mask_count = np.zeros(CFG.shape_list[0])\n","    model.eval()\n","    epoch_loss = 0\n","    for step, (images, labels, positions) in tqdm(enumerate(valid_loader), total=len(valid_loader)):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        with torch.no_grad():\n","            y_preds = model(images)\n","            loss = criterion(y_preds, labels)\n","        # make whole mask\n","        y_preds = torch.sigmoid(y_preds)\n","        pred_img =y_preds.squeeze().cpu().numpy()\n","        positions = positions.squeeze()\n","        for i in range(len(positions)):\n","            x1, y1, x2, y2, _ = positions[i].numpy().tolist()\n","            pred_label[y1:y2, x1:x2] += pred_img[i]\n","            mask_count[y1:y2, x1:x2] += np.ones((CFG.tile_size, CFG.tile_size))\n","        epoch_loss += loss.item()\n","    avg_loss = epoch_loss / len(valid_loader)\n","    print(f'mask_count_min: {mask_count.min()}')\n","    print(f'mask_count_max: {mask_count.max()}')\n","    # 计算准确率\n","    pred_label /= mask_count\n","    pred_label *= CFG.val_mask\n","    best_th = 0\n","    best_dice = 0\n","    for th in np.arange(1, 6, 0.5) / 10:\n","        dice_score = dice_coef(torch.from_numpy(true_label).to(CFG.device), torch.from_numpy(pred_label).to(CFG.device), thr=th).item()\n","        # dice_scores.append(dice_score)\n","        if dice_score > best_dice:\n","            best_dice = dice_score\n","            best_th = th\n","    if CFG.all_best_dice < best_dice:\n","        print('best_th={:2f}' .format(best_th),\"score up: {:2f}->{:2f}\".format(CFG.all_best_dice, best_dice))       \n","        cv2.imwrite('result/logs/img/'+str(epoch) + '_res.png', ((pred_label > best_th).astype('int')* 255) )\n","        CFG.all_best_dice = best_dice\n","        torch.save(model.state_dict(), 'result/' +  '{}-DIM-{}-[eval_loss]-{:.4f}-[dice_score]-{:.2f}-'.format(model_name, CFG.in_chans , avg_loss, best_dice) + str(epoch) + '-epoch.pkl')\n","        # 使用make_grid将图片转换成网格形式\n","        # pred_mask = make_grid(torch.from_numpy(pred_label ).to(CFG.device),normalize=True)\n","        # true_mask = make_grid(torch.from_numpy(true_label).to(CFG.device), normalize=True)\n","        # 使用add_image方法将图片添加到TensorBoard中\n","        # writer.add_image('Valid/True_mask', true_mask, global_step=epoch, dataformats=\"CHW\")\n","        # writer.add_image('Valid/Pred_mask', pred_mask, global_step=epoch, dataformats=\"CHW\")\n","    if CFG.all_best_loss > avg_loss:\n","        print('best_loss={:2f}'.format(avg_loss), \"loss down: {:2f}->{:2f}\".format(CFG.all_best_loss, avg_loss))\n","        cv2.imwrite('result/logs/img/' + str(epoch) + '_res.png', ((pred_label > best_th).astype('int')* 255) )\n","        CFG.all_best_loss = avg_loss\n","        torch.save(model.state_dict(), 'result/' +  '{}-DIM-{}-[eval_loss]-{:.4f}-[dice_score]-{:.2f}-'.format(model_name, CFG.in_chans ,avg_loss, best_dice) + str(epoch) + '-epoch.pkl')\n","    writer.add_scalar('Val/Dice', best_dice, epoch)\n","    writer.add_scalar('Valid/Loss', avg_loss , epoch)\n","    return avg_loss"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:33<00:00,  2.30it/s, epoch=1, gpu_mem=5.60 GB, loss=0.3506, lr=1.00e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","best_th=0.400000 score up: 0.000000->0.280372\n","best_loss=0.478190 loss down: inf->0.478190\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:38<00:00,  2.28it/s, epoch=2, gpu_mem=7.05 GB, loss=0.3267, lr=1.00e-04]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","best_th=0.250000 score up: 0.280372->0.369097\n","best_loss=0.390765 loss down: 0.478190->0.390765\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:38<00:00,  2.28it/s, epoch=3, gpu_mem=7.05 GB, loss=0.5382, lr=1.00e-04]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:39<00:00,  2.28it/s, epoch=4, gpu_mem=7.05 GB, loss=0.3492, lr=9.96e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","best_th=0.350000 score up: 0.369097->0.415894\n","best_loss=0.382265 loss down: 0.390765->0.382265\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:38<00:00,  2.28it/s, epoch=5, gpu_mem=7.05 GB, loss=0.1558, lr=9.91e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:40<00:00,  2.28it/s, epoch=6, gpu_mem=7.05 GB, loss=0.4181, lr=9.84e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","best_th=0.450000 score up: 0.415894->0.437695\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:38<00:00,  2.28it/s, epoch=7, gpu_mem=7.05 GB, loss=0.4465, lr=9.76e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:39<00:00,  2.28it/s, epoch=8, gpu_mem=7.05 GB, loss=0.2369, lr=9.65e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:39<00:00,  2.28it/s, epoch=9, gpu_mem=7.05 GB, loss=0.3147, lr=9.52e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:39<00:00,  2.28it/s, epoch=10, gpu_mem=7.05 GB, loss=0.5141, lr=9.38e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:39<00:00,  2.28it/s, epoch=11, gpu_mem=7.05 GB, loss=0.2946, lr=9.22e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:39<00:00,  2.28it/s, epoch=12, gpu_mem=7.05 GB, loss=0.1403, lr=9.05e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:39<00:00,  2.28it/s, epoch=13, gpu_mem=7.05 GB, loss=0.1678, lr=8.85e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:40<00:00,  2.28it/s, epoch=14, gpu_mem=7.05 GB, loss=0.1833, lr=8.65e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:39<00:00,  2.28it/s, epoch=15, gpu_mem=7.05 GB, loss=0.1514, lr=8.42e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:39<00:00,  2.28it/s, epoch=16, gpu_mem=7.05 GB, loss=0.3319, lr=8.19e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:39<00:00,  2.28it/s, epoch=17, gpu_mem=7.05 GB, loss=0.2317, lr=7.94e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:39<00:00,  2.28it/s, epoch=18, gpu_mem=7.05 GB, loss=0.1823, lr=7.68e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","best_th=0.550000 score up: 0.437695->0.473989\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:40<00:00,  2.28it/s, epoch=19, gpu_mem=7.05 GB, loss=0.3331, lr=7.41e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:39<00:00,  2.28it/s, epoch=20, gpu_mem=7.05 GB, loss=0.1314, lr=7.13e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:39<00:00,  2.28it/s, epoch=21, gpu_mem=7.05 GB, loss=0.1655, lr=6.84e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:39<00:00,  2.28it/s, epoch=22, gpu_mem=7.05 GB, loss=0.1667, lr=6.55e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:39<00:00,  2.28it/s, epoch=23, gpu_mem=7.05 GB, loss=0.1445, lr=6.25e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:39<00:00,  2.28it/s, epoch=24, gpu_mem=7.05 GB, loss=0.2671, lr=5.94e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:40<00:00,  2.27it/s, epoch=25, gpu_mem=7.05 GB, loss=0.2074, lr=5.63e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:42<00:00,  2.26it/s, epoch=26, gpu_mem=7.05 GB, loss=0.0461, lr=5.32e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:44<00:00,  2.26it/s, epoch=27, gpu_mem=7.05 GB, loss=0.0834, lr=5.01e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:44<00:00,  2.26it/s, epoch=28, gpu_mem=7.05 GB, loss=0.0427, lr=4.69e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:44<00:00,  2.26it/s, epoch=29, gpu_mem=7.05 GB, loss=0.2038, lr=4.38e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:44<00:00,  2.26it/s, epoch=30, gpu_mem=7.05 GB, loss=0.2414, lr=4.07e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:45<00:00,  2.26it/s, epoch=31, gpu_mem=7.05 GB, loss=0.2756, lr=3.76e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:45<00:00,  2.26it/s, epoch=32, gpu_mem=7.05 GB, loss=0.0651, lr=3.46e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:45<00:00,  2.25it/s, epoch=33, gpu_mem=7.05 GB, loss=0.2078, lr=3.17e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:45<00:00,  2.26it/s, epoch=34, gpu_mem=7.05 GB, loss=0.1285, lr=2.88e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:47<00:00,  2.25it/s, epoch=35, gpu_mem=7.05 GB, loss=0.1318, lr=2.60e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:39<00:00,  8.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:46<00:00,  2.25it/s, epoch=36, gpu_mem=7.05 GB, loss=0.0986, lr=2.33e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:45<00:00,  2.26it/s, epoch=37, gpu_mem=7.05 GB, loss=0.0897, lr=2.07e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:45<00:00,  2.25it/s, epoch=38, gpu_mem=7.05 GB, loss=0.1124, lr=1.82e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:47<00:00,  2.25it/s, epoch=39, gpu_mem=7.05 GB, loss=0.2144, lr=1.59e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:39<00:00,  8.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:50<00:00,  2.24it/s, epoch=40, gpu_mem=7.05 GB, loss=0.0503, lr=1.36e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:39<00:00,  8.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:49<00:00,  2.24it/s, epoch=41, gpu_mem=7.05 GB, loss=0.1443, lr=1.16e-05]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:46<00:00,  2.25it/s, epoch=42, gpu_mem=7.05 GB, loss=0.2794, lr=9.64e-06]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:46<00:00,  2.25it/s, epoch=43, gpu_mem=7.05 GB, loss=0.1176, lr=7.88e-06]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:46<00:00,  2.25it/s, epoch=44, gpu_mem=7.05 GB, loss=0.0781, lr=6.28e-06]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:45<00:00,  2.25it/s, epoch=45, gpu_mem=7.05 GB, loss=0.1347, lr=4.85e-06]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:46<00:00,  2.25it/s, epoch=46, gpu_mem=7.05 GB, loss=0.0385, lr=3.61e-06]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:39<00:00,  8.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:46<00:00,  2.25it/s, epoch=47, gpu_mem=7.05 GB, loss=0.0534, lr=2.54e-06]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:45<00:00,  2.25it/s, epoch=48, gpu_mem=7.05 GB, loss=0.0231, lr=1.67e-06]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:39<00:00,  8.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:46<00:00,  2.25it/s, epoch=49, gpu_mem=7.05 GB, loss=0.1173, lr=9.85e-07]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n","train:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1320/1320 [09:46<00:00,  2.25it/s, epoch=50, gpu_mem=7.05 GB, loss=0.0488, lr=4.94e-07]"]},{"name":"stdout","output_type":"stream","text":["val:\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 328/328 [00:38<00:00,  8.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["mask_count_min: 0.0\n","mask_count_max: 4.0\n"]}],"source":["criterion = smp.losses.SoftBCEWithLogitsLoss()\n","optimizer = optim.AdamW(model.parameters(),\n","                        lr=CFG.lr,\n","                        betas=(0.9, 0.999),\n","                        weight_decay=CFG.weight_decay\n","                        )\n","scheduler = get_scheduler(CFG, optimizer)\n","writer = SummaryWriter('result/logs')\n","for i in range(CFG.epochs):\n","    print('train:')\n","    train_step(train_loader, model, criterion, optimizer, writer, CFG.device, i + 1)\n","    print('val:')\n","    val_loss = valid_step(valid_loader, model, criterion, CFG.device, writer, i + 1)\n","    scheduler_step(scheduler, val_loss, i + 1)"]}],"metadata":{"kernelspec":{"display_name":"dtt","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"61166640a95ac08c4dfcc44984648f9045f44ea39ff0c31cc75bc4fde1586daf"}}},"nbformat":4,"nbformat_minor":4}
