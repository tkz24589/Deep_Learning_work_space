{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"a18c7d0f-a17a-4603-956d-2b531016c536","_uuid":"748d3554-7759-4443-b1b8-916e19ca50ed","trusted":true},"source":["This is a notebook explaining the [Ink Detection progress prize on Kaggle](https://www.kaggle.com/competitions/vesuvius-challenge), which is part of the larger [Vesuvius Challenge](https://scrollprize.org).\n","\n","For more background on the process of ink detection, be sure to check out [Tutorial 4: Ink Detection](https://scrollprize.org/tutorial4) on the Vesuvius Challenge website.\n","\n","In this notebook we'll see how to train a simple ML model to detect ink in a papyrus fragment from a 3d x-ray scan of the fragment.\n","\n","<img src=\"https://user-images.githubusercontent.com/177461/224853397-3cf86dc2-45b4-4e7c-9ec2-28a733791a75.jpg\" width=\"200\"/>\n","\n","First, initialize some variables, and let's look at a photo of the fragment. We won't use this for training, but it's useful to see.\n","\n","It's an infrared photo, since the ink is better visible in infrared light."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff3c9fb9-0c86-4acf-9162-c741c46e53a4","_kg_hide-output":false,"_uuid":"91db1348-a896-4607-8686-f6c6df6419ed","collapsed":false,"execution":{"iopub.execute_input":"2023-03-19T07:30:35.202851Z","iopub.status.busy":"2023-03-19T07:30:35.202431Z","iopub.status.idle":"2023-03-19T07:30:53.178442Z","shell.execute_reply":"2023-03-19T07:30:53.177132Z","shell.execute_reply.started":"2023-03-19T07:30:35.202813Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from einops import rearrange\n","from einops.layers.torch import Rearrange\n","import torch.optim as optim\n","import numpy as np\n","import glob\n","import PIL.Image as Image\n","import torch.utils.data as data\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from tqdm import tqdm\n","from ipywidgets import interact, fixed\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision.utils import make_grid\n","import os\n","os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n","\n","PREFIX = ['data/train/1/']\n","TEST_PREFIX = ['data/test/a/', 'data/test/b/']\n","BUFFER = 32  # Buffer size in x and y direction\n","Z_START = 27 # First slice in the z direction to use\n","Z_DIM = 8   # Number of slices in the z direction\n","TRAINING_STEPS = 60000\n","LEARNING_RATE = 1e-3\n","BATCH_SIZE = 32\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","IS_TRAIN = True\n","CHEPOINT = 'result/[train_loss]-0.1417-[dice_score]-0.0325-[iou_score]-0.0165-0-epoch.pkl'\n","FT = False # 是否加载预训练权重\n","THRESHOLD = 0.4 # mask阈值\n","\n","for i in range(len(PREFIX)):\n","    fig, ax1 = plt.subplots(1, 1)\n","    ax1.set_title(str(i) + \"_ir.png\")\n","    ax1.imshow(Image.open(PREFIX[i] + 'ir.png'))\n","    plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"7607926b-5a4d-4107-8935-955288d53ebd","_uuid":"ee5f3f31-6cc0-4dbf-b4e1-e9afb18bc0ea","trusted":true},"source":["Let's load these binary images:\n","* **mask.png**: a mask of which pixels contain data, and which pixels we should ignore.\n","* **inklabels.png**: our label data: whether a pixel contains ink or no ink (which has been hand-labeled based on the infrared photo)."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43a9acbe-f2c5-4976-b9ee-027e62c27a83","_uuid":"351fefa9-30dd-4e8d-bf3b-1aaa0fb33905","collapsed":false,"execution":{"iopub.execute_input":"2023-03-19T07:21:05.585716Z","iopub.status.busy":"2023-03-19T07:21:05.585127Z","iopub.status.idle":"2023-03-19T07:21:09.808558Z","shell.execute_reply":"2023-03-19T07:21:09.807356Z","shell.execute_reply.started":"2023-03-19T07:21:05.585678Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["if IS_TRAIN:\n","    # 加载训练数据\n","    mask_list = []\n","    lable_list = []\n","    for i in range(len(PREFIX)):\n","        mask = np.array(Image.open(PREFIX[i]+\"mask.png\").convert('1'))\n","        label = torch.from_numpy(np.array(Image.open(PREFIX[i]+\"inklabels.png\"))).gt(0).float().to(DEVICE)\n","        mask_list.append(mask)\n","        lable_list.append(label)\n","        fig, (ax1, ax2) = plt.subplots(1, 2)\n","        ax1.set_title(\"mask.png\")\n","        ax1.imshow(mask, cmap='gray')\n","        ax2.set_title(\"inklabels.png\")\n","        ax2.imshow(label.cpu(), cmap='gray')\n","        plt.show()\n","else:\n","    # 加载测试数据\n","    shape_list = []\n","    test_mask_list = []\n","    for i in range(len(TEST_PREFIX)):\n","        shape_list.append(torch.from_numpy(np.array(Image.open(TEST_PREFIX[i] + \"mask.png\"))))\n","        test_mask_list.append(np.array(Image.open(TEST_PREFIX[i] + \"mask.png\").convert('1')))"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"09e95f98-439b-49c3-aae2-550fadd533df","_uuid":"74a6ae91-2aa2-4eb3-9f3c-956dc54cf017","trusted":true},"source":["Next, we'll load the 3d x-ray of the fragment. This is represented as a .tif image stack. The image stack is an array of 16-bit grayscale images. Each image represents a \"slice\" in the z-direction, going from below the papyrus, to above the papyrus. We'll convert it to a 4D tensor of 32-bit floats. We'll also convert the pixel values to the range [0, 1].\n","\n","To save memory, we'll only load the innermost slices (`Z_DIM` of them). Let's look at them when we're done."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f75858f9-06ad-43cc-be5f-ab09738a58c1","_uuid":"929b9e7a-d30c-4462-a7b9-0765a76cdb4e","collapsed":false,"execution":{"iopub.execute_input":"2023-03-19T07:21:09.811169Z","iopub.status.busy":"2023-03-19T07:21:09.810453Z","iopub.status.idle":"2023-03-19T07:21:25.304029Z","shell.execute_reply":"2023-03-19T07:21:25.302929Z","shell.execute_reply.started":"2023-03-19T07:21:09.811130Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Load the 3d x-ray scan, one slice at a time\n","if IS_TRAIN:\n","    # 训练数据提取，使用demo中相同的方法\n","    # images_list = []\n","    image_stack_list = []\n","    for i in range(len(PREFIX)):\n","      # images_list.append(PREFIX[i]+\"surface_volume/*.tif\")\n","\n","      images = [np.array(Image.open(filename), dtype=np.float32)/65535.0 for filename in tqdm(sorted(glob.glob(PREFIX[i]+\"surface_volume/*.tif\"))[Z_START:Z_START+Z_DIM])]\n","      image_stack = torch.stack([torch.from_numpy(image) for image in images], dim=0).to(DEVICE)\n","      # images_list.append(images)\n","      image_stack_list.append(image_stack)\n","      fig, axes = plt.subplots(1, len(images), figsize=(15, 3))\n","      for image, ax in zip(images, axes):\n","        ax.imshow(np.array(Image.fromarray(image).resize((image.shape[1]//20, image.shape[0]//20)), dtype=np.float32), cmap='gray')\n","        ax.set_xticks([]); ax.set_yticks([])\n","      fig.tight_layout()\n","      plt.show()\n","      del images\n","else:\n","    test_images_list = []\n","    test_image_stack_list = []\n","    for i in range(len(TEST_PREFIX)):\n","      images = [np.array(Image.open(filename), dtype=np.float32)/65535.0 for filename in tqdm(sorted(glob.glob(TEST_PREFIX[i]+\"surface_volume/*.tif\"))[Z_START:Z_START+Z_DIM])]\n","      images_stack = torch.stack([torch.from_numpy(image) for image in images], dim=0).to(DEVICE)\n","      test_images_list.append(images)\n","      test_image_stack_list.append(images_stack)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"173e0034-8ce4-4a12-9a0b-43cff0022249","_uuid":"18a40c3b-4241-4f8d-b808-e1cab35b8f6e","jupyter":{"source_hidden":true},"trusted":true},"source":["Can you see the ink in these slices of the 3d x-ray scan..? Neither can we.\n","\n","Now we'll create a dataset of subvolumes. We use a small rectangle around the letter \"P\" for our evaluation, and we'll exclude those pixels from the training set. (It's actually a Greek letter \"rho\", which looks similar to our \"P\".)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"62d60bbe-85f1-4df4-b1e6-f4337268b11c","_uuid":"39a855d9-38f5-4f2d-ac7f-1f65529d1a3e","collapsed":false,"execution":{"iopub.execute_input":"2023-03-19T07:21:25.308039Z","iopub.status.busy":"2023-03-19T07:21:25.307245Z","iopub.status.idle":"2023-03-19T07:21:27.187141Z","shell.execute_reply":"2023-03-19T07:21:27.186043Z","shell.execute_reply.started":"2023-03-19T07:21:25.307998Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# rect_list = [(1100, 3500, 700, 950), \n","#             (1403, 7115, 1660, 1142), \n","#              (1310, 4554, 860, 930)]\n","\n","rect_list = [(1100, 3500, 700, 950)]\n","if IS_TRAIN:\n","    for i in range(len(lable_list)):\n","        rect = rect_list[i]\n","        fig, ax = plt.subplots()\n","        ax.imshow(lable_list[i].cpu())\n","        patch = patches.Rectangle((rect[0], rect[1]), rect[2], rect[3], linewidth=2, edgecolor='r', facecolor='none')\n","        ax.add_patch(patch)\n","        plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"456fbd67-b8ed-4622-925a-3efc9fb7eb4a","_uuid":"4061cd69-3dd7-495c-838f-17280c1041b2","trusted":true},"source":["Now we'll define a PyTorch dataset and (super simple) model."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"25930dc1-1883-4fcd-9d40-f4aaa2ca152b","_kg_hide-output":true,"_uuid":"9cf6abaa-b06b-4d05-a6d8-b7f012cf2e2c","collapsed":false,"execution":{"iopub.execute_input":"2023-03-19T07:21:27.189440Z","iopub.status.busy":"2023-03-19T07:21:27.188760Z","iopub.status.idle":"2023-03-19T07:21:27.197989Z","shell.execute_reply":"2023-03-19T07:21:27.196895Z","shell.execute_reply.started":"2023-03-19T07:21:27.189397Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class SubvolumeDataset(data.Dataset):\n","    def __init__(self, image_stack, label, pixels, is_train):\n","        self.image_stack = image_stack\n","        self.label = label\n","        self.pixels = pixels\n","        self.is_train = is_train\n","    def __len__(self):\n","        return len(self.pixels)\n","    def __getitem__(self, index):\n","        y, x = self.pixels[index]\n","        subvolume = self.image_stack[:, y-BUFFER:y+BUFFER, x-BUFFER:x+BUFFER].view(1, Z_DIM, BUFFER*2, BUFFER*2)\n","        if self.is_train:\n","            inklabel = self.label[y, x].view(1)\n","            return subvolume, inklabel\n","        else:\n","            return subvolume\n","# IOU and Dice Score\n","def dice_coef(y_true, y_pred, thr=0.5, dim=(0, 1), epsilon=0.001):\n","    y_true = y_true.to(torch.float32)\n","    y_pred = (y_pred > thr).to(torch.float32)\n","    inter = (y_true * y_pred).sum(dim=dim)\n","    den = y_true.sum(dim=dim) + y_pred.sum(dim=dim)\n","    dice = ((2 * inter + epsilon) / (den + epsilon)).mean()\n","    return dice\n","\n","\n","def iou_coef(y_true, y_pred, thr=0.5, dim=(0, 1), epsilon=0.001):\n","    y_true = y_true.to(torch.float32)\n","    y_pred = (y_pred > thr).to(torch.float32)\n","    inter = (y_true * y_pred).sum(dim=dim)\n","    union = (y_true + y_pred - y_true * y_pred).sum(dim=dim)\n","    iou = ((inter + epsilon) / (union + epsilon)).mean()\n","    return iou\n","\n","# model = nn.Sequential(\n","#     nn.Conv3d(1, 16, 3, 1, 1), nn.MaxPool3d(2, 2),\n","#     nn.Conv3d(16, 32, 3, 1, 1), nn.MaxPool3d(2, 2),\n","#     nn.Conv3d(32, 64, 3, 1, 1), nn.MaxPool3d(2, 2),\n","#     nn.Flatten(start_dim=1),\n","#     nn.LazyLinear(128), nn.ReLU(),\n","#     nn.LazyLinear(1), nn.Sigmoid()\n","# ).to(DEVICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-19T07:21:27.201325Z","iopub.status.busy":"2023-03-19T07:21:27.200972Z","iopub.status.idle":"2023-03-19T07:21:27.221232Z","shell.execute_reply":"2023-03-19T07:21:27.220146Z","shell.execute_reply.started":"2023-03-19T07:21:27.201284Z"},"trusted":true},"outputs":[],"source":["def pair(t):\n","    return t if isinstance(t, tuple) else (t, t)\n","\n","\n","# classes\n","\n","class PreNorm(nn.Module):\n","    def __init__(self, dim, fn):\n","        super().__init__()\n","        self.norm = nn.LayerNorm(dim)\n","        self.fn = fn\n","\n","    def forward(self, x, **kwargs):\n","        return self.fn(self.norm(x), **kwargs)\n","\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, dim, hidden_dim, dropout=0.):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_dim, dim),\n","            nn.Dropout(dropout)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","\n","class Attention(nn.Module):\n","    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n","        super().__init__()\n","        inner_dim = dim_head * heads\n","        project_out = not (heads == 1 and dim_head == dim)\n","\n","        self.heads = heads\n","        self.scale = dim_head ** -0.5\n","\n","        self.attend = nn.Softmax(dim=-1)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n","\n","        self.to_out = nn.Sequential(\n","            nn.Linear(inner_dim, dim),\n","            nn.Dropout(dropout)\n","        ) if project_out else nn.Identity()\n","\n","    def forward(self, x):\n","        qkv = self.to_qkv(x).chunk(3, dim=-1)\n","        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n","\n","        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n","\n","        attn = self.attend(dots)\n","        attn = self.dropout(attn)\n","\n","        out = torch.matmul(attn, v)\n","        out = rearrange(out, 'b h n d -> b n (h d)')\n","        return self.to_out(out)\n","class ResNetBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super(ResNetBlock, self).__init__()\n","        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm3d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.stride = stride\n","\n","        if in_channels != out_channels or stride != 1:\n","            self.shortcut = nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n","            self.bn_shortcut = nn.BatchNorm3d(out_channels)\n","        else:\n","            self.shortcut = nn.Identity()\n","            self.bn_shortcut = None\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","\n","        identity = self.shortcut(identity)\n","        if self.bn_shortcut is not None:\n","            identity = self.bn_shortcut(identity)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","class ResNet3D(nn.Module):\n","    def __init__(self, block, layers, num_classes=10, depth=6, dim=64, mlp_dim=512, heads=8, dim_head=64, dropout=0.1):\n","        super(ResNet3D, self).__init__()\n","        self.in_channels = 8\n","\n","        self.conv1 = nn.Conv3d(1, 8, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm3d(8)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.layer1 = self.make_layer(block, 8, layers[0])\n","        self.layer2 = self.make_layer(block, 16, layers[1], stride=2)\n","        self.layer3 = self.make_layer(block, 32, layers[2], stride=2)\n","        # self.layer4 = self.make_layer(block, 64, layers[3], stride=2)\n","        \n","        self.to_patch_embedding = Rearrange('b c t (h p1) (w p2) -> b (h w) (p1 p2 c t)', p1=1, p2=1)\n","        self.layers = nn.ModuleList([])\n","        for _ in range(depth):\n","            self.layers.append(nn.ModuleList([\n","                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n","                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n","            ]))\n","        self.pool = 'mean'\n","        # self.flatten = nn.Flatten(start_dim=1)\n","        self.linear1 = nn.LazyLinear(256)\n","        self.relu1 = nn.ReLU()\n","        self.linear2 = nn.LazyLinear(128)\n","        self.relu2 = nn.ReLU()\n","        self.linear3 = nn.LazyLinear(num_classes)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def make_layer(self, block, out_channels, blocks, stride=1):\n","        layers = []\n","        layers.append(block(self.in_channels, out_channels, stride))\n","        self.in_channels = out_channels\n","\n","        for i in range(1, blocks):\n","            layers.append(block(out_channels, out_channels))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        # x = self.layer4(x)\n","\n","        x = self.to_patch_embedding(x)\n","\n","        for attn, ff in self.layers:\n","            x = attn(x) + x\n","            x = ff(x) + x\n","        x = x.mean(dim=1) if self.pool == 'mean' else x[:, 0]\n","\n","        x = self.linear1(x)\n","        x = self.relu1(x)\n","        x = self.linear2(x)\n","        x = self.relu2(x)\n","        x = self.linear3(x)\n","        x = self.sigmoid(x)\n","\n","        return x"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"e7b84e1e-7903-4290-9e09-3bf2cb62b222","_uuid":"cfbc9413-b6ff-4a69-ae60-22dddef18f11","trusted":true},"source":["Now we'll train the model. Conceptually it looks like this:\n","\n","<a href=\"https://user-images.githubusercontent.com/22727759/224853655-3fad9edb-c798-452e-94d0-f74efe71c08e.mp4\"><img src=\"https://user-images.githubusercontent.com/22727759/224853385-ed190d89-f466-469c-82a9-499881759d57.gif\"/></a>\n","\n","This typically takes about 10 minutes."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-19T07:21:27.223154Z","iopub.status.busy":"2023-03-19T07:21:27.222612Z","iopub.status.idle":"2023-03-19T07:22:04.777006Z","shell.execute_reply":"2023-03-19T07:22:04.775953Z","shell.execute_reply.started":"2023-03-19T07:21:27.223117Z"},"trusted":true},"outputs":[],"source":["if IS_TRAIN:    \n","    print(\"Generating pixel lists of train...\")\n","    # Split our dataset into train and val. The pixels inside the rect are the \n","    # val set, and the pixels outside the rect are the train set.\n","    # 直接加载全部显存会爆炸, 放在train里面单独加载\n","    pixels_inside_rect_list = []\n","    pixels_outside_rect_list = []\n","    for i in range(len(mask_list)):\n","        pixels_inside_rect = []\n","        pixels_outside_rect = []\n","        for pixel in zip(*np.where(mask_list[i] == 1)):\n","            if pixel[1] < BUFFER or pixel[1] > mask_list[i].shape[1]-BUFFER or pixel[0] < BUFFER or pixel[0] > mask_list[i].shape[0]-BUFFER:\n","                continue # Too close to the edge\n","            if pixel[1] >= rect_list[i][0] and pixel[1] <= rect_list[i][0]+rect_list[i][2] and pixel[0] >= rect_list[i][1] and pixel[0] <= rect_list[i][1]+rect_list[i][3]:\n","                pixels_inside_rect.append(pixel)\n","            else:\n","                pixels_outside_rect.append(pixel)\n","        pixels_inside_rect_list.append(pixels_inside_rect)\n","        pixels_outside_rect_list.append(pixels_outside_rect)\n","\n","else:\n","    print(\"Generating pixel lists of test...\")\n","    # test不需要分割，取mask内的全部\n","    pixels_test_rect_list = []\n","    for i in range(len(test_mask_list)):\n","        pixels_test_rect = []\n","        for pixel in zip(*np.where(test_mask_list[i] == 1)):\n","            if pixel[1] < BUFFER or pixel[1] > test_mask_list[i].shape[1]-BUFFER or pixel[0] < BUFFER or pixel[0] > test_mask_list[i].shape[0]-BUFFER:\n","                continue # Too close to the edge\n","            pixels_test_rect.append(pixel)\n","        pixels_test_rect_list.append(pixels_test_rect)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-19T07:22:04.779128Z","iopub.status.busy":"2023-03-19T07:22:04.778480Z","iopub.status.idle":"2023-03-19T07:22:06.646772Z","shell.execute_reply":"2023-03-19T07:22:06.645661Z","shell.execute_reply.started":"2023-03-19T07:22:04.779088Z"},"trusted":true},"outputs":[],"source":["model = ResNet3D(block=ResNetBlock, layers=[1,2,3], num_classes=1).to(DEVICE)\n","model_name = 'ResNet3D'\n","if FT:\n","    try:\n","        checkpoint = torch.load(CHEPOINT, map_location=DEVICE)\n","        models_dict = model.state_dict()\n","        for model_part in models_dict:\n","            if model_part in checkpoint:\n","                models_dict[model_part] = checkpoint[model_part]\n","        model.load_state_dict(models_dict)\n","        print('Checkpoint loaded')\n","    except:\n","        print('Checkpoint not loaded')\n","        pass"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"790108d2-5260-4276-9105-9da5a27c28f5","_uuid":"29fb8028-1ec5-42fb-b61a-658e1181c951","execution":{"iopub.execute_input":"2023-03-19T07:22:06.650589Z","iopub.status.busy":"2023-03-19T07:22:06.649965Z","iopub.status.idle":"2023-03-19T07:22:06.662667Z","shell.execute_reply":"2023-03-19T07:22:06.661396Z","shell.execute_reply.started":"2023-03-19T07:22:06.650559Z"},"trusted":true},"outputs":[],"source":["if IS_TRAIN:\n","    # 实例化SummaryWriter对象\n","    torch.cuda.empty_cache()\n","    writer = SummaryWriter('result/logs')\n","    EPOCH = 10\n","    T_max = int(30000 / BATCH_SIZE * EPOCH) + 50\n","    min_lr = 0.000001\n","    print('''\n","    Starting training:\n","        Model: {}\n","        Epochs: {}\n","        Batch size: {}\n","        Learning rate: {}\n","        Training Step: {}\n","        CUDA: {}\n","    '''.format(model_name,\n","               EPOCH,\n","               BATCH_SIZE,\n","               LEARNING_RATE,\n","               TRAINING_STEPS,\n","               DEVICE.type))\n","    criterion = nn.BCELoss()\n","    optimizer = optim.AdamW(model.parameters(),\n","                            lr=LEARNING_RATE,\n","                            betas=(0.9, 0.999),\n","                            weight_decay=0.001\n","                            )\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max, eta_min=min_lr)\n","    max_memory = torch.cuda.max_memory_allocated(device=DEVICE) / 1E9 if torch.cuda.is_available() else 0\n","    # epoch_bar = tqdm(range(EPOCH), total=EPOCH)\n","    iter = 0\n","    for epoch in range(EPOCH):\n","        # 循环训练 1~3中的数据，每轮数据只抽取了TRAINING_STEPS的长度，也可以全部加入\n","        for index in range(len(image_stack_list)):\n","            # 加载数据\n","            image_stack, pixels_inside_rect, pixels_outside_rect = image_stack_list[index], pixels_inside_rect_list[index], pixels_outside_rect_list[index]\n","\n","            train_dataset = SubvolumeDataset(image_stack, lable_list[index], pixels_outside_rect, IS_TRAIN)\n","            eval_dataset = SubvolumeDataset(image_stack, lable_list[index], pixels_inside_rect, IS_TRAIN)\n","            train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","            eval_loader = data.DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","            epoch_loss = 0\n","            model.train()\n","            # TRAINING_STEPS = len(train_loader)\n","            bar = tqdm(enumerate(train_loader), total=TRAINING_STEPS) \n","            for i, (subvolumes, inklabels) in bar:\n","                if i >= TRAINING_STEPS:\n","                    break\n","                optimizer.zero_grad()\n","                outputs = model(subvolumes.to(DEVICE))\n","                loss = criterion(outputs, inklabels.to(DEVICE))\n","                loss.backward()\n","                optimizer.step()\n","                scheduler.step()\n","                mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","                bar.set_postfix(loss=f'{loss.item():0.4f}', epoch=iter, dataset=str(index + 1) ,gpu_mem=f'{mem:0.2f} GB')\n","                epoch_loss += loss.item()\n","            #     for j, pred_value in enumerate(outputs):\n","            #         output[pixels_outside_rect[i*BATCH_SIZE+j]] = pred_value\n","            # # 使用make_grid将图片转换成网格形式，这里是每训练SUMMERY_SIZE步就会把结果打印在tensorboard中\n","            # pred_mask = make_grid(output.to(DEVICE), normalize=True)\n","            # true_mask = make_grid(lable_list[index].to(DEVICE), normalize=True)\n","            # 使用add_image方法将图片添加到TensorBoard中\n","            # writer.add_image('Train/True_mask', true_mask, global_step=epoch, dataformats=\"CHW\")\n","            # writer.add_image('Train/Pred_mask', pred_mask, global_step=epoch, dataformats=\"CHW\")\n","            iter += 1\n","            writer.add_scalar('Train/Loss', epoch_loss / TRAINING_STEPS, iter)\n","            output = torch.zeros_like(lable_list[index]).float()\n","            true = torch.zeros_like(lable_list[index]).float()\n","            model.eval()\n","            with torch.no_grad():\n","                for i, (subvolumes, inklabels) in enumerate(tqdm(eval_loader)):\n","                    outputs = model(subvolumes.to(DEVICE))\n","                    for j, (value, true_value) in enumerate(zip(outputs, inklabels)):\n","                        output[pixels_inside_rect[i*BATCH_SIZE+j]] = value\n","                        true[pixels_inside_rect[i*BATCH_SIZE+j]] = true_value\n","\n","                # 计算准确率\n","                dice_score = dice_coef(true.to(DEVICE), output.to(DEVICE), thr=THRESHOLD).item()\n","                iou_socre = iou_coef(true.to(DEVICE), output.to(DEVICE), thr=THRESHOLD).item()\n","                        \n","                # 使用make_grid将图片转换成网格形式\n","                pred_mask = make_grid(output.to(DEVICE), normalize=True)\n","                true_mask = make_grid(true.to(DEVICE), normalize=True)\n","                # 使用add_image方法将图片添加到TensorBoard中\n","                writer.add_image('Valid/True_mask', true_mask, global_step=iter, dataformats=\"CHW\")\n","                writer.add_image('Valid/Pred_mask', pred_mask, global_step=iter, dataformats=\"CHW\")\n","\n","                # fig, (ax1, ax2) = plt.subplots(1, 2)\n","                # ax1.imshow(output.cpu(), cmap='gray')\n","                # ax2.imshow(label.cpu(), cmap='gray')\n","                # plt.show()\n","                writer.add_scalar('Val/IOU', iou_socre,  iter)\n","                writer.add_scalar('Val/Dice', dice_score,  iter)\n","            import gc\n","            gc.collect()\n","            torch.cuda.empty_cache()\n","            torch.save(model.state_dict(), 'result/' +  '{}-DIM-{}-[train_loss]-{:.2f}-[dice_score]-{:.2f}-[iou_score]-{:.2f}-'.format(model_name, Z_DIM ,epoch_loss / TRAINING_STEPS, dice_score, iou_socre) + str(iter) + '-epoch.pkl')\n","    writer.close()"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"3c6ad763-f47c-4aaa-8c12-cb95c2d28d74","_uuid":"8edfa121-b2ef-419e-acbe-6d430fb50133","trusted":true},"source":["Finally, we'll generate a prediction image. We'll use the model to predict the presence of ink for each pixel in our rectangle (the val set). Conceptually it looks like this:\n","\n","<a href=\"https://user-images.githubusercontent.com/22727759/224853653-7cffd0a4-c6fa-49a2-93c1-e3c820863a51.mp4\"><img src=\"https://user-images.githubusercontent.com/22727759/224853379-09ae991e-02be-4ecc-a652-313165b3005c.gif\"/></a>\n","\n","\n","This should take about a minute.\n","\n","Remember that the model has never seen the label data within the rectangle before!\n","\n","We'll plot it side-by-side with the label image. Are you able to recognize the letter \"P\" in it?"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"56812c41-904d-4645-bddf-49b19fe2685d","_uuid":"68013338-2e52-4f0b-b15b-b18e071aa5da","collapsed":false,"execution":{"iopub.execute_input":"2023-03-19T07:25:33.475121Z","iopub.status.busy":"2023-03-19T07:25:33.474728Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["if not IS_TRAIN:\n","    output_list = []\n","    for index in range(len(test_image_stack_list)):\n","        test_dataset = SubvolumeDataset(test_image_stack_list[index], None, pixels_test_rect_list[index], IS_TRAIN)\n","        test_eval_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","        output = torch.zeros_like(shape_list[index]).float()\n","        model.eval()\n","        with torch.no_grad():\n","            for i, (subvolumes) in enumerate(tqdm(test_eval_loader)):\n","                for j, value in enumerate(model(subvolumes.to(DEVICE))):\n","                    output[pixels_test_rect_list[index][i*BATCH_SIZE+j]] = value\n","            output_list.append(output)\n","            out = output_list[index].gt(THRESHOLD).cpu().float().numpy()\n","            import cv2\n","            cv2.imwrite(str(index + 1) + '.png', out * 255)\n","    fig, (ax1, ax2) = plt.subplots(1, 2)\n","    ax1.imshow(output_list[0].gt(THRESHOLD).cpu(), cmap='gray')\n","    ax1.imshow(output_list[1].gt(THRESHOLD).cpu(), cmap='gray')\n","    plt.show()\n","    "]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"49b12c62-7143-4d27-be79-e20e8cd9f5fe","_uuid":"15c0a510-b4d1-4e14-974e-cbe5a7ac6b8e","trusted":true},"source":["Since our output has to be binary, we have to choose a threshold, say 40% confidence."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4f1a3ed4-43c8-4a9c-9f49-dab4d3047048","_uuid":"3eb989fa-2823-49f7-a55f-1e178884e344","collapsed":false,"execution":{"iopub.status.busy":"2023-03-19T07:22:28.186015Z","iopub.status.idle":"2023-03-19T07:22:28.186806Z","shell.execute_reply":"2023-03-19T07:22:28.186565Z","shell.execute_reply.started":"2023-03-19T07:22:28.186538Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["if IS_TRAIN:\n","    fig, (ax1, ax2) = plt.subplots(1, 2)\n","    ax1.imshow(output.gt(THRESHOLD).cpu(), cmap='gray')\n","    ax2.imshow(label.cpu(), cmap='gray')\n","    plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"df73edb8-b09d-4e84-b33a-b384dbe486fe","_uuid":"04dc6e9a-5178-4ffa-95b3-a64783d4cf1a","trusted":true},"source":["Finally, Kaggle expects a runlength-encoded submission.csv file, so let's output that."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79b4b495-2e93-49ba-b9d8-434dccf49907","_uuid":"512cd6ab-2794-4ad3-87cc-fc240561f286","collapsed":false,"execution":{"iopub.status.busy":"2023-03-19T07:22:28.188296Z","iopub.status.idle":"2023-03-19T07:22:28.189057Z","shell.execute_reply":"2023-03-19T07:22:28.188810Z","shell.execute_reply.started":"2023-03-19T07:22:28.188784Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def rle(output):\n","    flat_img = np.where(output.flatten().cpu() > THRESHOLD, 1, 0).astype(np.uint8)\n","    starts = np.array((flat_img[:-1] == 0) & (flat_img[1:] == 1))\n","    ends = np.array((flat_img[:-1] == 1) & (flat_img[1:] == 0))\n","    starts_ix = np.where(starts)[0] + 2\n","    ends_ix = np.where(ends)[0] + 2\n","    lengths = ends_ix - starts_ix\n","    return \" \".join(map(str, sum(zip(starts_ix, lengths), ())))\n","# rle_output = rle(output)\n","# This doesn't make too much sense, but let's just output in the required format\n","# so notebook works as a submission. :-)\n","# print(\"Id,Predicted\\na,\" + rle_output + \"\\nb,\" + rle_output, file=open('submission.csv', 'w'))"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"799ddbd9-6862-4a43-9ae4-3c2d2f01da85","_uuid":"e84d0aa9-a297-4a90-b4f2-a8afb7c389c5","trusted":true},"source":["Hurray! We've detected ink! Now, can you do better? :-) For example, you could start with this [example submission](https://www.kaggle.com/code/danielhavir/vesuvius-challenge-example-submission)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-03-19T07:22:28.190428Z","iopub.status.idle":"2023-03-19T07:22:28.191183Z","shell.execute_reply":"2023-03-19T07:22:28.190951Z","shell.execute_reply.started":"2023-03-19T07:22:28.190926Z"},"trusted":true},"outputs":[],"source":["rle_list = []\n","for output in outputs:\n","    rle_sample = rle(output)\n","    rle_list.append(rle_sample)\n","print(\"Id,Predicted\\na,\" + rle_list[0] + \"\\nb,\" + rle_list[1], file=open('submission.csv', 'w'))"]}],"metadata":{"kernelspec":{"display_name":"dtt","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"61166640a95ac08c4dfcc44984648f9045f44ea39ff0c31cc75bc4fde1586daf"}}},"nbformat":4,"nbformat_minor":4}
