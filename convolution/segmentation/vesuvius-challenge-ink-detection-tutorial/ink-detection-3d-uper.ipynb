{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stu/anaconda3/envs/dtt/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from mmcv.cnn import ConvModule\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torchvision.utils import make_grid\n",
    "import warnings\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "# 忽略所有警告\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class CFG:\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    checpoint = ''\n",
    "    # ============== comp exp name =============\n",
    "    comp_name = 'vesuvius'\n",
    "\n",
    "    # # comp_dir_path = './'\n",
    "    # comp_dir_path = '/kaggle/input/'\n",
    "    # comp_folder_name = 'vesuvius-challenge-ink-detection'\n",
    "    # # comp_dataset_path = f'{comp_dir_path}datasets/{comp_folder_name}/'\n",
    "    # comp_dataset_path = f'{comp_dir_path}{comp_folder_name}/'\n",
    "        # comp_dir_path = './'\n",
    "    comp_dir_path = ''\n",
    "    comp_folder_name = 'data'\n",
    "    # comp_dataset_path = f'{comp_dir_path}datasets/{comp_folder_name}/'\n",
    "    comp_dataset_path = f'{comp_dir_path}{comp_folder_name}/'\n",
    "\n",
    "    img_path = 'working/'\n",
    "    \n",
    "    exp_name = 'Resnet3D'\n",
    "\n",
    "    # ============== pred target =============\n",
    "    target_size = 1\n",
    "\n",
    "    # ============== model cfg =============\n",
    "    model_name = 'Resnet3D'\n",
    "\n",
    "    # in_idx = [i for i in range(12, 25)]\n",
    "    # up = [i for i in range(28, 37)]\n",
    "\n",
    "    # in_idx.extend(up)\n",
    "    in_idx = [i for i in range(21, 43)]\n",
    "\n",
    "    backbone = 'Resnet3D'\n",
    "\n",
    "    valid_id = 3\n",
    "\n",
    "\n",
    "    in_chans =  len(in_idx)# 65\n",
    "    # ============== training cfg =============\n",
    "    size = 224\n",
    "\n",
    "    train_tile_size_1 = 224\n",
    "    train_stride_1 = train_tile_size_1 // 4\n",
    "\n",
    "    train_tile_size_2 = 224\n",
    "    train_stride_2 = train_tile_size_2 // 2\n",
    "\n",
    "    train_tile_size_3 = 224\n",
    "    train_stride_3= train_tile_size_3 // 4\n",
    "\n",
    "    valid_tile_size = 224\n",
    "    valid_stride = valid_tile_size // 2\n",
    "\n",
    "    train_batch_size = 8 # 32\n",
    "    valid_batch_size = 8\n",
    "    use_amp = True\n",
    "\n",
    "    inplanes = [64, 128, 256, 512]\n",
    "\n",
    "    epochs = 30 # 30\n",
    "\n",
    "    # lr = 1e-4 / warmup_factor\n",
    "    lr = 5e-6\n",
    "\n",
    "    # ============== fixed =============\n",
    "    pretrained = False\n",
    "\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-4\n",
    "    max_grad_norm = 1000\n",
    "\n",
    "    num_workers = 4\n",
    "\n",
    "    seed = 42\n",
    "\n",
    "    threshhold = 0.5\n",
    "\n",
    "    all_best_dice = 0\n",
    "    all_best_loss = np.float('inf')\n",
    "\n",
    "    shape_list = []\n",
    "    test_shape_list = []\n",
    "\n",
    "    val_mask = None\n",
    "    val_label = None\n",
    "\n",
    "    # ============== augmentation =============\n",
    "    train_aug_list = [\n",
    "        # A.RandomCrop(height=size, width=size, p=0.5),\n",
    "        A.Resize(size, size),\n",
    "        A.Rotate(limit=90,  p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.75),\n",
    "        A.ShiftScaleRotate(p=0.75),\n",
    "        A.OneOf([\n",
    "                A.GaussNoise(var_limit=[10, 50]),\n",
    "                A.GaussianBlur(),\n",
    "                A.MotionBlur(),\n",
    "                ], p=0.4),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "        A.CoarseDropout(max_holes=1, max_width=int(size * 0.3), max_height=int(size * 0.3), \n",
    "                        mask_fill_value=0, p=0.5),\n",
    "        # A.ChannelShuffle(p=0.5),\n",
    "        # A.Cutout(max_h_size=int(size * 0.6),\n",
    "        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n",
    "        A.Normalize(\n",
    "            mean= [0] * in_chans,\n",
    "            std= [1] * in_chans\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "\n",
    "    valid_aug_list = [\n",
    "        A.Resize(size, size),\n",
    "        A.Normalize(\n",
    "            mean= [0] * in_chans,\n",
    "            std= [1] * in_chans\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    test_aug_list = [\n",
    "        A.Normalize(\n",
    "            mean= [0] * in_chans,\n",
    "            std= [1] * in_chans\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "seed = CFG.seed\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inplanes():\n",
    "    return [64, 128, 256, 512]\n",
    "\n",
    "\n",
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=3,\n",
    "                     stride=stride,\n",
    "                     padding=1,\n",
    "                     bias=False)\n",
    "\n",
    "\n",
    "def conv1x1x1(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=1,\n",
    "                     stride=stride,\n",
    "                     bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv3x3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv1x1x1(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = conv3x3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = conv1x1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 block,\n",
    "                 layers,\n",
    "                 block_inplanes,\n",
    "                 n_input_channels=3,\n",
    "                 conv1_t_size=7,\n",
    "                 conv1_t_stride=1,\n",
    "                 shortcut_type='B',\n",
    "                 widen_factor=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        block_inplanes = [int(x * widen_factor) for x in block_inplanes]\n",
    "\n",
    "        self.in_planes = block_inplanes[0]\n",
    "\n",
    "        self.conv1 = nn.Conv3d(n_input_channels,\n",
    "                               self.in_planes,\n",
    "                               kernel_size=(conv1_t_size, 7, 7),\n",
    "                               stride=(conv1_t_stride, 2, 2),\n",
    "                               padding=(conv1_t_size // 2, 3, 3),\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(self.in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
    "        self.layer1 = self._make_layer(block,\n",
    "                                       block_inplanes[0],\n",
    "                                       layers[0],\n",
    "                                       shortcut_type,\n",
    "                                       stride=(1, 1, 1),\n",
    "                                       downsample=False)\n",
    "        self.layer2 = self._make_layer(block,\n",
    "                                       block_inplanes[1],\n",
    "                                       layers[1],\n",
    "                                       shortcut_type,\n",
    "                                       stride=(1, 2, 2),\n",
    "                                       downsample=True)\n",
    "        self.layer3 = self._make_layer(block,\n",
    "                                       block_inplanes[2],\n",
    "                                       layers[2],\n",
    "                                       shortcut_type,\n",
    "                                       stride=(1, 2, 2),\n",
    "                                       downsample=True)\n",
    "        self.layer4 = self._make_layer(block,\n",
    "                                       block_inplanes[3],\n",
    "                                       layers[3],\n",
    "                                       shortcut_type,\n",
    "                                       stride=(1, 2, 2),\n",
    "                                       downsample=True)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool3d(kernel_size=(CFG.in_chans, 1, 1), stride=1, padding=0)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight,\n",
    "                                        mode='fan_out',\n",
    "                                        nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _downsample_basic_block(self, x, planes, stride):\n",
    "        out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "        zero_pads = torch.zeros(out.size(0), planes - out.size(1), out.size(2),\n",
    "                                out.size(3), out.size(4))\n",
    "        if isinstance(out.data, torch.cuda.FloatTensor):\n",
    "            zero_pads = zero_pads.cuda()\n",
    "\n",
    "        out = torch.cat([out.data, zero_pads], dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, shortcut_type, stride, downsample):\n",
    "        downsample_block = None\n",
    "        if downsample:\n",
    "            if shortcut_type == 'A':\n",
    "                downsample_block = partial(self._downsample_basic_block,\n",
    "                                     planes=planes * block.expansion,\n",
    "                                     stride=stride)\n",
    "            else:\n",
    "                downsample_block = nn.Sequential(\n",
    "                    conv1x1x1(self.in_planes, planes * block.expansion, stride),\n",
    "                    nn.BatchNorm3d(planes * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(in_planes=self.in_planes,\n",
    "                  planes=planes,\n",
    "                  stride=stride,\n",
    "                  downsample=downsample_block))\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        x4 = self.layer4(x3)\n",
    "\n",
    "        x1 = self.avg_pool(x1).squeeze(2)\n",
    "        x2 = self.avg_pool(x2).squeeze(2)\n",
    "        x3 = self.avg_pool(x3).squeeze(2)\n",
    "        x4 = self.avg_pool(x4).squeeze(2)\n",
    "\n",
    "        return [x1, x2, x3, x4]\n",
    "\n",
    "\n",
    "def generate_model(model_depth, **kwargs):\n",
    "    assert model_depth in [10, 18, 34, 50, 101, 152, 200]\n",
    "\n",
    "    if model_depth == 10:\n",
    "        model = ResNet(BasicBlock, [1, 1, 1, 1], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 18:\n",
    "        model = ResNet(BasicBlock, [2, 2, 2, 2], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 34:\n",
    "        model = ResNet(BasicBlock, [3, 4, 6, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 50:\n",
    "        model = ResNet(Bottleneck, [3, 4, 6, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 101:\n",
    "        model = ResNet(Bottleneck, [3, 4, 23, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 152:\n",
    "        model = ResNet(Bottleneck, [3, 8, 36, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 200:\n",
    "        model = ResNet(Bottleneck, [3, 24, 36, 3], get_inplanes(), **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "def resize(input,\n",
    "           size=None,\n",
    "           scale_factor=None,\n",
    "           mode='nearest',\n",
    "           align_corners=None,\n",
    "           warning=True):\n",
    "    if warning:\n",
    "        if size is not None and align_corners:\n",
    "            input_h, input_w = tuple(int(x) for x in input.shape[2:])\n",
    "            output_h, output_w = tuple(int(x) for x in size)\n",
    "            if output_h > input_h or output_w > output_h:\n",
    "                if ((output_h > 1 and output_w > 1 and input_h > 1\n",
    "                     and input_w > 1) and (output_h - 1) % (input_h - 1)\n",
    "                        and (output_w - 1) % (input_w - 1)):\n",
    "                    warnings.warn(\n",
    "                        f'When align_corners={align_corners}, '\n",
    "                        'the output would more aligned if '\n",
    "                        f'input size {(input_h, input_w)} is `x+1` and '\n",
    "                        f'out size {(output_h, output_w)} is `nx+1`')\n",
    "    return F.interpolate(input, size, scale_factor, mode, align_corners)\n",
    "\n",
    "class PPM(nn.ModuleList):\n",
    "    \"\"\"Pooling Pyramid Module used in PSPNet.\n",
    "\n",
    "    Args:\n",
    "        pool_scales (tuple[int]): Pooling scales used in Pooling Pyramid\n",
    "            Module.\n",
    "        in_channels (int): Input channels.\n",
    "        channels (int): Channels after modules, before conv_seg.\n",
    "        conv_cfg (dict|None): Config of conv layers.\n",
    "        norm_cfg (dict|None): Config of norm layers.\n",
    "        act_cfg (dict): Config of activation layers.\n",
    "        align_corners (bool): align_corners argument of F.interpolate.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pool_scales, in_channels, channels, conv_cfg, norm_cfg,\n",
    "                 act_cfg, align_corners, **kwargs):\n",
    "        super(PPM, self).__init__()\n",
    "        self.pool_scales = pool_scales\n",
    "        self.align_corners = align_corners\n",
    "        self.in_channels = in_channels\n",
    "        self.channels = channels\n",
    "        self.conv_cfg = conv_cfg\n",
    "        self.norm_cfg = norm_cfg\n",
    "        self.act_cfg = act_cfg\n",
    "        for pool_scale in pool_scales:\n",
    "            self.append(\n",
    "                nn.Sequential(\n",
    "                    nn.AdaptiveAvgPool2d(pool_scale),\n",
    "                    ConvModule(\n",
    "                        self.in_channels,\n",
    "                        self.channels,\n",
    "                        1,\n",
    "                        conv_cfg=self.conv_cfg,\n",
    "                        norm_cfg=self.norm_cfg,\n",
    "                        act_cfg=self.act_cfg,\n",
    "                        **kwargs)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function.\"\"\"\n",
    "        ppm_outs = []\n",
    "        for ppm in self:\n",
    "            ppm_out = ppm(x)\n",
    "            upsampled_ppm_out = resize(\n",
    "                ppm_out,\n",
    "                size=x.size()[2:],\n",
    "                mode='bilinear',\n",
    "                align_corners=self.align_corners)\n",
    "            ppm_outs.append(upsampled_ppm_out)\n",
    "        return ppm_outs\n",
    "class UPerHead(nn.Module):\n",
    "    \"\"\"Unified Perceptual Parsing for Scene Understanding.\n",
    "\n",
    "    This head is the implementation of `UPerNet\n",
    "    <https://arxiv.org/abs/1807.10221>`_.\n",
    "\n",
    "    Args:\n",
    "        pool_scales (tuple[int]): Pooling scales used in Pooling Pyramid\n",
    "            Module applied on the last feature. Default: (1, 2, 3, 6).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                in_channels=[128, 256, 512, 1024],\n",
    "                in_index=[0, 1, 2, 3],\n",
    "                pool_scales=(1, 2, 3, 6),\n",
    "                channels=512,\n",
    "                dropout_ratio=0.1,\n",
    "                num_classes=0,\n",
    "                norm_cfg=dict(type='BN', requires_grad=True),\n",
    "                align_corners=False):\n",
    "        super(UPerHead, self).__init__()\n",
    "        # PSP Module\n",
    "        self.input_transform = 'multiple_select'\n",
    "        self.align_corners = align_corners\n",
    "        self.in_index = in_index\n",
    "        self.psp_modules = PPM(\n",
    "            pool_scales,\n",
    "            in_channels[-1],\n",
    "            channels,\n",
    "            conv_cfg=None,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=dict(type='ReLU'),\n",
    "            align_corners=align_corners)\n",
    "        self.bottleneck = ConvModule(\n",
    "            in_channels[-1] + len(pool_scales) * channels,\n",
    "            channels,\n",
    "            3,\n",
    "            padding=1,\n",
    "            conv_cfg=None,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=dict(type='ReLU'))\n",
    "        # FPN Module\n",
    "        self.lateral_convs = nn.ModuleList()\n",
    "        self.fpn_convs = nn.ModuleList()\n",
    "        for in_channel in in_channels[:-1]:  # skip the top layer\n",
    "            l_conv = ConvModule(\n",
    "                in_channel,\n",
    "                channels,\n",
    "                1,\n",
    "                conv_cfg=None,\n",
    "                norm_cfg=norm_cfg,\n",
    "                act_cfg=dict(type='ReLU'),\n",
    "                inplace=False)\n",
    "            fpn_conv = ConvModule(\n",
    "                channels,\n",
    "                channels,\n",
    "                3,\n",
    "                padding=1,\n",
    "                conv_cfg=None,\n",
    "                norm_cfg=norm_cfg,\n",
    "                act_cfg=dict(type='ReLU'),\n",
    "                inplace=False)\n",
    "            self.lateral_convs.append(l_conv)\n",
    "            self.fpn_convs.append(fpn_conv)\n",
    "\n",
    "        self.fpn_bottleneck = ConvModule(\n",
    "            len(in_channels) * channels,\n",
    "            channels,\n",
    "            3,\n",
    "            padding=1,\n",
    "            conv_cfg=None,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=dict(type='ReLU'))\n",
    "        if dropout_ratio > 0:\n",
    "            self.dropout = nn.Dropout2d(dropout_ratio)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        self.conv_seg = nn.Conv2d(channels, num_classes, kernel_size=1)\n",
    "\n",
    "    def psp_forward(self, inputs):\n",
    "        \"\"\"Forward function of PSP module.\"\"\"\n",
    "        x = inputs[-1]\n",
    "        psp_outs = [x]\n",
    "        psp_outs.extend(self.psp_modules(x))\n",
    "        psp_outs = torch.cat(psp_outs, dim=1)\n",
    "        output = self.bottleneck(psp_outs)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def _transform_inputs(self, inputs):\n",
    "        \"\"\"Transform inputs for decoder.\n",
    "\n",
    "        Args:\n",
    "            inputs (list[Tensor]): List of multi-level img features.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The transformed inputs\n",
    "        \"\"\"\n",
    "\n",
    "        if self.input_transform == 'resize_concat':\n",
    "            inputs = [inputs[i] for i in self.in_index]\n",
    "            upsampled_inputs = [\n",
    "                resize(\n",
    "                    input=x,\n",
    "                    size=inputs[0].shape[2:],\n",
    "                    mode='bilinear',\n",
    "                    align_corners=self.align_corners) for x in inputs\n",
    "            ]\n",
    "            inputs = torch.cat(upsampled_inputs, dim=1)\n",
    "        elif self.input_transform == 'multiple_select':\n",
    "            inputs = [inputs[i] for i in self.in_index]\n",
    "        else:\n",
    "            inputs = inputs[self.in_index]\n",
    "\n",
    "        return inputs\n",
    "    \n",
    "    def cls_seg(self, feat):\n",
    "        \"\"\"Classify each pixel.\"\"\"\n",
    "        if self.dropout is not None:\n",
    "            feat = self.dropout(feat)\n",
    "        output = self.conv_seg(feat)\n",
    "        return output\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward function.\"\"\"\n",
    "        inputs = self._transform_inputs(inputs)\n",
    "\n",
    "        # build laterals\n",
    "        laterals = [\n",
    "            lateral_conv(inputs[i]) for i, lateral_conv in enumerate(self.lateral_convs)\n",
    "        ]\n",
    "\n",
    "        laterals.append(self.psp_forward(inputs))\n",
    "\n",
    "        # build top-down path\n",
    "        used_backbone_levels = len(laterals)\n",
    "        for i in range(used_backbone_levels - 1, 0, -1):\n",
    "            prev_shape = laterals[i - 1].shape[2:]\n",
    "            laterals[i - 1] = laterals[i - 1] + resize(\n",
    "                laterals[i],\n",
    "                size=prev_shape,\n",
    "                mode='bilinear',\n",
    "                align_corners=self.align_corners)\n",
    "\n",
    "        # build outputs\n",
    "        fpn_outs = [\n",
    "            self.fpn_convs[i](laterals[i])\n",
    "            for i in range(used_backbone_levels - 1)\n",
    "        ]\n",
    "        # append psp feature\n",
    "        fpn_outs.append(laterals[-1])\n",
    "\n",
    "        for i in range(used_backbone_levels - 1, 0, -1):\n",
    "            fpn_outs[i] = resize(\n",
    "                fpn_outs[i],\n",
    "                size=fpn_outs[0].shape[2:],\n",
    "                mode='bilinear',\n",
    "                align_corners=self.align_corners)\n",
    "        fpn_outs = torch.cat(fpn_outs, dim=1)\n",
    "        output = self.fpn_bottleneck(fpn_outs)\n",
    "        output = self.cls_seg(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class InK3DUnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = generate_model(model_depth=18, n_input_channels=1)\n",
    "        self.decoder = UPerHead(in_channels=[64, 128, 256, 512],\n",
    "                                in_index=[0, 1, 2, 3],\n",
    "                                pool_scales=(1, 2, 3, 6),\n",
    "                                channels=512,\n",
    "                                dropout_ratio=0.1,\n",
    "                                num_classes=CFG.target_size,\n",
    "                                norm_cfg=dict(type='BN', requires_grad=True),\n",
    "                                align_corners=False)\n",
    "        self.up = nn.Upsample(scale_factor=4, mode=\"bilinear\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feat_maps = self.encoder(x)\n",
    "        pred_mask = self.decoder(feat_maps)\n",
    "        pred_mask = self.up(pred_mask)\n",
    "        return pred_mask\n",
    "    \n",
    "    def load_pretrained_weights(self, state_dict):\n",
    "        # Convert 3 channel weights to single channel\n",
    "        # ref - https://timm.fast.ai/models#Case-1:-When-the-number-of-input-channels-is-1\n",
    "        conv1_weight = state_dict['conv1.weight']\n",
    "        state_dict['conv1.weight'] = conv1_weight.sum(dim=1, keepdim=True)\n",
    "        print(self.encoder.load_state_dict(state_dict, strict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['fc.weight', 'fc.bias'])\n"
     ]
    }
   ],
   "source": [
    "model = InK3DUnet()\n",
    "model.load_pretrained_weights(torch.load(\"result/resnet3d-seg-2d/r3d18_K_200ep.pth\")[\"state_dict\"])\n",
    "model = model.to(CFG.device)\n",
    "model_name = CFG.model_name\n",
    "i = torch.ones(2, 1, 22, 224,224).cuda()\n",
    "o = model(i)\n",
    "if CFG.pretrained:\n",
    "    try:\n",
    "        checkpoint = torch.load(CFG.checpoint, map_location=CFG.device)\n",
    "        models_dict = model.state_dict()\n",
    "        for model_part in models_dict:\n",
    "            if model_part in checkpoint:\n",
    "                models_dict[model_part] = checkpoint[model_part]\n",
    "        model.load_state_dict(models_dict)\n",
    "        print('Checkpoint loaded')\n",
    "    except:\n",
    "        print('Checkpoint not loaded')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_mask(fragment_id, tile_size):\n",
    "\n",
    "    images = []\n",
    "\n",
    "    # idxs = range(65)\n",
    "    # mid = 65 // 2\n",
    "    # start = mid - CFG.in_chans // 2\n",
    "    # end = mid + CFG.in_chans // 2\n",
    "    # idxs = range(start, end)\n",
    "    idxs = CFG.in_idx\n",
    "\n",
    "    for i in tqdm(idxs):\n",
    "        \n",
    "        image = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/surface_volume/{i:02}.tif\", 0)\n",
    "\n",
    "        pad0 = (tile_size - image.shape[0] % tile_size)\n",
    "        pad1 = (tile_size - image.shape[1] % tile_size)\n",
    "\n",
    "        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "\n",
    "        images.append(image)\n",
    "    images = np.stack(images, axis=2)\n",
    "\n",
    "    mask = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/inklabels.png\", 0)\n",
    "    mask = np.pad(mask, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "\n",
    "    mask = mask.astype('float32')\n",
    "    mask /= 255.0\n",
    "\n",
    "    mask_location = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/mask.png\", 0)\n",
    "    mask_location = np.pad(mask_location, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "\n",
    "    mask_location = mask_location / 255\n",
    "    \n",
    "    return images, mask, mask_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_dataset():\n",
    "    train_images = []\n",
    "    train_masks = []\n",
    "\n",
    "    valid_images = []\n",
    "    valid_masks = []\n",
    "    valid_xyxys = []\n",
    "\n",
    "    for fragment_id in range(1, 4):\n",
    "        \n",
    "        if fragment_id == 1:\n",
    "            tile_size = CFG.train_tile_size_1\n",
    "            stride = CFG.train_stride_1\n",
    "        elif fragment_id == 2:\n",
    "            tile_size = CFG.train_tile_size_2\n",
    "            stride = CFG.train_stride_2\n",
    "        else:\n",
    "            tile_size = CFG.train_tile_size_3\n",
    "            stride = CFG.train_stride_3\n",
    "\n",
    "        if fragment_id == CFG.valid_id:\n",
    "            tile_size = CFG.valid_tile_size\n",
    "            stride = CFG.valid_stride\n",
    "            \n",
    "        image, mask, mask_location = read_image_mask(fragment_id, tile_size)\n",
    "        x1_list = list(range(0, image.shape[1]-tile_size+1, stride))\n",
    "        y1_list = list(range(0, image.shape[0]-tile_size+1, stride))\n",
    "\n",
    "        for y1 in y1_list:\n",
    "            for x1 in x1_list:\n",
    "                y2 = y1 + tile_size\n",
    "                x2 = x1 + tile_size\n",
    "                if np.sum(mask_location[y1:y2, x1:x2]) == 0:\n",
    "                    continue\n",
    "        \n",
    "                if fragment_id == CFG.valid_id:\n",
    "                    if CFG.valid_id  == 2:\n",
    "                        if  y2 <4800 or y2 > 4800 + 4096 + 2048 or x2 > 640+ 4096 +2048 or x2 < 640:\n",
    "                            continue\n",
    "                    valid_images.append(image[y1:y2, x1:x2])\n",
    "                    valid_masks.append(mask[y1:y2, x1:x2, None])\n",
    "\n",
    "                    valid_xyxys.append([x1, y1, x2, y2])\n",
    "                else:\n",
    "                    train_images.append(image[y1:y2, x1:x2])\n",
    "                    train_masks.append(mask[y1:y2, x1:x2, None])\n",
    "\n",
    "    return train_images, train_masks, valid_images, valid_masks, valid_xyxys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(data, cfg):\n",
    "    if data == 'train':\n",
    "        aug = A.Compose(cfg.train_aug_list)\n",
    "    elif data == 'valid':\n",
    "        aug = A.Compose(cfg.valid_aug_list)\n",
    "\n",
    "    # print(aug)\n",
    "    return aug\n",
    "\n",
    "class Ink_Detection_Dataset(data.Dataset):\n",
    "    def __init__(self, images, cfg, labels=None, transform=None):\n",
    "        self.images = images\n",
    "        self.cfg = cfg\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len(self.df)\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(image=image, mask=label)\n",
    "            image = data['image'].unsqueeze(0)\n",
    "            label = data['mask']\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:08<00:00,  2.67it/s]\n",
      "100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.35it/s]\n"
     ]
    }
   ],
   "source": [
    "train_images, train_masks, valid_images, valid_masks, valid_xyxys = get_train_valid_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_xyxys = np.stack(valid_xyxys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Ink_Detection_Dataset(\n",
    "    train_images, CFG, labels=train_masks, transform=get_transforms(data='train', cfg=CFG))\n",
    "valid_dataset = Ink_Detection_Dataset(\n",
    "    valid_images, CFG, labels=valid_masks, transform=get_transforms(data='valid', cfg=CFG))\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset,\n",
    "                          batch_size=CFG.train_batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=CFG.num_workers, pin_memory=True, drop_last=True,\n",
    "                          )\n",
    "valid_loader = data.DataLoader(valid_dataset,\n",
    "                          batch_size=CFG.valid_batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "\n",
    "class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/code/underwearfitting/single-fold-training-of-resnet200d-lb0-965\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV2, self).__init__(\n",
    "            optimizer, multiplier, total_epoch, after_scheduler)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [\n",
    "                        base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n",
    "\n",
    "def get_scheduler(cfg, optimizer):\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, cfg.epochs, eta_min=1e-7)\n",
    "    scheduler = GradualWarmupSchedulerV2(\n",
    "        optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n",
    "\n",
    "    return scheduler\n",
    "\n",
    "def scheduler_step(scheduler, avg_val_loss, epoch):\n",
    "    scheduler.step(epoch)\n",
    "\n",
    "def dice_coef(targets, preds, thr=0.5, beta=0.5, smooth=1e-5):\n",
    "\n",
    "    #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "    # flatten label and prediction tensors\n",
    "    preds = (preds > thr).view(-1).float()\n",
    "    targets = targets.view(-1).float()\n",
    "\n",
    "    y_true_count = targets.sum()\n",
    "    ctp = preds[targets==1].sum()\n",
    "    cfp = preds[targets==0].sum()\n",
    "    beta_squared = beta * beta\n",
    "\n",
    "    c_precision = ctp / (ctp + cfp + smooth)\n",
    "    c_recall = ctp / (y_true_count + smooth)\n",
    "    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n",
    "\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(train_loader, model, criterion, optimizer, writer, device, epoch):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    scaler = GradScaler(enabled=CFG.use_amp)\n",
    "    bar = tqdm(enumerate(train_loader), total=len(train_loader)) \n",
    "    for step, (image, label) in bar:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image.to(device))\n",
    "        loss = criterion(outputs, label.to(device))\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        bar.set_postfix(loss=f'{loss.item():0.4f}', epoch=epoch ,gpu_mem=f'{mem:0.2f} GB', lr=f'{optimizer.state_dict()[\"param_groups\"][0][\"lr\"]:0.2e}')\n",
    "        epoch_loss += loss.item()\n",
    "    writer.add_scalar('Train/Loss', epoch_loss / len(train_loader), epoch)\n",
    "    return epoch_loss / len(train_loader)\n",
    "\n",
    "def valid_step(valid_loader, model, valid_xyxys, valid_mask , criterion, device, writer, epoch):\n",
    "    model.eval()\n",
    "    mask_pred = np.zeros(valid_mask.shape)\n",
    "    mask_count = (1 - valid_mask).astype(np.float64)\n",
    "    valid_mask_gt = np.zeros(valid_mask.shape)\n",
    "\n",
    "    epoch_loss = 0\n",
    "    dice_scores = {}\n",
    "    for th in np.arange(1, 6, 0.5) / 10:\n",
    "        dice_scores[th] = []\n",
    "\n",
    "    bar = tqdm(enumerate(valid_loader), total=len(valid_loader)) \n",
    "    for step, (image, label) in bar:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(image)\n",
    "            loss = criterion(y_pred, label)\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        bar.set_postfix(loss=f'{loss.item():0.4f}', epoch=epoch ,gpu_mem=f'{mem:0.2f} GB')\n",
    "        # make whole mask\n",
    "        y_pred = torch.sigmoid(y_pred).to('cpu').numpy()\n",
    "        label = label.to('cpu').numpy()\n",
    "        start_idx = step*CFG.valid_batch_size\n",
    "        end_idx = start_idx + CFG.valid_batch_size\n",
    "        for i, (x1, y1, x2, y2) in enumerate(valid_xyxys[start_idx:end_idx]):\n",
    "            mask_pred[y1:y2, x1:x2] += y_pred[i].squeeze(0)\n",
    "            valid_mask_gt[y1:y2, x1:x2] = label[i].squeeze(0)\n",
    "            mask_count[y1:y2, x1:x2] += np.ones((CFG.valid_tile_size, CFG.valid_tile_size))\n",
    "        epoch_loss += loss.item()\n",
    "    avg_loss = epoch_loss / len(valid_loader)\n",
    "    writer.add_scalar('Valid/Loss', avg_loss, epoch)\n",
    "    best_th = 0\n",
    "    best_dice = 0\n",
    "    print(f'mask_count_min: {mask_count.min()}')\n",
    "    mask_pred /= mask_count\n",
    "    mask_pred *= valid_mask\n",
    "    has_nan = np.isnan(mask_pred).any()\n",
    "    print(has_nan)\n",
    "    if CFG.valid_id == 2:\n",
    "        # 防止内存溢出if  y2 <4800 or y2 > 4800 + 4096 + 2048 or x2 > 640+ 4096 +2048 or x2 < 640:\n",
    "        valid_mask_gt = valid_mask_gt[4800:4800+4096+2048, 640:640+4096+2048]\n",
    "        mask_pred = mask_pred[4800:4800+4096+2048, 640:640+4096+2048]\n",
    "        valid_mask = valid_mask[4800:4800+4096+2048, 640:640+4096+2048]\n",
    "    for th in np.arange(1, 6, 0.5) / 10:\n",
    "        dice_score = dice_coef(torch.from_numpy(valid_mask_gt).to(CFG.device), torch.from_numpy(mask_pred).to(CFG.device), thr=th).item()\n",
    "        dice_scores[th].append(dice_score)\n",
    "    for th in np.arange(1, 6, 0.5) / 10:\n",
    "        dice_score = sum(dice_scores[th]) / len(dice_scores[th])\n",
    "        if dice_score > best_dice:\n",
    "            best_dice = dice_score\n",
    "            best_th = th\n",
    "    # # 使用make_grid将图片转换成网格形式\n",
    "    # pred_mask = make_grid((torch.from_numpy(mask_pred) > best_th).float().to(CFG.device), normalize=True)\n",
    "    # true_mask = make_grid(torch.from_numpy(valid_mask_gt).to(CFG.device), normalize=True)\n",
    "    # # 使用add_image方法将图片添加到TensorBoard中\n",
    "    # writer.add_image('Valid/True_mask', true_mask, global_step=epoch, dataformats=\"CHW\")\n",
    "    # writer.add_image('Valid/Pred_mask', pred_mask, global_step=epoch, dataformats=\"CHW\")\n",
    "    mask_pred = (mask_pred >= best_th).astype(int)\n",
    "    cv2.imwrite(f'result/logs/{epoch}.png', mask_pred * 255)\n",
    "    cv2.imwrite(f'result/logs/gt.png', valid_mask_gt * 255)\n",
    "    if CFG.all_best_dice < best_dice:\n",
    "        print('best_th={:2f}' .format(best_th),\"score up: {:2f}->{:2f}\".format(CFG.all_best_dice, best_dice))       \n",
    "        CFG.all_best_dice = best_dice\n",
    "    torch.save(model.state_dict(), 'result/' +  '{}-DIM-{}-[eval_loss]-{:.4f}-[dice_score]-{:.2f}-'.format(CFG.model_name, CFG.in_chans , avg_loss, best_dice) + str(epoch) + '-epoch.pkl')  \n",
    "    writer.add_scalar('Valid/Dice', best_dice, epoch)\n",
    "    \n",
    "    return avg_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragment_id = CFG.valid_id\n",
    "valid_mask = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/mask.png\", 0)\n",
    "valid_mask = valid_mask.astype('float32') / 255.\n",
    "pad0 = (CFG.valid_tile_size - valid_mask.shape[0] % CFG.valid_tile_size)\n",
    "pad1 = (CFG.valid_tile_size - valid_mask.shape[1] % CFG.valid_tile_size)\n",
    "valid_mask = np.pad(valid_mask, [(0, pad0), (0, pad1)], constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:10<00:00,  1.13s/it, epoch=1, gpu_mem=7.71 GB, loss=0.4384, lr=5.00e-06]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 278/278 [01:13<00:00,  3.77it/s, epoch=1, gpu_mem=7.71 GB, loss=0.0361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "best_th=0.450000 score up: 0.000000->0.377888\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:07<00:00,  1.13s/it, epoch=2, gpu_mem=7.71 GB, loss=0.2088, lr=5.00e-05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 278/278 [01:13<00:00,  3.78it/s, epoch=2, gpu_mem=7.71 GB, loss=0.0155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "best_th=0.400000 score up: 0.377888->0.575385\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:19<00:00,  1.13s/it, epoch=3, gpu_mem=7.71 GB, loss=0.2052, lr=5.00e-05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 278/278 [01:14<00:00,  3.75it/s, epoch=3, gpu_mem=7.71 GB, loss=0.0255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "best_th=0.550000 score up: 0.575385->0.594623\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:24<00:00,  1.13s/it, epoch=4, gpu_mem=7.71 GB, loss=0.4167, lr=4.95e-05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 278/278 [01:14<00:00,  3.74it/s, epoch=4, gpu_mem=7.71 GB, loss=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "best_th=0.350000 score up: 0.594623->0.636369\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:28<00:00,  1.14s/it, epoch=5, gpu_mem=7.71 GB, loss=0.1422, lr=4.88e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 278/278 [01:13<00:00,  3.77it/s, epoch=5, gpu_mem=7.71 GB, loss=0.0358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:31<00:00,  1.14s/it, epoch=6, gpu_mem=7.71 GB, loss=0.1433, lr=4.78e-05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 278/278 [01:13<00:00,  3.76it/s, epoch=6, gpu_mem=7.71 GB, loss=0.0639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:34<00:00,  1.14s/it, epoch=7, gpu_mem=7.71 GB, loss=0.2406, lr=4.67e-05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 278/278 [01:14<00:00,  3.75it/s, epoch=7, gpu_mem=7.71 GB, loss=0.0455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:43<00:00,  1.14s/it, epoch=8, gpu_mem=7.71 GB, loss=0.1451, lr=4.52e-05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 278/278 [01:14<00:00,  3.75it/s, epoch=8, gpu_mem=7.71 GB, loss=0.0594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:39<00:00,  1.14s/it, epoch=9, gpu_mem=7.71 GB, loss=0.1839, lr=4.36e-05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 278/278 [01:14<00:00,  3.75it/s, epoch=9, gpu_mem=7.71 GB, loss=0.0351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "best_th=0.550000 score up: 0.636369->0.636658\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:42<00:00,  1.14s/it, epoch=10, gpu_mem=7.71 GB, loss=0.3626, lr=4.17e-05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 278/278 [01:14<00:00,  3.75it/s, epoch=10, gpu_mem=7.71 GB, loss=0.0290]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:43<00:00,  1.14s/it, epoch=11, gpu_mem=7.71 GB, loss=0.1464, lr=3.97e-05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 278/278 [01:13<00:00,  3.76it/s, epoch=11, gpu_mem=7.71 GB, loss=0.0529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:41<00:00,  1.14s/it, epoch=12, gpu_mem=7.71 GB, loss=0.1464, lr=3.75e-05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 278/278 [01:14<00:00,  3.75it/s, epoch=12, gpu_mem=7.71 GB, loss=0.0641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:47<00:00,  1.14s/it, epoch=13, gpu_mem=7.71 GB, loss=0.2307, lr=3.52e-05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 278/278 [01:14<00:00,  3.72it/s, epoch=13, gpu_mem=7.71 GB, loss=0.1287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:45<00:00,  1.14s/it, epoch=14, gpu_mem=7.71 GB, loss=0.3192, lr=3.28e-05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 278/278 [01:14<00:00,  3.75it/s, epoch=14, gpu_mem=7.71 GB, loss=0.1338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:45<00:00,  1.14s/it, epoch=15, gpu_mem=7.71 GB, loss=0.0794, lr=3.02e-05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 278/278 [01:14<00:00,  3.71it/s, epoch=15, gpu_mem=7.71 GB, loss=0.1044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:23<00:00,  1.13s/it, epoch=16, gpu_mem=7.71 GB, loss=0.2163, lr=2.77e-05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 278/278 [01:13<00:00,  3.76it/s, epoch=16, gpu_mem=7.71 GB, loss=0.1306]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2349/2349 [44:15<00:00,  1.13s/it, epoch=17, gpu_mem=7.71 GB, loss=0.1499, lr=2.51e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 278/278 [01:13<00:00,  3.76it/s, epoch=17, gpu_mem=7.71 GB, loss=0.1335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_count_min: 1.0\n",
      "False\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1981/2349 [36:31<06:47,  1.11s/it, epoch=18, gpu_mem=7.71 GB, loss=0.1797, lr=2.24e-05]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(CFG\u001b[39m.\u001b[39mepochs):\n\u001b[1;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtrain:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     train_step(train_loader, model, criterion, optimizer, writer, CFG\u001b[39m.\u001b[39;49mdevice, i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mval:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m     val_loss \u001b[39m=\u001b[39m valid_step(valid_loader, model, valid_xyxys, valid_mask, criterion, CFG\u001b[39m.\u001b[39mdevice, writer,  i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(train_loader, model, criterion, optimizer, writer, device, epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m scaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     11\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), CFG\u001b[39m.\u001b[39mmax_grad_norm)\n\u001b[0;32m---> 12\u001b[0m scaler\u001b[39m.\u001b[39;49mstep(optimizer)\n\u001b[1;32m     13\u001b[0m scaler\u001b[39m.\u001b[39mupdate()\n\u001b[1;32m     14\u001b[0m mem \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mmemory_reserved() \u001b[39m/\u001b[39m \u001b[39m1E9\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/dtt/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:338\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    336\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mfound_inf_per_device\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 338\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_opt_step(optimizer, optimizer_state, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    340\u001b[0m optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mstage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m OptState\u001b[39m.\u001b[39mSTEPPED\n\u001b[1;32m    342\u001b[0m \u001b[39mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/anaconda3/envs/dtt/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:284\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_maybe_opt_step\u001b[39m(\u001b[39mself\u001b[39m, optimizer, optimizer_state, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    283\u001b[0m     retval \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39msum\u001b[39;49m(v\u001b[39m.\u001b[39;49mitem() \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m optimizer_state[\u001b[39m\"\u001b[39;49m\u001b[39mfound_inf_per_device\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues()):\n\u001b[1;32m    285\u001b[0m         retval \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mstep(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    286\u001b[0m     \u001b[39mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/anaconda3/envs/dtt/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:284\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_maybe_opt_step\u001b[39m(\u001b[39mself\u001b[39m, optimizer, optimizer_state, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    283\u001b[0m     retval \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39msum\u001b[39m(v\u001b[39m.\u001b[39;49mitem() \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mfound_inf_per_device\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    285\u001b[0m         retval \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mstep(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    286\u001b[0m     \u001b[39mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                        lr=CFG.lr,\n",
    "                        betas=(0.9, 0.999),\n",
    "                        weight_decay=CFG.weight_decay\n",
    "                        )\n",
    "scheduler = get_scheduler(CFG, optimizer)\n",
    "writer = SummaryWriter('result/logs')\n",
    "\n",
    "for i in range(CFG.epochs):\n",
    "    print('train:')\n",
    "    train_step(train_loader, model, criterion, optimizer, writer, CFG.device, i + 1)\n",
    "    print('val:')\n",
    "    val_loss = valid_step(valid_loader, model, valid_xyxys, valid_mask, criterion, CFG.device, writer,  i + 1)\n",
    "    scheduler_step(scheduler, val_loss, i + 1)\n",
    "    import gc\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61166640a95ac08c4dfcc44984648f9045f44ea39ff0c31cc75bc4fde1586daf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
