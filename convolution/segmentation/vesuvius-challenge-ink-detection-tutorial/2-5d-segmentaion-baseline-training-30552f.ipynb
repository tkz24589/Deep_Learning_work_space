{"cells":[{"cell_type":"markdown","metadata":{},"source":["## summary\n","\n","* 2.5d segmentation\n","    *  segmentation_models_pytorch \n","    *  Unet\n","* use only 6 slices in the middle\n","* slide inference"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:50:04.942067Z","iopub.status.busy":"2023-04-04T05:50:04.941229Z","iopub.status.idle":"2023-04-04T05:50:08.854436Z","shell.execute_reply":"2023-04-04T05:50:08.853221Z","shell.execute_reply.started":"2023-04-04T05:50:04.942033Z"},"trusted":true},"outputs":[],"source":["\n","from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, log_loss\n","import pickle\n","from torch.utils.data import DataLoader\n","from torch.cuda.amp import autocast, GradScaler\n","import warnings\n","import sys\n","import pandas as pd\n","import os\n","import gc\n","import sys\n","import math\n","import time\n","import random\n","import shutil\n","from pathlib import Path\n","from contextlib import contextmanager\n","from collections import defaultdict, Counter\n","import cv2\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from functools import partial\n","\n","import argparse\n","import importlib\n","import torch\n","import torch.nn as nn\n","from torch.optim import Adam, SGD, AdamW\n","\n","import datetime"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:50:08.857552Z","iopub.status.busy":"2023-04-04T05:50:08.856941Z","iopub.status.idle":"2023-04-04T05:50:08.86897Z","shell.execute_reply":"2023-04-04T05:50:08.866753Z","shell.execute_reply.started":"2023-04-04T05:50:08.857508Z"},"trusted":true},"outputs":[],"source":["# sys.path.append('/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4')\n","# sys.path.append('/kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch-master')\n","# sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n","# sys.path.append('/kaggle/input/segmentation-models-pytorch/segmentation_models.pytorch-master')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:50:23.847082Z","iopub.status.busy":"2023-04-04T05:50:23.846745Z","iopub.status.idle":"2023-04-04T05:50:26.322624Z","shell.execute_reply":"2023-04-04T05:50:26.321448Z","shell.execute_reply.started":"2023-04-04T05:50:23.847045Z"},"trusted":true},"outputs":[],"source":["import segmentation_models_pytorch as smp"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:50:37.365713Z","iopub.status.busy":"2023-04-04T05:50:37.365274Z","iopub.status.idle":"2023-04-04T05:50:38.190783Z","shell.execute_reply":"2023-04-04T05:50:38.189664Z","shell.execute_reply.started":"2023-04-04T05:50:37.365653Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from torch.utils.data import DataLoader, Dataset\n","import cv2\n","import torch\n","import os\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from albumentations import ImageOnlyTransform"]},{"cell_type":"markdown","metadata":{},"source":["## config"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:50:38.19323Z","iopub.status.busy":"2023-04-04T05:50:38.192696Z","iopub.status.idle":"2023-04-04T05:50:38.211206Z","shell.execute_reply":"2023-04-04T05:50:38.209636Z","shell.execute_reply.started":"2023-04-04T05:50:38.193193Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["set dataset path\n"]}],"source":["import os\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","class CFG:\n","    # ============== comp exp name =============\n","    comp_name = 'vesuvius'\n","\n","    # comp_dir_path = './'\n","    comp_dir_path = '/kaggle/input/'\n","    comp_folder_name = 'vesuvius-challenge-ink-detection'\n","    # comp_dataset_path = f'{comp_dir_path}datasets/{comp_folder_name}/'\n","    comp_dataset_path = f'{comp_dir_path}{comp_folder_name}/'\n","    \n","    exp_name = 'vesuvius_2d_slide_exp002'\n","\n","    # ============== pred target =============\n","    target_size = 1\n","\n","    # ============== model cfg =============\n","    model_name = 'Unet'\n","    backbone = 'efficientnet-b0'\n","    # backbone = 'se_resnext50_32x4d'\n","\n","    in_chans = 6 # 65\n","    # ============== training cfg =============\n","    size = 224\n","    tile_size = 224\n","    stride = tile_size // 2\n","\n","    train_batch_size = 16 # 32\n","    valid_batch_size = train_batch_size * 2\n","    use_amp = True\n","\n","    scheduler = 'GradualWarmupSchedulerV2'\n","    # scheduler = 'CosineAnnealingLR'\n","    epochs = 15 # 30\n","\n","    # adamW warmupあり\n","    warmup_factor = 10\n","    # lr = 1e-4 / warmup_factor\n","    lr = 1e-4 / warmup_factor\n","\n","    # ============== fold =============\n","    valid_id = 1\n","\n","    # objective_cv = 'binary'  # 'binary', 'multiclass', 'regression'\n","    metric_direction = 'maximize'  # maximize, 'minimize'\n","    # metrics = 'dice_coef'\n","\n","    # ============== fixed =============\n","    pretrained = True\n","    inf_weight = 'best'  # 'best'\n","\n","    min_lr = 1e-6\n","    weight_decay = 1e-6\n","    max_grad_norm = 1000\n","\n","    print_freq = 50\n","    num_workers = 4\n","\n","    seed = 42\n","\n","    # ============== set dataset path =============\n","    print('set dataset path')\n","\n","    outputs_path = f'/kaggle/working/outputs/{comp_name}/{exp_name}/'\n","\n","    submission_dir = outputs_path + 'submissions/'\n","    submission_path = submission_dir + f'submission_{exp_name}.csv'\n","\n","    model_dir = outputs_path + \\\n","        f'{comp_name}-models/'\n","\n","    figures_dir = outputs_path + 'figures/'\n","\n","    log_dir = outputs_path + 'logs/'\n","    log_path = log_dir + f'{exp_name}.txt'\n","\n","    # ============== augmentation =============\n","    train_aug_list = [\n","        # A.RandomResizedCrop(\n","        #     size, size, scale=(0.85, 1.0)),\n","        A.Resize(size, size),\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.5),\n","        A.RandomBrightnessContrast(p=0.75),\n","        A.ShiftScaleRotate(p=0.75),\n","        A.OneOf([\n","                A.GaussNoise(var_limit=[10, 50]),\n","                A.GaussianBlur(),\n","                A.MotionBlur(),\n","                ], p=0.4),\n","        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n","        A.CoarseDropout(max_holes=1, max_width=int(size * 0.3), max_height=int(size * 0.3), \n","                        mask_fill_value=0, p=0.5),\n","        # A.Cutout(max_h_size=int(size * 0.6),\n","        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n","        A.Normalize(\n","            mean= [0] * in_chans,\n","            std= [1] * in_chans\n","        ),\n","        ToTensorV2(transpose_mask=True),\n","    ]\n","\n","    valid_aug_list = [\n","        A.Resize(size, size),\n","        A.Normalize(\n","            mean= [0] * in_chans,\n","            std= [1] * in_chans\n","        ),\n","        ToTensorV2(transpose_mask=True),\n","    ]\n"]},{"cell_type":"markdown","metadata":{},"source":["## helper"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:50:38.213481Z","iopub.status.busy":"2023-04-04T05:50:38.212989Z","iopub.status.idle":"2023-04-04T05:50:38.223704Z","shell.execute_reply":"2023-04-04T05:50:38.222663Z","shell.execute_reply.started":"2023-04-04T05:50:38.213439Z"},"trusted":true},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:50:38.226059Z","iopub.status.busy":"2023-04-04T05:50:38.225626Z","iopub.status.idle":"2023-04-04T05:50:38.235593Z","shell.execute_reply":"2023-04-04T05:50:38.234144Z","shell.execute_reply.started":"2023-04-04T05:50:38.225965Z"},"trusted":true},"outputs":[],"source":["def init_logger(log_file):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=log_file)\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","def set_seed(seed=None, cudnn_deterministic=True):\n","    if seed is None:\n","        seed = 42\n","\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = cudnn_deterministic\n","    torch.backends.cudnn.benchmark = False"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:50:38.241784Z","iopub.status.busy":"2023-04-04T05:50:38.241459Z","iopub.status.idle":"2023-04-04T05:50:38.247843Z","shell.execute_reply":"2023-04-04T05:50:38.246748Z","shell.execute_reply.started":"2023-04-04T05:50:38.241756Z"},"trusted":true},"outputs":[],"source":["def make_dirs(cfg):\n","    for dir in [cfg.model_dir, cfg.figures_dir, cfg.submission_dir, cfg.log_dir]:\n","        os.makedirs(dir, exist_ok=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:50:38.24971Z","iopub.status.busy":"2023-04-04T05:50:38.249241Z","iopub.status.idle":"2023-04-04T05:50:38.257126Z","shell.execute_reply":"2023-04-04T05:50:38.255307Z","shell.execute_reply.started":"2023-04-04T05:50:38.249675Z"},"trusted":true},"outputs":[],"source":["def cfg_init(cfg, mode='train'):\n","    set_seed(cfg.seed)\n","    # set_env_name()\n","    # set_dataset_path(cfg)\n","\n","    if mode == 'train':\n","        make_dirs(cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:50:38.258747Z","iopub.status.busy":"2023-04-04T05:50:38.258387Z","iopub.status.idle":"2023-04-04T05:50:38.326583Z","shell.execute_reply":"2023-04-04T05:50:38.325136Z","shell.execute_reply.started":"2023-04-04T05:50:38.258711Z"},"trusted":true},"outputs":[],"source":["cfg_init(CFG)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","Logger = init_logger(log_file=CFG.log_path)\n","\n","Logger.info('\\n\\n-------- exp_info -----------------')\n","# Logger.info(datetime.datetime.now().strftime('%Y年%m月%d日 %H:%M:%S'))"]},{"cell_type":"markdown","metadata":{},"source":["## image, mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:50:38.329105Z","iopub.status.busy":"2023-04-04T05:50:38.328402Z","iopub.status.idle":"2023-04-04T05:50:38.33872Z","shell.execute_reply":"2023-04-04T05:50:38.337763Z","shell.execute_reply.started":"2023-04-04T05:50:38.329062Z"},"trusted":true},"outputs":[],"source":["def read_image_mask(fragment_id):\n","\n","    images = []\n","\n","    # idxs = range(65)\n","    mid = 65 // 2\n","    start = mid - CFG.in_chans // 2\n","    end = mid + CFG.in_chans // 2\n","    idxs = range(start, end)\n","\n","    for i in tqdm(idxs):\n","        \n","        image = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/surface_volume/{i:02}.tif\", 0)\n","\n","        pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n","        pad1 = (CFG.tile_size - image.shape[1] % CFG.tile_size)\n","\n","        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n","\n","        images.append(image)\n","    images = np.stack(images, axis=2)\n","\n","    mask = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/inklabels.png\", 0)\n","    mask = np.pad(mask, [(0, pad0), (0, pad1)], constant_values=0)\n","\n","    mask = mask.astype('float32')\n","    mask /= 255.0\n","    \n","    return images, mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:50:38.341555Z","iopub.status.busy":"2023-04-04T05:50:38.3407Z","iopub.status.idle":"2023-04-04T05:50:38.351622Z","shell.execute_reply":"2023-04-04T05:50:38.350835Z","shell.execute_reply.started":"2023-04-04T05:50:38.341513Z"},"trusted":true},"outputs":[],"source":["def get_train_valid_dataset():\n","    train_images = []\n","    train_masks = []\n","\n","    valid_images = []\n","    valid_masks = []\n","    valid_xyxys = []\n","\n","    for fragment_id in range(1, 4):\n","\n","        image, mask = read_image_mask(fragment_id)\n","\n","        x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n","        y1_list = list(range(0, image.shape[0]-CFG.tile_size+1, CFG.stride))\n","\n","        for y1 in y1_list:\n","            for x1 in x1_list:\n","                y2 = y1 + CFG.tile_size\n","                x2 = x1 + CFG.tile_size\n","                # xyxys.append((x1, y1, x2, y2))\n","        \n","                if fragment_id == CFG.valid_id:\n","                    valid_images.append(image[y1:y2, x1:x2])\n","                    valid_masks.append(mask[y1:y2, x1:x2, None])\n","\n","                    valid_xyxys.append([x1, y1, x2, y2])\n","                else:\n","                    train_images.append(image[y1:y2, x1:x2])\n","                    train_masks.append(mask[y1:y2, x1:x2, None])\n","\n","    return train_images, train_masks, valid_images, valid_masks, valid_xyxys"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:50:38.354134Z","iopub.status.busy":"2023-04-04T05:50:38.353277Z","iopub.status.idle":"2023-04-04T05:51:20.631165Z","shell.execute_reply":"2023-04-04T05:51:20.630108Z","shell.execute_reply.started":"2023-04-04T05:50:38.354042Z"},"trusted":true},"outputs":[],"source":["train_images, train_masks, valid_images, valid_masks, valid_xyxys = get_train_valid_dataset()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:51:20.63304Z","iopub.status.busy":"2023-04-04T05:51:20.632692Z","iopub.status.idle":"2023-04-04T05:51:20.64927Z","shell.execute_reply":"2023-04-04T05:51:20.647916Z","shell.execute_reply.started":"2023-04-04T05:51:20.632997Z"},"trusted":true},"outputs":[],"source":["valid_xyxys = np.stack(valid_xyxys)"]},{"cell_type":"markdown","metadata":{},"source":["## dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:51:20.651743Z","iopub.status.busy":"2023-04-04T05:51:20.651337Z","iopub.status.idle":"2023-04-04T05:51:20.658373Z","shell.execute_reply":"2023-04-04T05:51:20.656822Z","shell.execute_reply.started":"2023-04-04T05:51:20.651703Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from torch.utils.data import DataLoader, Dataset\n","import cv2\n","import torch\n","import os\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from albumentations import ImageOnlyTransform"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:51:20.661414Z","iopub.status.busy":"2023-04-04T05:51:20.660178Z","iopub.status.idle":"2023-04-04T05:51:20.670557Z","shell.execute_reply":"2023-04-04T05:51:20.669713Z","shell.execute_reply.started":"2023-04-04T05:51:20.66137Z"},"trusted":true},"outputs":[],"source":["def get_transforms(data, cfg):\n","    if data == 'train':\n","        aug = A.Compose(cfg.train_aug_list)\n","    elif data == 'valid':\n","        aug = A.Compose(cfg.valid_aug_list)\n","\n","    # print(aug)\n","    return aug\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, images, cfg, labels=None, transform=None):\n","        self.images = images\n","        self.cfg = cfg\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        # return len(self.df)\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image = self.images[idx]\n","        label = self.labels[idx]\n","\n","        if self.transform:\n","            data = self.transform(image=image, mask=label)\n","            image = data['image']\n","            label = data['mask']\n","\n","        return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:51:20.673078Z","iopub.status.busy":"2023-04-04T05:51:20.67192Z","iopub.status.idle":"2023-04-04T05:51:20.683545Z","shell.execute_reply":"2023-04-04T05:51:20.682452Z","shell.execute_reply.started":"2023-04-04T05:51:20.67304Z"},"trusted":true},"outputs":[],"source":["\n","train_dataset = CustomDataset(\n","    train_images, CFG, labels=train_masks, transform=get_transforms(data='train', cfg=CFG))\n","valid_dataset = CustomDataset(\n","    valid_images, CFG, labels=valid_masks, transform=get_transforms(data='valid', cfg=CFG))\n","\n","train_loader = DataLoader(train_dataset,\n","                          batch_size=CFG.train_batch_size,\n","                          shuffle=True,\n","                          num_workers=CFG.num_workers, pin_memory=True, drop_last=True,\n","                          )\n","valid_loader = DataLoader(valid_dataset,\n","                          batch_size=CFG.valid_batch_size,\n","                          shuffle=False,\n","                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:51:20.685727Z","iopub.status.busy":"2023-04-04T05:51:20.684968Z","iopub.status.idle":"2023-04-04T05:51:20.73428Z","shell.execute_reply":"2023-04-04T05:51:20.733329Z","shell.execute_reply.started":"2023-04-04T05:51:20.685689Z"},"trusted":true},"outputs":[],"source":["train_dataset[0][0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:51:20.736127Z","iopub.status.busy":"2023-04-04T05:51:20.735684Z","iopub.status.idle":"2023-04-04T05:51:26.656584Z","shell.execute_reply":"2023-04-04T05:51:26.655392Z","shell.execute_reply.started":"2023-04-04T05:51:20.736089Z"},"trusted":true},"outputs":[],"source":["\n","plot_dataset = CustomDataset(\n","    train_images, CFG, labels=train_masks)\n","\n","transform = CFG.train_aug_list\n","transform = A.Compose(\n","    [t for t in transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n","\n","\n","plot_count = 0\n","for i in range(1000):\n","\n","    image, mask = plot_dataset[i]\n","    data = transform(image=image, mask=mask)\n","    aug_image = data['image']\n","    aug_mask = data['mask']\n","\n","    if mask.sum() == 0:\n","        continue\n","\n","    fig, axes = plt.subplots(1, 4, figsize=(15, 8))\n","    axes[0].imshow(image[..., 0], cmap=\"gray\")\n","    axes[1].imshow(mask, cmap=\"gray\")\n","    axes[2].imshow(aug_image[..., 0], cmap=\"gray\")\n","    axes[3].imshow(aug_mask, cmap=\"gray\")\n","    \n","    plt.savefig(CFG.figures_dir + f'aug_fold_{CFG.valid_id}_{plot_count}.png')\n","\n","    plot_count += 1\n","    if plot_count == 5:\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:51:26.658688Z","iopub.status.busy":"2023-04-04T05:51:26.658231Z","iopub.status.idle":"2023-04-04T05:51:26.872679Z","shell.execute_reply":"2023-04-04T05:51:26.871379Z","shell.execute_reply.started":"2023-04-04T05:51:26.65865Z"},"trusted":true},"outputs":[],"source":["del plot_dataset\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["## model"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:51:26.876524Z","iopub.status.busy":"2023-04-04T05:51:26.875667Z","iopub.status.idle":"2023-04-04T05:51:26.88457Z","shell.execute_reply":"2023-04-04T05:51:26.88351Z","shell.execute_reply.started":"2023-04-04T05:51:26.876478Z"},"trusted":true},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, weight=None):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        self.encoder = smp.Unet(\n","            encoder_name=cfg.backbone, \n","            encoder_weights=weight,\n","            in_channels=cfg.in_chans,\n","            classes=cfg.target_size,\n","            activation=None,\n","        )\n","\n","    def forward(self, image):\n","        output = self.encoder(image)\n","        # output = output.squeeze(-1)\n","        return output\n","\n","\n","def build_model(cfg, weight=\"imagenet\"):\n","    print('model_name', cfg.model_name)\n","    print('backbone', cfg.backbone)\n","\n","    model = CustomModel(cfg, weight)\n","\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["## scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:51:26.88703Z","iopub.status.busy":"2023-04-04T05:51:26.886749Z","iopub.status.idle":"2023-04-04T05:51:26.901457Z","shell.execute_reply":"2023-04-04T05:51:26.900426Z","shell.execute_reply.started":"2023-04-04T05:51:26.887004Z"},"trusted":true},"outputs":[],"source":["\n","import torch.nn as nn\n","import torch\n","import math\n","import time\n","import numpy as np\n","import torch\n","\n","from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n","from warmup_scheduler import GradualWarmupScheduler\n","\n","\n","class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n","    \"\"\"\n","    https://www.kaggle.com/code/underwearfitting/single-fold-training-of-resnet200d-lb0-965\n","    \"\"\"\n","    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n","        super(GradualWarmupSchedulerV2, self).__init__(\n","            optimizer, multiplier, total_epoch, after_scheduler)\n","\n","    def get_lr(self):\n","        if self.last_epoch > self.total_epoch:\n","            if self.after_scheduler:\n","                if not self.finished:\n","                    self.after_scheduler.base_lrs = [\n","                        base_lr * self.multiplier for base_lr in self.base_lrs]\n","                    self.finished = True\n","                return self.after_scheduler.get_lr()\n","            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n","        if self.multiplier == 1.0:\n","            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n","        else:\n","            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n","\n","def get_scheduler(cfg, optimizer):\n","    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(\n","        optimizer, cfg.epochs, eta_min=1e-7)\n","    scheduler = GradualWarmupSchedulerV2(\n","        optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n","\n","    return scheduler\n","\n","def scheduler_step(scheduler, avg_val_loss, epoch):\n","    scheduler.step(epoch)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:51:26.903907Z","iopub.status.busy":"2023-04-04T05:51:26.902941Z","iopub.status.idle":"2023-04-04T05:51:30.20362Z","shell.execute_reply":"2023-04-04T05:51:30.202562Z","shell.execute_reply.started":"2023-04-04T05:51:26.903869Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model_name Unet\n","backbone efficientnet-b0\n"]},{"name":"stderr","output_type":"stream","text":["Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /home/stu/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea8f4b5c5eed45de84218da0676113c5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/20.4M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m build_model(CFG)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[1;32m      3\u001b[0m model\u001b[39m.\u001b[39mto(device)\n","Cell \u001b[0;32mIn[11], line 24\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(cfg, weight)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m'\u001b[39m, cfg\u001b[39m.\u001b[39mmodel_name)\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mbackbone\u001b[39m\u001b[39m'\u001b[39m, cfg\u001b[39m.\u001b[39mbackbone)\n\u001b[0;32m---> 24\u001b[0m model \u001b[39m=\u001b[39m CustomModel(cfg, weight)\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m model\n","Cell \u001b[0;32mIn[11], line 6\u001b[0m, in \u001b[0;36mCustomModel.__init__\u001b[0;34m(self, cfg, weight)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m      4\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg \u001b[39m=\u001b[39m cfg\n\u001b[0;32m----> 6\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m smp\u001b[39m.\u001b[39;49mUnet(\n\u001b[1;32m      7\u001b[0m     encoder_name\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mbackbone, \n\u001b[1;32m      8\u001b[0m     encoder_weights\u001b[39m=\u001b[39;49mweight,\n\u001b[1;32m      9\u001b[0m     in_channels\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49min_chans,\n\u001b[1;32m     10\u001b[0m     classes\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mtarget_size,\n\u001b[1;32m     11\u001b[0m     activation\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     12\u001b[0m )\n","File \u001b[0;32m~/anaconda3/envs/dtt/lib/python3.9/site-packages/segmentation_models_pytorch/decoders/unet/model.py:71\u001b[0m, in \u001b[0;36mUnet.__init__\u001b[0;34m(self, encoder_name, encoder_depth, encoder_weights, decoder_use_batchnorm, decoder_channels, decoder_attention_type, in_channels, classes, activation, aux_params)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     57\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     58\u001b[0m     encoder_name: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mresnet34\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     aux_params: Optional[\u001b[39mdict\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     68\u001b[0m ):\n\u001b[1;32m     69\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m get_encoder(\n\u001b[1;32m     72\u001b[0m         encoder_name,\n\u001b[1;32m     73\u001b[0m         in_channels\u001b[39m=\u001b[39;49min_channels,\n\u001b[1;32m     74\u001b[0m         depth\u001b[39m=\u001b[39;49mencoder_depth,\n\u001b[1;32m     75\u001b[0m         weights\u001b[39m=\u001b[39;49mencoder_weights,\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     78\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder \u001b[39m=\u001b[39m UnetDecoder(\n\u001b[1;32m     79\u001b[0m         encoder_channels\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mout_channels,\n\u001b[1;32m     80\u001b[0m         decoder_channels\u001b[39m=\u001b[39mdecoder_channels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m         attention_type\u001b[39m=\u001b[39mdecoder_attention_type,\n\u001b[1;32m     85\u001b[0m     )\n\u001b[1;32m     87\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msegmentation_head \u001b[39m=\u001b[39m SegmentationHead(\n\u001b[1;32m     88\u001b[0m         in_channels\u001b[39m=\u001b[39mdecoder_channels[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[1;32m     89\u001b[0m         out_channels\u001b[39m=\u001b[39mclasses,\n\u001b[1;32m     90\u001b[0m         activation\u001b[39m=\u001b[39mactivation,\n\u001b[1;32m     91\u001b[0m         kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m     92\u001b[0m     )\n","File \u001b[0;32m~/anaconda3/envs/dtt/lib/python3.9/site-packages/segmentation_models_pytorch/encoders/__init__.py:85\u001b[0m, in \u001b[0;36mget_encoder\u001b[0;34m(name, in_channels, depth, weights, output_stride, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m     79\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mWrong pretrained weights `\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m` for encoder `\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m`. Available options are: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     80\u001b[0m                 weights,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m             )\n\u001b[1;32m     84\u001b[0m         )\n\u001b[0;32m---> 85\u001b[0m     encoder\u001b[39m.\u001b[39mload_state_dict(model_zoo\u001b[39m.\u001b[39;49mload_url(settings[\u001b[39m\"\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n\u001b[1;32m     87\u001b[0m encoder\u001b[39m.\u001b[39mset_in_channels(in_channels, pretrained\u001b[39m=\u001b[39mweights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m output_stride \u001b[39m!=\u001b[39m \u001b[39m32\u001b[39m:\n","File \u001b[0;32m~/anaconda3/envs/dtt/lib/python3.9/site-packages/torch/hub.py:727\u001b[0m, in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name)\u001b[0m\n\u001b[1;32m    725\u001b[0m         r \u001b[39m=\u001b[39m HASH_REGEX\u001b[39m.\u001b[39msearch(filename)  \u001b[39m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[1;32m    726\u001b[0m         hash_prefix \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mgroup(\u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m r \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 727\u001b[0m     download_url_to_file(url, cached_file, hash_prefix, progress\u001b[39m=\u001b[39;49mprogress)\n\u001b[1;32m    729\u001b[0m \u001b[39mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[1;32m    730\u001b[0m     \u001b[39mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location)\n","File \u001b[0;32m~/anaconda3/envs/dtt/lib/python3.9/site-packages/torch/hub.py:615\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(total\u001b[39m=\u001b[39mfile_size, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m progress,\n\u001b[1;32m    613\u001b[0m           unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mB\u001b[39m\u001b[39m'\u001b[39m, unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, unit_divisor\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m) \u001b[39mas\u001b[39;00m pbar:\n\u001b[1;32m    614\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 615\u001b[0m         buffer \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39;49mread(\u001b[39m8192\u001b[39;49m)\n\u001b[1;32m    616\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    617\u001b[0m             \u001b[39mbreak\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/dtt/lib/python3.9/http/client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[39m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 463\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    464\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    465\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m     \u001b[39m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     \u001b[39m# and self.chunked\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/dtt/lib/python3.9/http/client.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    502\u001b[0m         b \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[1;32m    504\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[1;32m    509\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n","File \u001b[0;32m~/anaconda3/envs/dtt/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/dtt/lib/python3.9/ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1239\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1240\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1241\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1244\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n","File \u001b[0;32m~/anaconda3/envs/dtt/lib/python3.9/ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1100\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1101\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model = build_model(CFG)\n","print(model)\n","model.to(device)\n","\n","optimizer = AdamW(model.parameters(), lr=CFG.lr)\n","scheduler = get_scheduler(CFG, optimizer)"]},{"cell_type":"markdown","metadata":{},"source":["## loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:51:30.205674Z","iopub.status.busy":"2023-04-04T05:51:30.205266Z","iopub.status.idle":"2023-04-04T05:51:30.214065Z","shell.execute_reply":"2023-04-04T05:51:30.212997Z","shell.execute_reply.started":"2023-04-04T05:51:30.205636Z"},"trusted":true},"outputs":[],"source":["\n","DiceLoss = smp.losses.DiceLoss(mode='binary')\n","BCELoss = smp.losses.SoftBCEWithLogitsLoss()\n","\n","alpha = 0.5\n","beta = 1 - alpha\n","TverskyLoss = smp.losses.TverskyLoss(\n","    mode='binary', log_loss=False, alpha=alpha, beta=beta)\n","\n","def criterion(y_pred, y_true):\n","    # return 0.5 * BCELoss(y_pred, y_true) + 0.5 * DiceLoss(y_pred, y_true)\n","    return BCELoss(y_pred, y_true)\n","    # return 0.5 * BCELoss(y_pred, y_true) + 0.5 * TverskyLoss(y_pred, y_true)"]},{"cell_type":"markdown","metadata":{},"source":["## train, val"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:51:30.216151Z","iopub.status.busy":"2023-04-04T05:51:30.21568Z","iopub.status.idle":"2023-04-04T05:51:30.23155Z","shell.execute_reply":"2023-04-04T05:51:30.230509Z","shell.execute_reply.started":"2023-04-04T05:51:30.21611Z"},"trusted":true},"outputs":[],"source":["def train_fn(train_loader, model, criterion, optimizer, device):\n","    model.train()\n","\n","    scaler = GradScaler(enabled=CFG.use_amp)\n","    losses = AverageMeter()\n","\n","    for step, (images, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with autocast(CFG.use_amp):\n","            y_preds = model(images)\n","            loss = criterion(y_preds, labels)\n","\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","\n","        grad_norm = torch.nn.utils.clip_grad_norm_(\n","            model.parameters(), CFG.max_grad_norm)\n","\n","        scaler.step(optimizer)\n","        scaler.update()\n","        optimizer.zero_grad()\n","\n","    return losses.avg\n","\n","def valid_fn(valid_loader, model, criterion, device, valid_xyxys, valid_mask_gt):\n","    mask_pred = np.zeros(valid_mask_gt.shape)\n","    mask_count = np.zeros(valid_mask_gt.shape)\n","\n","    model.eval()\n","    losses = AverageMeter()\n","\n","    for step, (images, labels) in tqdm(enumerate(valid_loader), total=len(valid_loader)):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.no_grad():\n","            y_preds = model(images)\n","            loss = criterion(y_preds, labels)\n","        losses.update(loss.item(), batch_size)\n","\n","        # make whole mask\n","        y_preds = torch.sigmoid(y_preds).to('cpu').numpy()\n","        start_idx = step*CFG.valid_batch_size\n","        end_idx = start_idx + batch_size\n","        for i, (x1, y1, x2, y2) in enumerate(valid_xyxys[start_idx:end_idx]):\n","            mask_pred[y1:y2, x1:x2] += y_preds[i].squeeze(0)\n","            mask_count[y1:y2, x1:x2] += np.ones((CFG.tile_size, CFG.tile_size))\n","\n","    print(f'mask_count_min: {mask_count.min()}')\n","    mask_pred /= mask_count\n","    return losses.avg, mask_pred"]},{"cell_type":"markdown","metadata":{},"source":["## metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:51:30.23806Z","iopub.status.busy":"2023-04-04T05:51:30.237696Z","iopub.status.idle":"2023-04-04T05:51:30.248748Z","shell.execute_reply":"2023-04-04T05:51:30.247706Z","shell.execute_reply.started":"2023-04-04T05:51:30.23803Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import fbeta_score\n","\n","def fbeta_numpy(targets, preds, beta=0.5, smooth=1e-5):\n","    \"\"\"\n","    https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/397288\n","    \"\"\"\n","    y_true_count = targets.sum()\n","    ctp = preds[targets==1].sum()\n","    cfp = preds[targets==0].sum()\n","    beta_squared = beta * beta\n","\n","    c_precision = ctp / (ctp + cfp + smooth)\n","    c_recall = ctp / (y_true_count + smooth)\n","    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n","\n","    return dice\n","\n","def calc_fbeta(mask, mask_pred):\n","    mask = mask.astype(int).flatten()\n","    mask_pred = mask_pred.flatten()\n","\n","    best_th = 0\n","    best_dice = 0\n","    for th in np.array(range(10, 50+1, 5)) / 100:\n","        \n","        # dice = fbeta_score(mask, (mask_pred >= th).astype(int), beta=0.5)\n","        dice = fbeta_numpy(mask, (mask_pred >= th).astype(int), beta=0.5)\n","        print(f'th: {th}, fbeta: {dice}')\n","\n","        if dice > best_dice:\n","            best_dice = dice\n","            best_th = th\n","    \n","    Logger.info(f'best_th: {best_th}, fbeta: {best_dice}')\n","    return best_dice, best_th\n","\n","\n","def calc_cv(mask_gt, mask_pred):\n","    best_dice, best_th = calc_fbeta(mask_gt, mask_pred)\n","\n","    return best_dice, best_th"]},{"cell_type":"markdown","metadata":{},"source":["## main"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:51:30.250925Z","iopub.status.busy":"2023-04-04T05:51:30.250303Z","iopub.status.idle":"2023-04-04T05:51:30.765669Z","shell.execute_reply":"2023-04-04T05:51:30.764621Z","shell.execute_reply.started":"2023-04-04T05:51:30.250887Z"},"trusted":true},"outputs":[],"source":["fragment_id = CFG.valid_id\n","\n","valid_mask_gt = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/inklabels.png\", 0)\n","valid_mask_gt = valid_mask_gt / 255\n","pad0 = (CFG.tile_size - valid_mask_gt.shape[0] % CFG.tile_size)\n","pad1 = (CFG.tile_size - valid_mask_gt.shape[1] % CFG.tile_size)\n","valid_mask_gt = np.pad(valid_mask_gt, [(0, pad0), (0, pad1)], constant_values=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T05:51:30.767837Z","iopub.status.busy":"2023-04-04T05:51:30.767438Z","iopub.status.idle":"2023-04-04T06:51:14.117016Z","shell.execute_reply":"2023-04-04T06:51:14.115452Z","shell.execute_reply.started":"2023-04-04T05:51:30.767795Z"},"trusted":true},"outputs":[],"source":["\n","fold = CFG.valid_id\n","\n","if CFG.metric_direction == 'minimize':\n","    best_score = np.inf\n","elif CFG.metric_direction == 'maximize':\n","    best_score = -1\n","\n","best_loss = np.inf\n","\n","for epoch in range(CFG.epochs):\n","\n","    start_time = time.time()\n","\n","    # train\n","    avg_loss = train_fn(train_loader, model, criterion, optimizer, device)\n","\n","    # eval\n","    avg_val_loss, mask_pred = valid_fn(\n","        valid_loader, model, criterion, device, valid_xyxys, valid_mask_gt)\n","\n","    scheduler_step(scheduler, avg_val_loss, epoch)\n","\n","    best_dice, best_th = calc_cv(valid_mask_gt, mask_pred)\n","\n","    # score = avg_val_loss\n","    score = best_dice\n","\n","    elapsed = time.time() - start_time\n","\n","    Logger.info(\n","        f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","    # Logger.info(f'Epoch {epoch+1} - avgScore: {avg_score:.4f}')\n","    Logger.info(\n","        f'Epoch {epoch+1} - avgScore: {score:.4f}')\n","\n","    if CFG.metric_direction == 'minimize':\n","        update_best = score < best_score\n","    elif CFG.metric_direction == 'maximize':\n","        update_best = score > best_score\n","\n","    if update_best:\n","        best_loss = avg_val_loss\n","        best_score = score\n","\n","        Logger.info(\n","            f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","        Logger.info(\n","            f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n","        \n","        torch.save({'model': model.state_dict(),\n","                    'preds': mask_pred},\n","                    CFG.model_dir + f'{CFG.model_name}_fold{fold}_best.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T06:51:14.122575Z","iopub.status.busy":"2023-04-04T06:51:14.122159Z","iopub.status.idle":"2023-04-04T06:51:17.552043Z","shell.execute_reply":"2023-04-04T06:51:17.550364Z","shell.execute_reply.started":"2023-04-04T06:51:14.122524Z"},"trusted":true},"outputs":[],"source":["check_point = torch.load(\n","    CFG.model_dir + f'{CFG.model_name}_fold{fold}_{CFG.inf_weight}.pth', map_location=torch.device('cpu'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T06:51:17.554159Z","iopub.status.busy":"2023-04-04T06:51:17.553755Z","iopub.status.idle":"2023-04-04T06:51:17.591872Z","shell.execute_reply":"2023-04-04T06:51:17.590665Z","shell.execute_reply.started":"2023-04-04T06:51:17.554119Z"},"trusted":true},"outputs":[],"source":["mask_pred = check_point['preds']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T06:51:17.594773Z","iopub.status.busy":"2023-04-04T06:51:17.593945Z","iopub.status.idle":"2023-04-04T06:51:23.216932Z","shell.execute_reply":"2023-04-04T06:51:23.215813Z","shell.execute_reply.started":"2023-04-04T06:51:17.594736Z"},"trusted":true},"outputs":[],"source":["best_dice, best_th  = calc_fbeta(valid_mask_gt, mask_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T06:51:23.218989Z","iopub.status.busy":"2023-04-04T06:51:23.218597Z","iopub.status.idle":"2023-04-04T06:51:37.221509Z","shell.execute_reply":"2023-04-04T06:51:37.220561Z","shell.execute_reply.started":"2023-04-04T06:51:23.21895Z"},"trusted":true},"outputs":[],"source":["fig, axes = plt.subplots(1, 3, figsize=(15, 8))\n","axes[0].imshow(valid_mask_gt)\n","axes[1].imshow(mask_pred)\n","axes[2].imshow((mask_pred>=best_th).astype(int))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T06:51:37.223885Z","iopub.status.busy":"2023-04-04T06:51:37.22286Z","iopub.status.idle":"2023-04-04T06:51:38.516812Z","shell.execute_reply":"2023-04-04T06:51:38.515375Z","shell.execute_reply.started":"2023-04-04T06:51:37.223843Z"},"trusted":true},"outputs":[],"source":["plt.hist(mask_pred.flatten(), bins=20)"]}],"metadata":{"kernelspec":{"display_name":"dtt","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"61166640a95ac08c4dfcc44984648f9045f44ea39ff0c31cc75bc4fde1586daf"}}},"nbformat":4,"nbformat_minor":4}
